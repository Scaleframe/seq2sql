<<<<<<< HEAD
WARNING:root:about to load dataset
WARNING:root:data loaded
WARNING:root:glove loaded
WARNING:root:SQLNet loaded
WARNING:root:method seq2sqlforward
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'template', u'type', u'code', ',', u'template', u'type', u'description', ',', u'template', u'id', ',', u'version', u'number', ',', u'template', u'type', u'code', ',', u'date', u'effective', u'from', ',', u'date', u'effective', u'to', ',', u'template', u'details', ',', u'document', u'id', ',', u'template', u'id', ',', u'document', u'name', ',', u'document', u'description', ',', u'other', u'details', ',', u'paragraph', u'id', ',', u'document', u'id', ',', u'paragraph', u'text', ',', u'other', u'details', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'template', u'type', u'code', ',', u'template', u'type', u'description', ',', u'template', u'id', ',', u'version', u'number', ',', u'template', u'type', u'code', ',', u'date', u'effective', u'from', ',', u'date', u'effective', u'to', ',', u'template', u'details', ',', u'document', u'id', ',', u'template', u'id', ',', u'document', u'name', ',', u'document', u'description', ',', u'other', u'details', ',', u'paragraph', u'id', ',', u'document', u'id', ',', u'paragraph', u'text', ',', u'other', u'details', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'template', u'type', u'code', ',', u'template', u'type', u'description', ',', u'template', u'id', ',', u'version', u'number', ',', u'template', u'type', u'code', ',', u'date', u'effective', u'from', ',', u'date', u'effective', u'to', ',', u'template', u'details', ',', u'document', u'id', ',', u'template', u'id', ',', u'document', u'name', ',', u'document', u'description', ',', u'other', u'details', ',', u'paragraph', u'id', ',', u'document', u'id', ',', u'paragraph', u'text', ',', u'other', u'details', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'template', u'type', u'code', ',', u'template', u'type', u'description', ',', u'template', u'id', ',', u'version', u'number', ',', u'template', u'type', u'code', ',', u'date', u'effective', u'from', ',', u'date', u'effective', u'to', ',', u'template', u'details', ',', u'document', u'id', ',', u'template', u'id', ',', u'document', u'name', ',', u'document', u'description', ',', u'other', u'details', ',', u'paragraph', u'id', ',', u'document', u'id', ',', u'paragraph', u'text', ',', u'other', u'details', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'template', u'type', u'code', ',', u'template', u'type', u'description', ',', u'template', u'id', ',', u'version', u'number', ',', u'template', u'type', u'code', ',', u'date', u'effective', u'from', ',', u'date', u'effective', u'to', ',', u'template', u'details', ',', u'document', u'id', ',', u'template', u'id', ',', u'document', u'name', ',', u'document', u'description', ',', u'other', u'details', ',', u'paragraph', u'id', ',', u'document', u'id', ',', u'paragraph', u'text', ',', u'other', u'details', ',']
Loading from new dataset
Loading data from New_Data/train.json
Loading data from New_Data/tables.json
Loading data from New_Data/dev.json
Loading data from New_Data/tables.json
Loading data from New_Data/train.json
Loading data from New_Data/tables.json
Loading word embedding from glove/glove.42B.300d.txt
WARNING:root:seq2sqlforward non-trainable embeddings
WARNING:root:gt_sel: None
WARNING:root:method subsequence_pred forward
WARNING:root:q_seq [[u'Home', u'many', u'documents', u'do', u'we', u'have', u'?'], [u'Count', u'the', u'number', u'of', u'documents', u'.'], [u'List', u'document', u'IDs', u',', u'document', u'names', u',', u'and', u'document', u'descriptions', u'for', u'all', u'documents', u'.'], [u'What', u'are', u'the', u'ids', u',', u'names', u',', u'and', u'descriptions', u'for', u'all', u'documents', u'?'], [u'What', u'is', u'the', u'document', u'name', u'and', u'template', u'id', u'for', u'document', u'with', u'description', u'with', u'the', u'letter', u"'w", u"'", u'in', u'it', u'?']]
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_toks: [u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id']
WARNING:root:to_idx: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details', ',']
WARNING:root:self.agg_sql_tok: ['MAX', 'MIN', 'AVG', 'COUNT', 'SUM']
WARNING:root:looking for id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:unknown pred col: id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:No items predicted in sel_query: predict them all
WARNING:root:pred sel_query indices: [0]
('st', 0)
('ed', 100)
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_toks: [u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id']
WARNING:root:to_idx: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details', ',']
WARNING:root:self.agg_sql_tok: ['MAX', 'MIN', 'AVG', 'COUNT', 'SUM']
WARNING:root:looking for id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:unknown pred col: id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:No items predicted in sel_query: predict them all
WARNING:root:pred sel_query indices: [0]
('st', 0)
('ed', 100)
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_toks: [u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id']
WARNING:root:to_idx: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details', ',']
WARNING:root:self.agg_sql_tok: ['MAX', 'MIN', 'AVG', 'COUNT', 'SUM']
WARNING:root:looking for id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:unknown pred col: id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:No items predicted in sel_query: predict them all
WARNING:root:pred sel_query indices: [0]
('st', 0)
('ed', 100)
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_toks: [u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id']
WARNING:root:to_idx: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details', ',']
WARNING:root:self.agg_sql_tok: ['MAX', 'MIN', 'AVG', 'COUNT', 'SUM']
WARNING:root:looking for id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:unknown pred col: id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:No items predicted in sel_query: predict them all
WARNING:root:pred sel_query indices: [0]
('st', 0)
('ed', 100)
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_tok 55
WARNING:root:sel_val id
WARNING:root:sel_toks: [u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id', u'id']
WARNING:root:to_idx: [u'*', u'template type code', u'template type description', u'template id', u'version number', u'template type code', u'date effective from', u'date effective to', u'template details', u'document id', u'template id', u'document name', u'document description', u'other details', u'paragraph id', u'document id', u'paragraph text', u'other details', ',']
WARNING:root:self.agg_sql_tok: ['MAX', 'MIN', 'AVG', 'COUNT', 'SUM']
WARNING:root:looking for id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:unknown pred col: id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id id
WARNING:root:No items predicted in sel_query: predict them all
WARNING:root:pred sel_query indices: [0]
WARNING:root:pred_queries: [{'agg': [0], 'sel': [0], 'conds': [[0, 0, u'have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have']]}, {'agg': [0], 'sel': [0], 'conds': [[0, 0, u'to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to']]}, {'agg': [0], 'sel': [0], 'conds': [[0, 0, u'to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to']]}, {'agg': [0], 'sel': [0], 'conds': [[0, 0, u'to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to']]}, {'agg': [0], 'sel': [0], 'conds': [[0, 0, u'to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to']]}]
WARNING:root:sel_pred: [0]
WARNING:root:sel_gt: [0]
WARNING:root:wrong number of columns
WARNING:root:Error increased by one
WARNING:root:sel_pred: [0]
WARNING:root:sel_gt: [0]
WARNING:root:wrong number of columns
WARNING:root:Error increased by one
WARNING:root:sel_pred: [0]
WARNING:root:sel_gt: [9, 11, 12]
WARNING:root:wrong number of columns selected
WARNING:root:incremented sel_err
WARNING:root:wrong number of columns
WARNING:root:Error increased by one
WARNING:root:sel_pred: [0]
WARNING:root:sel_gt: [9, 11, 12]
WARNING:root:wrong number of columns selected
WARNING:root:incremented sel_err
WARNING:root:wrong number of columns
WARNING:root:Error increased by one
WARNING:root:sel_pred: [0]
WARNING:root:sel_gt: [11, 10]
WARNING:root:wrong number of columns selected
WARNING:root:incremented sel_err
WARNING:root:Error increased by one
WARNING:root:tot_err: 5
WARNING:root:cond_err: 5.0
WARNING:root:one_acc_num: [ 0.  2.  0.]
WARNING:root:tot_acc_num: 0.0
WARNING:root:init_acc: (0.0, array([ 0. ,  0.4,  0. ]))
WARNING:root:Init dev acc_qm: 0.0
  breakdown on (agg, sel, where): [ 0.   0.4  0. ]
('st', 0)
('ed', 100)
WARNING:root:Epoch 1 @ 2018-04-26 15:38:03.484470
WARNING:root:method generate_gt_where_seq
WARNING:root:method generate_gt_sel_seq
WARNING:root:connect_col: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:cur_col_list: [[u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer']]
WARNING:root:all_toks_gt: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',', None, u'Who', u'is', u'the', u'founder', u'of', u'Sony', u'?', None]
WARNING:root:all_toks_condense: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', [u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer'], None, u'Who', u'is', u'the', u'founder', u'of', u'Sony', u'?', None]
WARNING:root:cur_sel_gt_query[u'SELECT', u'founder', u'FROM', u'manufacturers', u'WHERE', u'name', u'=', u"'Sony", u"'"]
WARNING:root:mini_sel_gt_seq([0], [4], 1, (2,), (2,), 1, [], 0, [], [], 0, -1)
WARNING:root:got word [u'founder'] for index12
WARNING:root:appended 16
WARNING:root:appended , with index 2
WARNING:root:cur_sel_query_indices: [0, 16, 1]
WARNING:root:connect_col: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:cur_col_list: [[u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer']]
WARNING:root:all_toks_gt: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',', None, u'Return', u'the', u'founder', u'of', u'Sony', u'.', None]
WARNING:root:all_toks_condense: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', [u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer'], None, u'Return', u'the', u'founder', u'of', u'Sony', u'.', None]
WARNING:root:cur_sel_gt_query[u'SELECT', u'founder', u'FROM', u'manufacturers', u'WHERE', u'name', u'=', u"'Sony", u"'"]
WARNING:root:mini_sel_gt_seq([0], [4], 1, (2,), (2,), 1, [], 0, [], [], 0, -1)
WARNING:root:got word [u'founder'] for index12
WARNING:root:appended 16
WARNING:root:appended , with index 2
WARNING:root:cur_sel_query_indices: [0, 16, 1]
WARNING:root:connect_col: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:cur_col_list: [[u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer']]
WARNING:root:all_toks_gt: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',', None, u'Where', u'is', u'the', u'headquarter', u'of', u'the', u'company', u'founded', u'by', u'James', u'?', None]
WARNING:root:all_toks_condense: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', [u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer'], None, u'Where', u'is', u'the', u'headquarter', u'of', u'the', u'company', u'founded', u'by', u'James', u'?', None]
WARNING:root:cur_sel_gt_query[u'SELECT', u'headquarter', u'FROM', u'manufacturers', u'WHERE', u'founder', u'=', u"'James", u"'"]
WARNING:root:mini_sel_gt_seq([0], [3], 1, (4,), (2,), 1, [], 0, [], [], 0, -1)
WARNING:root:got word [u'headquarter'] for index11
WARNING:root:appended 14
WARNING:root:appended , with index 2
WARNING:root:cur_sel_query_indices: [0, 14, 1]
WARNING:root:connect_col: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:cur_col_list: [[u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer']]
WARNING:root:all_toks_gt: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',', None, u'What', u'is', u'the', u'headquarter', u'of', u'the', u'company', u'whose', u'founder', u'is', u'James', u'?', None]
WARNING:root:all_toks_condense: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', [u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer'], None, u'What', u'is', u'the', u'headquarter', u'of', u'the', u'company', u'whose', u'founder', u'is', u'James', u'?', None]
WARNING:root:cur_sel_gt_query[u'SELECT', u'headquarter', u'FROM', u'manufacturers', u'WHERE', u'founder', u'=', u"'James", u"'"]
WARNING:root:mini_sel_gt_seq([0], [3], 1, (4,), (2,), 1, [], 0, [], [], 0, -1)
WARNING:root:got word [u'headquarter'] for index11
WARNING:root:appended 14
WARNING:root:appended , with index 2
WARNING:root:cur_sel_query_indices: [0, 14, 1]
WARNING:root:connect_col: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:cur_col_list: [[u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer']]
WARNING:root:all_toks_gt: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',', None, u'Find', u'all', u'manufacturers', u"'", u'names', u'and', u'their', u'headquarters', u',', u'sorted', u'by', u'the', u'ones', u'with', u'highest', u'revenue', u'first', u'.', None]
WARNING:root:all_toks_condense: ['SELECT', '<END>', ',', 'MAX', 'MIN', 'AVG', 'COUNT', 'SUM', [u'*'], [u'code'], [u'name'], [u'headquarter'], [u'founder'], [u'revenue'], [u'code'], [u'name'], [u'price'], [u'manufacturer'], None, u'Find', u'all', u'manufacturers', u"'", u'names', u'and', u'their', u'headquarters', u',', u'sorted', u'by', u'the', u'ones', u'with', u'highest', u'revenue', u'first', u'.', None]
WARNING:root:cur_sel_gt_query[u'SELECT', u'name', u',', u'headquarter', u'FROM', u'manufacturers', u'ORDER', u'BY', u'revenue', u'DESC']
WARNING:root:mini_sel_gt_seq([0, 0], [2, 3], 0, (), (), 2, [], 0, [0], [5], 1, 0)
WARNING:root:got word [u'name'] for index10
WARNING:root:appended 12
WARNING:root:appended , with index 2
WARNING:root:got word [u'headquarter'] for index11
WARNING:root:appended 14
WARNING:root:appended , with index 2
WARNING:root:cur_sel_query_indices: [0, 12, 2, 14, 1]
WARNING:root:method seq2sqlforward
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'code', u'name', u'headquarter', u'founder', u'revenue', u'code', u'name', u'price', u'manufacturer']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'code', u'name', u'headquarter', u'founder', u'revenue', u'code', u'name', u'price', u'manufacturer']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'code', u'name', u'headquarter', u'founder', u'revenue', u'code', u'name', u'price', u'manufacturer']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'code', u'name', u'headquarter', u'founder', u'revenue', u'code', u'name', u'price', u'manufacturer']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
WARNING:root:toks word_embedding _gen_x_batch: [u'*', u'code', u'name', u'headquarter', u'founder', u'revenue', u'code', u'name', u'price', u'manufacturer']
WARNING:root:first_item toks: *
WARNING:root:one_col_all _gen_x_batch: [u'*', ',', u'code', ',', u'name', ',', u'headquarter', ',', u'founder', ',', u'revenue', ',', u'code', ',', u'name', ',', u'price', ',', u'manufacturer', ',']
method epoch_train
WARNING:root:cond_score.size() torch.Size([5, 48])
Traceback (most recent call last):
  File "train_nl2sql.py", line 164, in <module>
    sql_data, table_data, TRAIN_ENTRY))
  File "/data/lily/slr63/SQLNet/sqlnet/utils_new.py", line 265, in epoch_train
    gt_where=gt_where_seq, gt_cond=gt_cond_seq, gt_sel=gt_sel_seq)
  File "/data/lily/slr63/SQLNet/sqlnet/model/seq2sql.py", line 266, in forward
    reinforce=reinforce)
  File "/home/lily/slr63/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.py", line 357, in __call__
    result = self.forward(*input, **kwargs)
  File "/data/lily/slr63/SQLNet/sqlnet/model/modules/seq2sql_condition_predict.py", line 80, in forward
    cond_score[idx, :, num:] = -100
  File "/home/lily/slr63/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.py", line 87, in __setitem__
    return SetItem.apply(self, key, value)
  File "/home/lily/slr63/anaconda2/lib/python2.7/site-packages/torch/autograd/_functions/tensor.py", line 117, in forward
    i._set_index(ctx.index, value)
IndexError: trying to index 3 dimensions of a 2 dimensional tensor
=======
Loading from nl2sql Yale dataset
Loading data from New_Data/Initial/train/art_1.json
Loading data from New_Data/Initial/train/boat_1.json
Loading data from New_Data/Initial/tables/art_1_table.json
Loading data from New_Data/Initial/tables/boat_1_table.json
clean_table_data
conds []
conds []
conds []
conds []
conds []
conds [[6, 0, u'80']]
conds []
conds [[13, 0, u"``gallery226''"]]
conds []
conds []
conds []
conds []
conds []
conds []
conds []
conds [[3, 0, u"``mary''"]]
conds [[4, 2, u'1850']]
conds [[3, 0, u"``pablo''"]]
conds []
conds [[11, 0, u"``oil''"]]
conds [[8, 0, u'1884']]
conds [[11, 0, u"``oil''"]]
conds []
conds []
conds [[8, 2, u'1900']]
conds [[8, 1, u'1910']]
conds [[11, 0, u"``oil''"]]
conds []
conds [[13, 0, u"``gallery240''"]]
conds []
conds []
conds []
conds []
conds []
conds [[1, 0, u'222']]
conds []
conds []
conds []
conds [[8, 2, u'1885'], [0, 1, u'1930']]
conds [[9, 1, u'500']]
conds [[12, 0, u"``panel''"]]
conds [[8, 2, u'1885']]
conds [[11, 0, u"``oil''"]]
conds [[8, 2, u'1900']]
conds []
conds []
conds []
conds []
conds []
conds [[13, 0, u"'gallery240'"]]
conds [[13, 0, u"'gallery240'"]]
Loading data from New_Data/Initial/dev/pets_1.json
Loading data from New_Data/Initial/tables/pets_1_table.json
clean_table_data
conds []
conds []
conds []
conds [[4, 1, u'20']]
conds [[5, 0, u"'f'"]]
conds []
conds []
conds [[12, 0, u"'dog'"]]
conds []
conds []
conds [[12, 0, u"'dog'"]]
conds []
conds []
conds []
conds []
conds []
conds []
conds []
conds []
conds [[13, 0, u'3'], [0, 0, u"'cat'"]]
conds []
Loading word embedding from glove/glove.42B.300d.txt
Using fixed embedding
Not using column attention on aggregator predicting
Not using column attention on selection predicting
Seq2SQL where prediction
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    0.0599    0.0530    0.0486  ...  -100.0000 -100.0000 -100.0000
    0.0500    0.0431    0.0387  ...  -100.0000 -100.0000 -100.0000
    0.0461    0.0392    0.0348  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0465    0.0396    0.0352  ...  -100.0000 -100.0000 -100.0000
    0.0465    0.0396    0.0352  ...  -100.0000 -100.0000 -100.0000
    0.0465    0.0396    0.0352  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.0605    0.0535    0.0491  ...  -100.0000 -100.0000 -100.0000
    0.0517    0.0448    0.0404  ...  -100.0000 -100.0000 -100.0000
    0.0486    0.0417    0.0373  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.0600    0.0531    0.0487  ...  -100.0000 -100.0000 -100.0000
    0.0512    0.0442    0.0398  ...  -100.0000 -100.0000 -100.0000
    0.0480    0.0411    0.0367  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    0.0597    0.0527    0.0483  ...  -100.0000 -100.0000 -100.0000
    0.0507    0.0438    0.0394  ...  -100.0000 -100.0000 -100.0000
    0.0476    0.0407    0.0363  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    0.0598    0.0528    0.0484  ...  -100.0000 -100.0000 -100.0000
    0.0507    0.0438    0.0394  ...  -100.0000 -100.0000 -100.0000
    0.0476    0.0406    0.0363  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000
    0.0483    0.0414    0.0370  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    0.0599    0.0530    0.0486  ...  -100.0000 -100.0000 -100.0000
    0.0500    0.0431    0.0387  ...  -100.0000 -100.0000 -100.0000
    0.0461    0.0392    0.0348  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0465    0.0396    0.0352  ...  -100.0000 -100.0000 -100.0000
    0.0465    0.0396    0.0352  ...  -100.0000 -100.0000 -100.0000
    0.0465    0.0396    0.0352  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [4, 0, 2, 3, 5, 1]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, u'information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information information']]
actual_cond []
predicted_agg [4, 0, 2, 3, 5, 1]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, u'major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major major']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.0602    0.0532    0.0488  ...  -100.0000 -100.0000 -100.0000
    0.0508    0.0439    0.0395  ...  -100.0000 -100.0000 -100.0000
    0.0475    0.0406    0.0362  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0493    0.0424    0.0380  ...  -100.0000 -100.0000 -100.0000
    0.0493    0.0424    0.0380  ...  -100.0000 -100.0000 -100.0000
    0.0493    0.0424    0.0380  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.0602    0.0532    0.0488  ...  -100.0000 -100.0000 -100.0000
    0.0508    0.0439    0.0395  ...  -100.0000 -100.0000 -100.0000
    0.0475    0.0406    0.0362  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0493    0.0424    0.0380  ...  -100.0000 -100.0000 -100.0000
    0.0493    0.0424    0.0380  ...  -100.0000 -100.0000 -100.0000
    0.0493    0.0424    0.0380  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.0600    0.0531    0.0487  ...  -100.0000 -100.0000 -100.0000
    0.0520    0.0450    0.0406  ...  -100.0000 -100.0000 -100.0000
    0.0498    0.0429    0.0385  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0540    0.0471    0.0427  ...  -100.0000 -100.0000 -100.0000
    0.0540    0.0471    0.0427  ...  -100.0000 -100.0000 -100.0000
    0.0540    0.0471    0.0427  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    0.0596    0.0526    0.0482  ...     0.0497    0.0583    0.0451
    0.0504    0.0435    0.0391  ...     0.0405    0.0492    0.0360
    0.0472    0.0403    0.0359  ...     0.0374    0.0460    0.0328
              ...                ⋱                ...             
    0.0483    0.0414    0.0370  ...     0.0385    0.0472    0.0340
    0.0483    0.0414    0.0370  ...     0.0385    0.0472    0.0340
    0.0483    0.0414    0.0370  ...     0.0385    0.0472    0.0340

( 4 ,.,.) = 
    0.0607    0.0538    0.0494  ...     0.0512    0.0404 -100.0000
    0.0519    0.0449    0.0406  ...     0.0424    0.0316 -100.0000
    0.0486    0.0417    0.0373  ...     0.0392    0.0283 -100.0000
              ...                ⋱                ...             
    0.0483    0.0414    0.0370  ...     0.0389    0.0281 -100.0000
    0.0483    0.0414    0.0370  ...     0.0389    0.0281 -100.0000
    0.0483    0.0414    0.0370  ...     0.0389    0.0281 -100.0000

( 5 ,.,.) = 
    0.0597    0.0528    0.0484  ...  -100.0000 -100.0000 -100.0000
    0.0518    0.0448    0.0404  ...  -100.0000 -100.0000 -100.0000
    0.0499    0.0430    0.0386  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0549    0.0480    0.0436  ...  -100.0000 -100.0000 -100.0000
    0.0549    0.0480    0.0436  ...  -100.0000 -100.0000 -100.0000
    0.0549    0.0480    0.0436  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [4, 0, 2, 3, 5, 1]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, u'have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have']]
actual_cond []
predicted_agg [4, 0, 2, 3, 5, 1]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, u'have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have']]
actual_cond []
----------

Init dev acc_qm: 0.809523809524
  breakdown on (agg, sel, where): [ 0.80952381  1.          0.80952381]
Epoch 1 @ 2018-04-12 20:35:49.939568
training
gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  6.4091e-02  5.9766e-02  5.5472e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8190e-02  7.3847e-02  6.9556e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8190e-02  7.3847e-02  6.9556e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8190e-02  7.3847e-02  6.9556e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8190e-02  7.3847e-02  6.9556e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8190e-02  7.3847e-02  6.9556e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  5.9739e-02  5.2651e-02  4.9233e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6284e-02  6.9191e-02  6.5757e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6284e-02  6.9191e-02  6.5757e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.6284e-02  6.9191e-02  6.5757e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6284e-02  6.9191e-02  6.5757e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6284e-02  6.9191e-02  6.5757e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  5.9092e-02  5.3421e-02  4.4432e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7229e-02  7.1565e-02  6.2569e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7229e-02  7.1565e-02  6.2569e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7229e-02  7.1565e-02  6.2569e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7229e-02  7.1565e-02  6.2569e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7229e-02  7.1565e-02  6.2569e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  6.5777e-02  5.7783e-02  5.1218e-02  ...   5.0981e-02 -1.0000e+02 -1.0000e+02
  7.9367e-02  7.1365e-02  6.4805e-02  ...   6.4585e-02 -1.0000e+02 -1.0000e+02
  7.9367e-02  7.1365e-02  6.4805e-02  ...   6.4585e-02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.9367e-02  7.1365e-02  6.4805e-02  ...   6.4585e-02 -1.0000e+02 -1.0000e+02
  7.9367e-02  7.1365e-02  6.4805e-02  ...   6.4585e-02 -1.0000e+02 -1.0000e+02
  7.9367e-02  7.1365e-02  6.4805e-02  ...   6.4585e-02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  5.7628e-02  5.0351e-02  4.8150e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4743e-02  6.7462e-02  6.5255e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4743e-02  6.7462e-02  6.5255e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4743e-02  6.7462e-02  6.5255e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4743e-02  6.7462e-02  6.5255e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4743e-02  6.7462e-02  6.5255e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  5.9349e-02  5.0736e-02  4.8793e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7135e-02  6.8522e-02  6.6574e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7135e-02  6.8522e-02  6.6574e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7135e-02  6.8522e-02  6.6574e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7135e-02  6.8522e-02  6.6574e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7135e-02  6.8522e-02  6.6574e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x8x63 (GPU 0)]

gt_where_seq [[7, 0, 28, 0, 0, 53, 0, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 55, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 22, 0, 53, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  6.3276e-02  5.5353e-02  4.2858e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4972e-02  4.7050e-02  3.4558e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5476e-02  4.7550e-02  3.5059e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.6382e-02  4.8456e-02  3.5961e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7088e-02  4.9162e-02  3.6666e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8435e-02  5.0508e-02  3.8010e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  5.7378e-02  4.7917e-02  4.4566e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.7846e-02  3.8393e-02  3.5041e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6875e-02  3.7424e-02  3.4071e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.2231e-02  4.2781e-02  3.9422e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4581e-02  6.5109e-02  6.1745e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4581e-02  6.5109e-02  6.1745e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  6.0760e-02  5.2656e-02  4.6729e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6544e-02  6.8443e-02  6.2509e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6544e-02  6.8443e-02  6.2509e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.6544e-02  6.8443e-02  6.2509e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6544e-02  6.8443e-02  6.2509e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6544e-02  6.8443e-02  6.2509e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  6.1177e-02  5.4915e-02  4.5320e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4435e-02  4.8178e-02  3.8582e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5321e-02  4.9058e-02  3.9457e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.7634e-02  5.1371e-02  4.1764e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7032e-02  7.0764e-02  6.1151e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7032e-02  7.0764e-02  6.1151e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  6.3225e-02  5.4987e-02  4.6154e-02  ...   3.0545e-02  4.5536e-02  4.1369e-02
  7.4468e-02  6.6225e-02  5.7372e-02  ...   4.1862e-02  5.6840e-02  5.2650e-02
  7.4468e-02  6.6225e-02  5.7372e-02  ...   4.1862e-02  5.6840e-02  5.2650e-02
                 ...                   ⋱                   ...                
  7.4468e-02  6.6225e-02  5.7372e-02  ...   4.1862e-02  5.6840e-02  5.2650e-02
  7.4468e-02  6.6225e-02  5.7372e-02  ...   4.1862e-02  5.6840e-02  5.2650e-02
  7.4468e-02  6.6225e-02  5.7372e-02  ...   4.1862e-02  5.6840e-02  5.2650e-02

(14,.,.) = 
  5.8477e-02  5.2218e-02  4.1962e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4512e-02  6.8249e-02  5.7971e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4512e-02  6.8249e-02  5.7971e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4512e-02  6.8249e-02  5.7971e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4512e-02  6.8249e-02  5.7971e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4512e-02  6.8249e-02  5.7971e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x61 (GPU 0)]

gt_where_seq [[7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 8, 0, 55, 1], [7, 0, 0, 0, 60, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  6.2288e-02  5.1258e-02  4.1807e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7824e-02  4.6792e-02  3.7340e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7067e-02  4.6033e-02  3.6583e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.7270e-02  4.6232e-02  3.6789e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3717e-02  6.2694e-02  5.3255e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3717e-02  6.2694e-02  5.3255e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  6.5921e-02  5.1585e-02  4.4800e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5135e-02  6.0790e-02  5.4022e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5135e-02  6.0790e-02  5.4022e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.5135e-02  6.0790e-02  5.4022e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5135e-02  6.0790e-02  5.4022e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5135e-02  6.0790e-02  5.4022e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  6.6046e-02  5.7946e-02  4.6282e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9673e-02  5.1575e-02  3.9901e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5508e-02  4.7413e-02  3.5737e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.6568e-02  6.8476e-02  5.6788e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6568e-02  6.8476e-02  5.6788e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6568e-02  6.8476e-02  5.6788e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  7.2430e-02  5.9293e-02  4.6601e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5653e-02  5.2513e-02  3.9824e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2648e-02  4.9508e-02  3.6819e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2187e-02  4.9051e-02  3.6364e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2873e-02  4.9740e-02  3.7053e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3214e-02  5.0077e-02  3.7389e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  6.3409e-02  5.2895e-02  4.1455e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4347e-02  4.3839e-02  3.2406e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5441e-02  4.4931e-02  3.3501e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.5793e-02  6.5270e-02  5.3837e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5793e-02  6.5270e-02  5.3837e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5793e-02  6.5270e-02  5.3837e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  6.6583e-02  5.2782e-02  4.0071e-02  ...  -3.4418e-02 -2.8574e-02  5.1518e-03
  6.0036e-02  4.6240e-02  3.3527e-02  ...  -4.0973e-02 -3.5130e-02 -1.4090e-03
  6.0164e-02  4.6370e-02  3.3653e-02  ...  -4.0825e-02 -3.4978e-02 -1.2710e-03
                 ...                   ⋱                   ...                
  7.9529e-02  6.5743e-02  5.3022e-02  ...  -2.1271e-02 -1.5468e-02  1.8205e-02
  7.9529e-02  6.5743e-02  5.3022e-02  ...  -2.1271e-02 -1.5468e-02  1.8205e-02
  7.9529e-02  6.5743e-02  5.3022e-02  ...  -2.1271e-02 -1.5468e-02  1.8205e-02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  7.1006e-02  5.8024e-02  4.6991e-02  ...  -3.8513e-02 -4.5840e-02 -2.0006e-02
  7.5053e-02  6.2084e-02  5.1071e-02  ...  -3.4213e-02 -4.1512e-02 -1.5751e-02
  7.5053e-02  6.2084e-02  5.1071e-02  ...  -3.4213e-02 -4.1512e-02 -1.5751e-02
                 ...                   ⋱                   ...                
  7.5053e-02  6.2084e-02  5.1071e-02  ...  -3.4213e-02 -4.1512e-02 -1.5751e-02
  7.5053e-02  6.2084e-02  5.1071e-02  ...  -3.4213e-02 -4.1512e-02 -1.5751e-02
  7.5053e-02  6.2084e-02  5.1071e-02  ...  -3.4213e-02 -4.1512e-02 -1.5751e-02

(1 ,.,.) = 
  6.5550e-02  5.0247e-02  4.0026e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7847e-02  4.2547e-02  3.2328e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9283e-02  4.3990e-02  3.3772e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3169e-02  4.7866e-02  3.7642e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5692e-02  5.0386e-02  4.0161e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4168e-02  4.8863e-02  3.8638e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  7.5311e-02  5.9689e-02  5.0388e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9706e-02  6.4094e-02  5.4802e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9706e-02  6.4094e-02  5.4802e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.9706e-02  6.4094e-02  5.4802e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9706e-02  6.4094e-02  5.4802e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9706e-02  6.4094e-02  5.4802e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(3 ,.,.) = 
  7.4134e-02  5.7749e-02  4.8455e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8791e-02  6.2421e-02  5.3132e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8791e-02  6.2421e-02  5.3132e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8791e-02  6.2421e-02  5.3132e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8791e-02  6.2421e-02  5.3132e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8791e-02  6.2421e-02  5.3132e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(4 ,.,.) = 
  7.3738e-02  5.5933e-02  4.1933e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1614e-02  6.3816e-02  4.9853e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1614e-02  6.3816e-02  4.9853e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.1614e-02  6.3816e-02  4.9853e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1614e-02  6.3816e-02  4.9853e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1614e-02  6.3816e-02  4.9853e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(5 ,.,.) = 
  6.6208e-02  5.7614e-02  4.3287e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9356e-02  6.0770e-02  4.6459e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9356e-02  6.0770e-02  4.6459e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.9356e-02  6.0770e-02  4.6459e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9356e-02  6.0770e-02  4.6459e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9356e-02  6.0770e-02  4.6459e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x7x61 (GPU 0)]

 Loss = 13.8836910023
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  7.5947e-02  5.8051e-02  4.2143e-02  ...  -7.6720e-02 -3.6338e-02 -1.0000e+02
  7.0896e-02  5.2997e-02  3.7087e-02  ...  -8.1822e-02 -4.1419e-02 -1.0000e+02
  7.0092e-02  5.2191e-02  3.6280e-02  ...  -8.2626e-02 -4.2221e-02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -7.9754e-02 -3.9358e-02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -7.9754e-02 -3.9358e-02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -7.9754e-02 -3.9358e-02 -1.0000e+02

( 1 ,.,.) = 
  7.5001e-02  5.7106e-02  4.1200e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9907e-02  5.2009e-02  3.6101e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9300e-02  5.1401e-02  3.5491e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  7.5807e-02  5.7911e-02  4.2003e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0769e-02  5.2870e-02  3.6960e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0007e-02  5.2106e-02  3.6195e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  7.5330e-02  5.7434e-02  4.1526e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0212e-02  5.2313e-02  3.6403e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9564e-02  5.1663e-02  3.5753e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  7.5669e-02  5.7773e-02  4.1866e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0551e-02  5.2651e-02  3.6741e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9784e-02  5.1882e-02  3.5971e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  7.5156e-02  5.7259e-02  4.1351e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9819e-02  5.1919e-02  3.6009e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9070e-02  5.1168e-02  3.5257e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [4]
actual_agg [0, 0]
predicted_sel set([0])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4]
actual_agg [0]
predicted_sel set([0])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  7.5395e-02  5.7499e-02  4.1592e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0458e-02  5.2559e-02  3.6649e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9823e-02  5.1921e-02  3.6011e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  7.6129e-02  5.8234e-02  4.2327e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1116e-02  5.3217e-02  3.7308e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0271e-02  5.2370e-02  3.6460e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  7.5958e-02  5.8062e-02  4.2154e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0918e-02  5.3018e-02  3.7108e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0102e-02  5.2200e-02  3.6290e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  7.5907e-02  5.8011e-02  4.2104e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0886e-02  5.2987e-02  3.7077e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0102e-02  5.2201e-02  3.6290e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  7.5783e-02  5.7888e-02  4.1980e-02  ...  -7.6952e-02 -3.5854e-02 -1.0000e+02
  7.0902e-02  5.3003e-02  3.7093e-02  ...  -8.1882e-02 -4.0765e-02 -1.0000e+02
  7.0216e-02  5.2315e-02  3.6405e-02  ...  -8.2566e-02 -4.1448e-02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -7.9823e-02 -3.8712e-02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -7.9823e-02 -3.8712e-02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -7.9823e-02 -3.8712e-02 -1.0000e+02

(14 ,.,.) = 
  7.4228e-02  5.6333e-02  4.0425e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9303e-02  5.1404e-02  3.5495e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8990e-02  5.1090e-02  3.5180e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [4]
actual_agg [0]
predicted_sel set([0])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [4]
actual_agg [0]
predicted_sel set([0])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  7.6190e-02  5.8294e-02  4.2387e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1200e-02  5.3301e-02  3.7391e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0359e-02  5.2458e-02  3.6547e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  7.5864e-02  5.7968e-02  4.2061e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0826e-02  5.2926e-02  3.7017e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0048e-02  5.2147e-02  3.6236e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  7.6095e-02  5.8199e-02  4.2292e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1093e-02  5.3195e-02  3.7285e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0280e-02  5.2379e-02  3.6469e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  7.6179e-02  5.8284e-02  4.2376e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1194e-02  5.3295e-02  3.7386e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0355e-02  5.2454e-02  3.6543e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  7.6156e-02  5.8260e-02  4.2353e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1188e-02  5.3289e-02  3.7379e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0361e-02  5.2460e-02  3.6550e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  7.5017e-02  5.7119e-02  4.1210e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0105e-02  5.2205e-02  3.6293e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9593e-02  5.1691e-02  3.5779e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [4]
actual_agg [0]
predicted_sel set([0])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4]
actual_agg [0]
predicted_sel set([0])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  7.5802e-02  5.7906e-02  4.1999e-02  ...  -8.9939e-02 -8.3694e-02 -4.1494e-02
  7.0751e-02  5.2851e-02  3.6942e-02  ...  -9.5050e-02 -8.8802e-02 -4.6577e-02
  6.9965e-02  5.2063e-02  3.6153e-02  ...  -9.5838e-02 -8.9591e-02 -4.7361e-02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -9.2830e-02 -8.6592e-02 -4.4370e-02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -9.2830e-02 -8.6592e-02 -4.4370e-02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -9.2830e-02 -8.6592e-02 -4.4370e-02

( 1 ,.,.) = 
  7.6042e-02  5.8147e-02  4.2240e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1021e-02  5.3122e-02  3.7213e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0200e-02  5.2299e-02  3.6389e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  7.5985e-02  5.8089e-02  4.2182e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1011e-02  5.3112e-02  3.7202e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0216e-02  5.2315e-02  3.6405e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  7.5283e-02  5.7386e-02  4.1478e-02  ...  -1.0288e-01 -9.8797e-02 -4.2359e-02
  7.0318e-02  5.2417e-02  3.6507e-02  ...  -1.0788e-01 -1.0381e-01 -4.7355e-02
  6.9711e-02  5.1809e-02  3.5898e-02  ...  -1.0847e-01 -1.0441e-01 -4.7954e-02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0517e-01 -1.0112e-01 -4.4693e-02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0517e-01 -1.0112e-01 -4.4693e-02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -1.0517e-01 -1.0112e-01 -4.4693e-02

( 4 ,.,.) = 
  7.5974e-02  5.8079e-02  4.2172e-02  ...  -3.4456e-02 -1.0000e+02 -1.0000e+02
  7.1120e-02  5.3222e-02  3.7313e-02  ...  -3.9341e-02 -1.0000e+02 -1.0000e+02
  7.0399e-02  5.2499e-02  3.6590e-02  ...  -4.0063e-02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -3.7521e-02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -3.7521e-02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -3.7521e-02 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  7.5872e-02  5.7976e-02  4.2068e-02  ...  -3.6473e-02 -1.0000e+02 -1.0000e+02
  7.0988e-02  5.3089e-02  3.7179e-02  ...  -4.1388e-02 -1.0000e+02 -1.0000e+02
  7.0277e-02  5.2376e-02  3.6465e-02  ...  -4.2097e-02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -3.9422e-02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -3.9422e-02 -1.0000e+02 -1.0000e+02
  7.2922e-02  5.5019e-02  3.9109e-02  ...  -3.9422e-02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [4]
actual_agg [5, 5]
predicted_sel set([0])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4]
actual_agg [3]
predicted_sel set([0])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.84313725  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  7.5270e-02  5.7199e-02  4.1006e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0185e-02  5.2111e-02  3.5915e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9514e-02  5.1438e-02  3.5241e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  7.5760e-02  5.7687e-02  4.1492e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0750e-02  5.2674e-02  3.6476e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0036e-02  5.1958e-02  3.5760e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  7.5433e-02  5.7362e-02  4.1168e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0403e-02  5.2328e-02  3.6132e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9699e-02  5.1622e-02  3.5425e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  7.5127e-02  5.7055e-02  4.0862e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0026e-02  5.1952e-02  3.5756e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9356e-02  5.1279e-02  3.5083e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  7.5332e-02  5.7260e-02  4.1067e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0144e-02  5.2068e-02  3.5872e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9376e-02  5.1298e-02  3.5101e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  7.5270e-02  5.7199e-02  4.1006e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0185e-02  5.2111e-02  3.5915e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9514e-02  5.1438e-02  3.5241e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [4]
actual_agg [0]
predicted_sel set([5])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4]
actual_agg [0]
predicted_sel set([5])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  7.5551e-02  5.7480e-02  4.1287e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0514e-02  5.2439e-02  3.6243e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9797e-02  5.1720e-02  3.5523e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  7.5551e-02  5.7480e-02  4.1287e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0514e-02  5.2439e-02  3.6243e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9797e-02  5.1720e-02  3.5523e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  7.5376e-02  5.7305e-02  4.1111e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0341e-02  5.2266e-02  3.6070e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9674e-02  5.1597e-02  3.5400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  7.5387e-02  5.7314e-02  4.1119e-02  ...  -1.1979e-01 -8.4889e-02 -4.1469e-02
  7.0164e-02  5.2088e-02  3.5890e-02  ...  -1.2507e-01 -9.0168e-02 -4.6722e-02
  6.9359e-02  5.1280e-02  3.5082e-02  ...  -1.2586e-01 -9.0968e-02 -4.7520e-02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.2247e-01 -8.7588e-02 -4.4153e-02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.2247e-01 -8.7588e-02 -4.4153e-02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.2247e-01 -8.7588e-02 -4.4153e-02

( 4 ,.,.) = 
  7.5902e-02  5.7831e-02  4.1638e-02  ...  -9.6081e-02 -5.1946e-02 -1.0000e+02
  7.0890e-02  5.2816e-02  3.6620e-02  ...  -1.0113e-01 -5.6979e-02 -1.0000e+02
  7.0059e-02  5.1982e-02  3.5785e-02  ...  -1.0196e-01 -5.7804e-02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -9.9293e-02 -5.5148e-02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -9.9293e-02 -5.5148e-02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -9.9293e-02 -5.5148e-02 -1.0000e+02

( 5 ,.,.) = 
  7.5316e-02  5.7245e-02  4.1051e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0164e-02  5.2088e-02  3.5892e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9453e-02  5.1375e-02  3.5178e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2677e-02  5.4598e-02  3.8400e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [4]
actual_agg [0]
predicted_sel set([5])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4]
actual_agg [0]
predicted_sel set([5])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  0.80952381  0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 2 @ 2018-04-12 20:35:52.356918
training
gt_where_seq [[7, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 0, 22, 0, 54, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 8, 0, 55, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  8.0037e-02  6.3467e-02  4.8686e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2816e-02  6.6272e-02  5.1503e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2816e-02  6.6272e-02  5.1503e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.2816e-02  6.6272e-02  5.1503e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2816e-02  6.6272e-02  5.1503e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2816e-02  6.6272e-02  5.1503e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  7.1282e-02  5.9572e-02  3.4901e-02  ...  -1.1110e-01 -6.2635e-02 -1.0000e+02
  7.4325e-02  6.2638e-02  3.7999e-02  ...  -1.0769e-01 -5.9291e-02 -1.0000e+02
  7.4325e-02  6.2638e-02  3.7999e-02  ...  -1.0769e-01 -5.9291e-02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4325e-02  6.2638e-02  3.7999e-02  ...  -1.0769e-01 -5.9291e-02 -1.0000e+02
  7.4325e-02  6.2638e-02  3.7999e-02  ...  -1.0769e-01 -5.9291e-02 -1.0000e+02
  7.4325e-02  6.2638e-02  3.7999e-02  ...  -1.0769e-01 -5.9291e-02 -1.0000e+02

(2 ,.,.) = 
  7.8537e-02  6.3862e-02  4.5409e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4461e-02  5.9787e-02  4.1331e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4813e-02  6.0139e-02  4.1673e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7220e-02  6.2578e-02  4.4118e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7220e-02  6.2578e-02  4.4118e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7220e-02  6.2578e-02  4.4118e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  8.2420e-02  6.7580e-02  5.1263e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8749e-02  6.3901e-02  4.7575e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6092e-02  6.1244e-02  4.4920e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4025e-02  5.9179e-02  4.2857e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8959e-02  6.4157e-02  4.7860e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8959e-02  6.4157e-02  4.7860e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  7.1267e-02  5.6676e-02  4.0887e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2467e-02  4.7874e-02  3.2083e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2478e-02  4.7887e-02  3.2095e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7382e-02  5.2795e-02  3.7007e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6456e-02  5.1867e-02  3.6075e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8051e-02  5.3462e-02  3.7667e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  8.2665e-02  6.3054e-02  4.2442e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8191e-02  5.8578e-02  3.7961e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7524e-02  5.7914e-02  3.7298e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.2366e-02  6.2761e-02  4.2176e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2366e-02  6.2761e-02  4.2176e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2366e-02  6.2761e-02  4.2176e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  8.9104e-02  7.0541e-02  4.0206e-02  ...  -1.4512e-01 -7.1337e-02 -1.0000e+02
  7.8209e-02  5.9667e-02  2.9383e-02  ...  -1.5529e-01 -8.1764e-02 -1.0000e+02
  7.8209e-02  5.9667e-02  2.9383e-02  ...  -1.5529e-01 -8.1764e-02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8209e-02  5.9667e-02  2.9383e-02  ...  -1.5529e-01 -8.1764e-02 -1.0000e+02
  7.8209e-02  5.9667e-02  2.9383e-02  ...  -1.5529e-01 -8.1764e-02 -1.0000e+02
  7.8209e-02  5.9667e-02  2.9383e-02  ...  -1.5529e-01 -8.1764e-02 -1.0000e+02

(1 ,.,.) = 
  8.4891e-02  6.1231e-02  3.4169e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8114e-02  5.4497e-02  2.7478e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8114e-02  5.4497e-02  2.7478e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8114e-02  5.4497e-02  2.7478e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8114e-02  5.4497e-02  2.7478e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8114e-02  5.4497e-02  2.7478e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  9.1308e-02  6.0308e-02  3.8610e-02  ...  -1.2951e-01 -1.4209e-01 -9.1769e-02
  9.1103e-02  6.0088e-02  3.8390e-02  ...  -1.2980e-01 -1.4237e-01 -9.2049e-02
  9.0149e-02  5.9130e-02  3.7436e-02  ...  -1.3079e-01 -1.4335e-01 -9.3020e-02
                 ...                   ⋱                   ...                
  9.2115e-02  6.1095e-02  3.9401e-02  ...  -1.2880e-01 -1.4133e-01 -9.1013e-02
  9.1162e-02  6.0141e-02  3.8450e-02  ...  -1.2973e-01 -1.4227e-01 -9.1948e-02
  9.1529e-02  6.0509e-02  3.8821e-02  ...  -1.2935e-01 -1.4189e-01 -9.1568e-02
...

(12,.,.) = 
  7.4219e-02  5.7798e-02  3.5388e-02  ...  -1.1326e-01 -7.0727e-02 -1.0000e+02
  6.8340e-02  5.1974e-02  2.9621e-02  ...  -1.1855e-01 -7.6168e-02 -1.0000e+02
  6.8340e-02  5.1974e-02  2.9621e-02  ...  -1.1855e-01 -7.6168e-02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.8340e-02  5.1974e-02  2.9621e-02  ...  -1.1855e-01 -7.6168e-02 -1.0000e+02
  6.8340e-02  5.1974e-02  2.9621e-02  ...  -1.1855e-01 -7.6168e-02 -1.0000e+02
  6.8340e-02  5.1974e-02  2.9621e-02  ...  -1.1855e-01 -7.6168e-02 -1.0000e+02

(13,.,.) = 
  9.2542e-02  6.4541e-02  4.1667e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.4862e-02  5.6901e-02  3.4070e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.4862e-02  5.6901e-02  3.4070e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.4862e-02  5.6901e-02  3.4070e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.4862e-02  5.6901e-02  3.4070e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.4862e-02  5.6901e-02  3.4070e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  8.7586e-02  6.9872e-02  4.0557e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8836e-02  6.1138e-02  3.1892e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8836e-02  6.1138e-02  3.1892e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8836e-02  6.1138e-02  3.1892e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8836e-02  6.1138e-02  3.1892e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8836e-02  6.1138e-02  3.1892e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  9.2371e-02  6.1118e-02  3.7969e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2743e-02  4.1575e-02  1.8490e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2743e-02  4.1575e-02  1.8490e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2743e-02  4.1575e-02  1.8490e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2743e-02  4.1575e-02  1.8490e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2743e-02  4.1575e-02  1.8490e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  9.7083e-02  7.2721e-02  3.5707e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.4535e-02  7.0161e-02  3.3135e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.3780e-02  6.9403e-02  3.2369e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.5374e-02  5.1086e-02  1.4117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5374e-02  5.1086e-02  1.4117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5374e-02  5.1086e-02  1.4117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  9.4196e-02  6.3024e-02  3.0471e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4911e-02  4.3801e-02  1.1321e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4911e-02  4.3801e-02  1.1321e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4911e-02  4.3801e-02  1.1321e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4911e-02  4.3801e-02  1.1321e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4911e-02  4.3801e-02  1.1321e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  9.8275e-02  6.3155e-02  4.0845e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0550e-02  4.5501e-02  2.3258e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0550e-02  4.5501e-02  2.3258e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.0550e-02  4.5501e-02  2.3258e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0550e-02  4.5501e-02  2.3258e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0550e-02  4.5501e-02  2.3258e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  9.1183e-02  6.8276e-02  4.1101e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4020e-02  5.1164e-02  2.4055e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4020e-02  5.1164e-02  2.4055e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4020e-02  5.1164e-02  2.4055e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4020e-02  5.1164e-02  2.4055e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4020e-02  5.1164e-02  2.4055e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.0606e-01  8.0061e-02  5.0686e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0193e-01  7.5918e-02  4.6527e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.8779e-02  7.2759e-02  4.3362e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.3376e-02  6.7364e-02  3.7968e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.3142e-02  6.7128e-02  3.7731e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.1675e-02  6.5665e-02  3.6271e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.1619e-01  8.3962e-02  4.9462e-02  ...  -3.0895e-01 -2.7487e-01 -1.7122e-01
  7.9815e-02  4.7653e-02  1.3242e-02  ...  -3.4355e-01 -3.0968e-01 -2.0647e-01
  7.9815e-02  4.7653e-02  1.3242e-02  ...  -3.4355e-01 -3.0968e-01 -2.0647e-01
                 ...                   ⋱                   ...                
  7.9815e-02  4.7653e-02  1.3242e-02  ...  -3.4355e-01 -3.0968e-01 -2.0647e-01
  7.9815e-02  4.7653e-02  1.3242e-02  ...  -3.4355e-01 -3.0968e-01 -2.0647e-01
  7.9815e-02  4.7653e-02  1.3242e-02  ...  -3.4355e-01 -3.0968e-01 -2.0647e-01

(1 ,.,.) = 
  1.1486e-01  8.8546e-02  3.7489e-02  ...  -3.3356e-01 -2.4307e-01 -1.3921e-01
  1.1710e-01  9.0770e-02  3.9694e-02  ...  -3.3156e-01 -2.4101e-01 -1.3712e-01
  1.1428e-01  8.7955e-02  3.6875e-02  ...  -3.3441e-01 -2.4383e-01 -1.3991e-01
                 ...                   ⋱                   ...                
  1.1213e-01  8.5803e-02  3.4730e-02  ...  -3.3645e-01 -2.4589e-01 -1.4200e-01
  1.1495e-01  8.8628e-02  3.7559e-02  ...  -3.3362e-01 -2.4305e-01 -1.3916e-01
  1.1120e-01  8.4880e-02  3.3813e-02  ...  -3.3731e-01 -2.4674e-01 -1.4286e-01

(2 ,.,.) = 
  1.1381e-01  8.7451e-02  4.8775e-02  ...  -2.4097e-01 -2.2715e-01 -1.4906e-01
  7.9783e-02  5.3469e-02  1.4877e-02  ...  -2.7371e-01 -2.5989e-01 -1.8217e-01
  7.9783e-02  5.3469e-02  1.4877e-02  ...  -2.7371e-01 -2.5989e-01 -1.8217e-01
                 ...                   ⋱                   ...                
  7.9783e-02  5.3469e-02  1.4877e-02  ...  -2.7371e-01 -2.5989e-01 -1.8217e-01
  7.9783e-02  5.3469e-02  1.4877e-02  ...  -2.7371e-01 -2.5989e-01 -1.8217e-01
  7.9783e-02  5.3469e-02  1.4877e-02  ...  -2.7371e-01 -2.5989e-01 -1.8217e-01

(3 ,.,.) = 
  1.1451e-01  8.9504e-02  4.6640e-02  ...  -2.4711e-01 -2.6866e-01 -1.6806e-01
  1.1253e-01  8.7504e-02  4.4626e-02  ...  -2.4926e-01 -2.7082e-01 -1.7015e-01
  1.1074e-01  8.5708e-02  4.2828e-02  ...  -2.5108e-01 -2.7263e-01 -1.7195e-01
                 ...                   ⋱                   ...                
  1.1436e-01  8.9328e-02  4.6449e-02  ...  -2.4745e-01 -2.6901e-01 -1.6835e-01
  1.1319e-01  8.8157e-02  4.5286e-02  ...  -2.4854e-01 -2.7009e-01 -1.6945e-01
  1.1273e-01  8.7695e-02  4.4821e-02  ...  -2.4901e-01 -2.7058e-01 -1.6992e-01

(4 ,.,.) = 
  1.1112e-01  7.3963e-02  4.4869e-02  ...  -2.7319e-01 -1.6607e-01 -1.0000e+02
  7.9866e-02  4.2797e-02  1.3797e-02  ...  -3.0293e-01 -1.9615e-01 -1.0000e+02
  7.9866e-02  4.2797e-02  1.3797e-02  ...  -3.0293e-01 -1.9615e-01 -1.0000e+02
                 ...                   ⋱                   ...                
  7.9866e-02  4.2797e-02  1.3797e-02  ...  -3.0293e-01 -1.9615e-01 -1.0000e+02
  7.9866e-02  4.2797e-02  1.3797e-02  ...  -3.0293e-01 -1.9615e-01 -1.0000e+02
  7.9866e-02  4.2797e-02  1.3797e-02  ...  -3.0293e-01 -1.9615e-01 -1.0000e+02

(5 ,.,.) = 
  1.1348e-01  7.1025e-02  3.9839e-02  ...  -3.0953e-01 -2.7877e-01 -1.5151e-01
  8.2224e-02  3.9837e-02  8.7628e-03  ...  -3.3901e-01 -3.0849e-01 -1.8169e-01
  8.2224e-02  3.9837e-02  8.7628e-03  ...  -3.3901e-01 -3.0849e-01 -1.8169e-01
                 ...                   ⋱                   ...                
  8.2224e-02  3.9837e-02  8.7628e-03  ...  -3.3901e-01 -3.0849e-01 -1.8169e-01
  8.2224e-02  3.9837e-02  8.7628e-03  ...  -3.3901e-01 -3.0849e-01 -1.8169e-01
  8.2224e-02  3.9837e-02  8.7628e-03  ...  -3.3901e-01 -3.0849e-01 -1.8169e-01
[torch.cuda.FloatTensor of size 6x7x59 (GPU 0)]

 Loss = 12.5959635342
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    0.1277    0.0833    0.0363  ...    -0.3985   -0.2534 -100.0000
    0.1302    0.0858    0.0387  ...    -0.3963   -0.2511 -100.0000
    0.1302    0.0858    0.0388  ...    -0.3963   -0.2510 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...    -0.4021   -0.2569 -100.0000
    0.1241    0.0798    0.0327  ...    -0.4021   -0.2569 -100.0000
    0.1241    0.0798    0.0327  ...    -0.4021   -0.2569 -100.0000

( 1 ,.,.) = 
    0.1267    0.0824    0.0353  ...  -100.0000 -100.0000 -100.0000
    0.1290    0.0846    0.0376  ...  -100.0000 -100.0000 -100.0000
    0.1292    0.0848    0.0377  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.1281    0.0837    0.0367  ...  -100.0000 -100.0000 -100.0000
    0.1307    0.0863    0.0392  ...  -100.0000 -100.0000 -100.0000
    0.1307    0.0863    0.0392  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    0.1281    0.0838    0.0367  ...  -100.0000 -100.0000 -100.0000
    0.1306    0.0862    0.0392  ...  -100.0000 -100.0000 -100.0000
    0.1306    0.0862    0.0391  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    0.1297    0.0854    0.0383  ...  -100.0000 -100.0000 -100.0000
    0.1325    0.0881    0.0411  ...  -100.0000 -100.0000 -100.0000
    0.1323    0.0879    0.0408  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    0.1279    0.0835    0.0364  ...  -100.0000 -100.0000 -100.0000
    0.1302    0.0858    0.0387  ...  -100.0000 -100.0000 -100.0000
    0.1301    0.0857    0.0387  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.1286    0.0842    0.0372  ...  -100.0000 -100.0000 -100.0000
    0.1316    0.0872    0.0401  ...  -100.0000 -100.0000 -100.0000
    0.1317    0.0873    0.0402  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.1277    0.0833    0.0363  ...  -100.0000 -100.0000 -100.0000
    0.1302    0.0858    0.0388  ...  -100.0000 -100.0000 -100.0000
    0.1302    0.0858    0.0388  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.1279    0.0836    0.0365  ...  -100.0000 -100.0000 -100.0000
    0.1305    0.0862    0.0391  ...  -100.0000 -100.0000 -100.0000
    0.1306    0.0862    0.0391  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    0.1282    0.0838    0.0367  ...  -100.0000 -100.0000 -100.0000
    0.1308    0.0864    0.0393  ...  -100.0000 -100.0000 -100.0000
    0.1307    0.0863    0.0392  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    0.1270    0.0827    0.0356  ...    -0.3749   -0.2361 -100.0000
    0.1295    0.0851    0.0381  ...    -0.3726   -0.2338 -100.0000
    0.1297    0.0853    0.0382  ...    -0.3724   -0.2336 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...    -0.3777   -0.2390 -100.0000
    0.1241    0.0798    0.0327  ...    -0.3777   -0.2390 -100.0000
    0.1241    0.0798    0.0327  ...    -0.3777   -0.2390 -100.0000

(14 ,.,.) = 
    0.1259    0.0815    0.0345  ...  -100.0000 -100.0000 -100.0000
    0.1283    0.0839    0.0368  ...  -100.0000 -100.0000 -100.0000
    0.1286    0.0842    0.0372  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.1272    0.0829    0.0358  ...  -100.0000 -100.0000 -100.0000
    0.1296    0.0852    0.0381  ...  -100.0000 -100.0000 -100.0000
    0.1297    0.0853    0.0382  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.1282    0.0839    0.0368  ...  -100.0000 -100.0000 -100.0000
    0.1308    0.0865    0.0394  ...  -100.0000 -100.0000 -100.0000
    0.1308    0.0864    0.0393  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.1271    0.0827    0.0357  ...  -100.0000 -100.0000 -100.0000
    0.1295    0.0851    0.0380  ...  -100.0000 -100.0000 -100.0000
    0.1296    0.0852    0.0381  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    0.1288    0.0844    0.0374  ...  -100.0000 -100.0000 -100.0000
    0.1315    0.0871    0.0401  ...  -100.0000 -100.0000 -100.0000
    0.1314    0.0870    0.0399  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    0.1277    0.0833    0.0363  ...  -100.0000 -100.0000 -100.0000
    0.1302    0.0858    0.0387  ...  -100.0000 -100.0000 -100.0000
    0.1302    0.0858    0.0387  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    0.1279    0.0835    0.0364  ...  -100.0000 -100.0000 -100.0000
    0.1306    0.0862    0.0391  ...  -100.0000 -100.0000 -100.0000
    0.1306    0.0862    0.0391  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.1275    0.0831    0.0361  ...    -0.4278   -0.4005   -0.2561
    0.1300    0.0856    0.0385  ...    -0.4257   -0.3984   -0.2538
    0.1300    0.0856    0.0385  ...    -0.4257   -0.3983   -0.2538
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...    -0.4312   -0.4039   -0.2594
    0.1241    0.0798    0.0327  ...    -0.4312   -0.4039   -0.2594
    0.1241    0.0798    0.0327  ...    -0.4312   -0.4039   -0.2594

( 1 ,.,.) = 
    0.1274    0.0831    0.0360  ...  -100.0000 -100.0000 -100.0000
    0.1299    0.0855    0.0384  ...  -100.0000 -100.0000 -100.0000
    0.1300    0.0856    0.0385  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.1278    0.0835    0.0364  ...  -100.0000 -100.0000 -100.0000
    0.1304    0.0860    0.0390  ...  -100.0000 -100.0000 -100.0000
    0.1304    0.0860    0.0390  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    0.1272    0.0829    0.0358  ...    -0.4906   -0.4678   -0.2811
    0.1298    0.0854    0.0383  ...    -0.4884   -0.4656   -0.2788
    0.1299    0.0855    0.0384  ...    -0.4883   -0.4655   -0.2787
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...    -0.4935   -0.4708   -0.2841
    0.1241    0.0798    0.0327  ...    -0.4935   -0.4708   -0.2841
    0.1241    0.0798    0.0327  ...    -0.4935   -0.4708   -0.2841

( 4 ,.,.) = 
    0.1268    0.0824    0.0354  ...    -0.2341 -100.0000 -100.0000
    0.1292    0.0848    0.0378  ...    -0.2319 -100.0000 -100.0000
    0.1294    0.0850    0.0379  ...    -0.2317 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...    -0.2368 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...    -0.2368 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...    -0.2368 -100.0000 -100.0000

( 5 ,.,.) = 
    0.1274    0.0830    0.0359  ...    -0.2457 -100.0000 -100.0000
    0.1299    0.0855    0.0384  ...    -0.2433 -100.0000 -100.0000
    0.1300    0.0856    0.0386  ...    -0.2432 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1241    0.0798    0.0327  ...    -0.2489 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...    -0.2489 -100.0000 -100.0000
    0.1241    0.0798    0.0327  ...    -0.2489 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    0.1261    0.0807    0.0321  ...  -100.0000 -100.0000 -100.0000
    0.1286    0.0832    0.0346  ...  -100.0000 -100.0000 -100.0000
    0.1287    0.0833    0.0347  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.1255    0.0801    0.0315  ...  -100.0000 -100.0000 -100.0000
    0.1281    0.0827    0.0341  ...  -100.0000 -100.0000 -100.0000
    0.1284    0.0830    0.0344  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.1263    0.0809    0.0323  ...  -100.0000 -100.0000 -100.0000
    0.1289    0.0835    0.0349  ...  -100.0000 -100.0000 -100.0000
    0.1290    0.0836    0.0350  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    0.1255    0.0802    0.0316  ...  -100.0000 -100.0000 -100.0000
    0.1280    0.0826    0.0340  ...  -100.0000 -100.0000 -100.0000
    0.1282    0.0828    0.0342  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    0.1270    0.0816    0.0330  ...  -100.0000 -100.0000 -100.0000
    0.1295    0.0841    0.0355  ...  -100.0000 -100.0000 -100.0000
    0.1294    0.0840    0.0354  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    0.1261    0.0807    0.0321  ...  -100.0000 -100.0000 -100.0000
    0.1286    0.0832    0.0346  ...  -100.0000 -100.0000 -100.0000
    0.1287    0.0833    0.0347  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.1261    0.0807    0.0322  ...  -100.0000 -100.0000 -100.0000
    0.1288    0.0834    0.0348  ...  -100.0000 -100.0000 -100.0000
    0.1289    0.0835    0.0349  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.1261    0.0807    0.0322  ...  -100.0000 -100.0000 -100.0000
    0.1288    0.0834    0.0348  ...  -100.0000 -100.0000 -100.0000
    0.1289    0.0835    0.0349  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.1259    0.0805    0.0319  ...  -100.0000 -100.0000 -100.0000
    0.1285    0.0831    0.0345  ...  -100.0000 -100.0000 -100.0000
    0.1287    0.0833    0.0347  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    0.1267    0.0813    0.0327  ...    -0.5114   -0.4236   -0.2717
    0.1292    0.0838    0.0352  ...    -0.5092   -0.4213   -0.2693
    0.1291    0.0837    0.0351  ...    -0.5093   -0.4214   -0.2694
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...    -0.5154   -0.4276   -0.2757
    0.1226    0.0771    0.0286  ...    -0.5154   -0.4276   -0.2757
    0.1226    0.0771    0.0286  ...    -0.5154   -0.4276   -0.2757

( 4 ,.,.) = 
    0.1256    0.0802    0.0316  ...    -0.4298   -0.2835 -100.0000
    0.1280    0.0826    0.0340  ...    -0.4277   -0.2813 -100.0000
    0.1281    0.0827    0.0341  ...    -0.4276   -0.2812 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...    -0.4329   -0.2865 -100.0000
    0.1226    0.0771    0.0286  ...    -0.4329   -0.2865 -100.0000
    0.1226    0.0771    0.0286  ...    -0.4329   -0.2865 -100.0000

( 5 ,.,.) = 
    0.1267    0.0813    0.0327  ...  -100.0000 -100.0000 -100.0000
    0.1293    0.0839    0.0353  ...  -100.0000 -100.0000 -100.0000
    0.1293    0.0839    0.0353  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
    0.1226    0.0771    0.0286  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [4, 2, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 3 @ 2018-04-12 20:35:54.724132
training
gt_where_seq [[7, 0, 14, 0, 54, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 28, 0, 0, 54, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.2770e-01  7.5753e-02  2.7054e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3006e-01  7.8101e-02  2.9390e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3332e-01  8.1363e-02  3.2655e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3213e-01  8.0179e-02  3.1475e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2511e-02  3.0661e-02 -1.7925e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2511e-02  3.0661e-02 -1.7925e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.1723e-01  7.7486e-02  2.3264e-02  ...  -2.4160e-01 -1.0000e+02 -1.0000e+02
  1.2429e-01  8.4526e-02  3.0273e-02  ...  -2.3477e-01 -1.0000e+02 -1.0000e+02
  1.2056e-01  8.0792e-02  2.6537e-02  ...  -2.3846e-01 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2313e-01  8.3358e-02  2.9100e-02  ...  -2.3588e-01 -1.0000e+02 -1.0000e+02
  7.6737e-02  3.7096e-02 -1.6979e-02  ...  -2.8066e-01 -1.0000e+02 -1.0000e+02
  7.6737e-02  3.7096e-02 -1.6979e-02  ...  -2.8066e-01 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.2072e-01  7.7798e-02  3.0114e-02  ...  -4.8142e-01 -4.7462e-01 -2.9094e-01
  7.8000e-02  3.5184e-02 -1.2350e-02  ...  -5.2106e-01 -5.1428e-01 -3.3178e-01
  7.8000e-02  3.5184e-02 -1.2350e-02  ...  -5.2106e-01 -5.1428e-01 -3.3178e-01
                 ...                   ⋱                   ...                
  7.8000e-02  3.5184e-02 -1.2350e-02  ...  -5.2106e-01 -5.1428e-01 -3.3178e-01
  7.8000e-02  3.5184e-02 -1.2350e-02  ...  -5.2106e-01 -5.1428e-01 -3.3178e-01
  7.8000e-02  3.5184e-02 -1.2350e-02  ...  -5.2106e-01 -5.1428e-01 -3.3178e-01
...

(12,.,.) = 
  1.4252e-01  1.0221e-01  5.0468e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.0868e-02  5.0639e-02 -9.8680e-04  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.0868e-02  5.0639e-02 -9.8680e-04  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.0868e-02  5.0639e-02 -9.8680e-04  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.0868e-02  5.0639e-02 -9.8680e-04  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.0868e-02  5.0639e-02 -9.8680e-04  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.2104e-01  7.7317e-02  3.2225e-02  ...  -3.2397e-01 -1.0000e+02 -1.0000e+02
  1.3020e-01  8.6448e-02  4.1344e-02  ...  -3.1516e-01 -1.0000e+02 -1.0000e+02
  1.3231e-01  8.8559e-02  4.3455e-02  ...  -3.1309e-01 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2956e-01  8.5808e-02  4.0712e-02  ...  -3.1570e-01 -1.0000e+02 -1.0000e+02
  1.1999e-01  7.6250e-02  3.1159e-02  ...  -3.2504e-01 -1.0000e+02 -1.0000e+02
  1.1853e-01  7.4796e-02  2.9708e-02  ...  -3.2644e-01 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.2571e-01  8.1838e-02  3.3550e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2785e-01  8.3947e-02  3.5639e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2872e-01  8.4815e-02  3.6504e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2769e-01  8.3783e-02  3.5478e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2293e-01  7.9026e-02  3.0722e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2393e-01  8.0026e-02  3.1730e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x61 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 60, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.5254e-01  9.3288e-02  2.1332e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8693e-02  1.9572e-02 -5.2203e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8693e-02  1.9572e-02 -5.2203e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8693e-02  1.9572e-02 -5.2203e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8693e-02  1.9572e-02 -5.2203e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8693e-02  1.9572e-02 -5.2203e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.3785e-01  8.4406e-02  2.0217e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4899e-01  9.5524e-02  3.1315e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5139e-01  9.7930e-02  3.3725e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4511e-01  9.1652e-02  2.7466e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4051e-01  8.7044e-02  2.2851e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3653e-01  8.3067e-02  1.8877e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.3733e-01  9.4073e-02  4.3166e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4128e-01  9.7997e-02  4.7063e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4753e-01  1.0424e-01  5.3310e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.0460e-02  2.7301e-02 -2.3469e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0460e-02  2.7301e-02 -2.3469e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0460e-02  2.7301e-02 -2.3469e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.3690e-01  9.3675e-02  2.8921e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6574e-02  2.3461e-02 -4.1119e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6574e-02  2.3461e-02 -4.1119e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.6574e-02  2.3461e-02 -4.1119e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6574e-02  2.3461e-02 -4.1119e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6574e-02  2.3461e-02 -4.1119e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.4933e-01  8.8366e-02  2.6434e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1017e-02  2.0211e-02 -4.1520e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1017e-02  2.0211e-02 -4.1520e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.1017e-02  2.0211e-02 -4.1520e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1017e-02  2.0211e-02 -4.1520e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1017e-02  2.0211e-02 -4.1520e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.2668e-01  8.0422e-02  2.7105e-02  ...  -6.6634e-01 -6.1743e-01 -3.6232e-01
  1.3525e-01  8.8974e-02  3.5633e-02  ...  -6.5836e-01 -6.0939e-01 -3.5401e-01
  1.3654e-01  9.0263e-02  3.6915e-02  ...  -6.5698e-01 -6.0800e-01 -3.5266e-01
                 ...                   ⋱                   ...                
  5.9670e-02  1.3529e-02 -3.9644e-02  ...  -7.2817e-01 -6.7974e-01 -4.2653e-01
  5.9670e-02  1.3529e-02 -3.9644e-02  ...  -7.2817e-01 -6.7974e-01 -4.2653e-01
  5.9670e-02  1.3529e-02 -3.9644e-02  ...  -7.2817e-01 -6.7974e-01 -4.2653e-01
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 8, 0, 55, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.6310e-01  9.6851e-02  1.7774e-02  ...  -7.3065e-01 -4.8536e-01 -1.0000e+02
  1.7618e-01  1.0990e-01  3.0815e-02  ...  -7.1835e-01 -4.7278e-01 -1.0000e+02
  1.8627e-01  1.2000e-01  4.0914e-02  ...  -7.0866e-01 -4.6292e-01 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6877e-01  1.0250e-01  2.3430e-02  ...  -7.2521e-01 -4.7981e-01 -1.0000e+02
  6.9753e-02  3.6299e-03 -7.5230e-02  ...  -8.1716e-01 -5.7442e-01 -1.0000e+02
  6.9753e-02  3.6299e-03 -7.5230e-02  ...  -8.1716e-01 -5.7442e-01 -1.0000e+02

(1 ,.,.) = 
  1.6196e-01  7.9770e-02  1.3465e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0906e-02 -1.1163e-02 -7.7248e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0906e-02 -1.1163e-02 -7.7248e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.0906e-02 -1.1163e-02 -7.7248e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0906e-02 -1.1163e-02 -7.7248e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0906e-02 -1.1163e-02 -7.7248e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.6249e-01  9.5922e-02  7.7780e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6853e-01  1.0195e-01  1.3773e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7235e-01  1.0577e-01  1.7576e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3646e-02 -2.8203e-03 -9.0700e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3646e-02 -2.8203e-03 -9.0700e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3646e-02 -2.8203e-03 -9.0700e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.7285e-01  9.6679e-02  1.3549e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6957e-02  9.2815e-04 -8.1940e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6957e-02  9.2815e-04 -8.1940e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.6957e-02  9.2815e-04 -8.1940e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6957e-02  9.2815e-04 -8.1940e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6957e-02  9.2815e-04 -8.1940e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.7638e-01  1.0350e-01  1.5532e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3283e-02  5.1156e-04 -8.7212e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3283e-02  5.1156e-04 -8.7212e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.3283e-02  5.1156e-04 -8.7212e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3283e-02  5.1156e-04 -8.7212e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3283e-02  5.1156e-04 -8.7212e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.7274e-01  9.8454e-02  9.5574e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5696e-02  1.5357e-03 -8.7117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5696e-02  1.5357e-03 -8.7117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.5696e-02  1.5357e-03 -8.7117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5696e-02  1.5357e-03 -8.7117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5696e-02  1.5357e-03 -8.7117e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.2238e-01  1.2128e-01 -3.4453e-03  ...  -7.4342e-01 -1.0000e+02 -1.0000e+02
  7.8281e-02 -2.2719e-02 -1.4706e-01  ...  -8.7741e-01 -1.0000e+02 -1.0000e+02
  7.8281e-02 -2.2719e-02 -1.4706e-01  ...  -8.7741e-01 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8281e-02 -2.2719e-02 -1.4706e-01  ...  -8.7741e-01 -1.0000e+02 -1.0000e+02
  7.8281e-02 -2.2719e-02 -1.4706e-01  ...  -8.7741e-01 -1.0000e+02 -1.0000e+02
  7.8281e-02 -2.2719e-02 -1.4706e-01  ...  -8.7741e-01 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  2.2087e-01  1.2289e-01  2.9887e-02  ...  -9.6076e-01 -6.7056e-01 -1.0000e+02
  7.4417e-02 -2.3437e-02 -1.1613e-01  ...  -1.0932e+00 -8.0803e-01 -1.0000e+02
  7.4417e-02 -2.3437e-02 -1.1613e-01  ...  -1.0932e+00 -8.0803e-01 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4417e-02 -2.3437e-02 -1.1613e-01  ...  -1.0932e+00 -8.0803e-01 -1.0000e+02
  7.4417e-02 -2.3437e-02 -1.1613e-01  ...  -1.0932e+00 -8.0803e-01 -1.0000e+02
  7.4417e-02 -2.3437e-02 -1.1613e-01  ...  -1.0932e+00 -8.0803e-01 -1.0000e+02

(2 ,.,.) = 
  1.8695e-01  9.7054e-02 -1.9499e-02  ...  -6.3191e-01 -1.0000e+02 -1.0000e+02
  5.8505e-02 -3.1243e-02 -1.4746e-01  ...  -7.5304e-01 -1.0000e+02 -1.0000e+02
  5.8505e-02 -3.1243e-02 -1.4746e-01  ...  -7.5304e-01 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.8505e-02 -3.1243e-02 -1.4746e-01  ...  -7.5304e-01 -1.0000e+02 -1.0000e+02
  5.8505e-02 -3.1243e-02 -1.4746e-01  ...  -7.5304e-01 -1.0000e+02 -1.0000e+02
  5.8505e-02 -3.1243e-02 -1.4746e-01  ...  -7.5304e-01 -1.0000e+02 -1.0000e+02

(3 ,.,.) = 
  1.9617e-01  9.5693e-02 -5.4304e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1687e-02 -3.8666e-02 -1.3938e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1687e-02 -3.8666e-02 -1.3938e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.1687e-02 -3.8666e-02 -1.3938e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1687e-02 -3.8666e-02 -1.3938e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1687e-02 -3.8666e-02 -1.3938e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(4 ,.,.) = 
  2.0398e-01  9.9096e-02  7.8335e-04  ...  -1.0296e+00 -9.5280e-01 -6.6651e-01
  6.7785e-02 -3.6947e-02 -1.3490e-01  ...  -1.1506e+00 -1.0756e+00 -7.9416e-01
  6.7785e-02 -3.6947e-02 -1.3490e-01  ...  -1.1506e+00 -1.0756e+00 -7.9416e-01
                 ...                   ⋱                   ...                
  6.7785e-02 -3.6947e-02 -1.3490e-01  ...  -1.1506e+00 -1.0756e+00 -7.9416e-01
  6.7785e-02 -3.6947e-02 -1.3490e-01  ...  -1.1506e+00 -1.0756e+00 -7.9416e-01
  6.7785e-02 -3.6947e-02 -1.3490e-01  ...  -1.1506e+00 -1.0756e+00 -7.9416e-01

(5 ,.,.) = 
  1.9270e-01  1.0778e-01 -3.3348e-03  ...  -7.1505e-01 -1.0000e+02 -1.0000e+02
  2.1700e-01  1.3208e-01  2.0928e-02  ...  -6.9223e-01 -1.0000e+02 -1.0000e+02
  2.1927e-01  1.3434e-01  2.3189e-02  ...  -6.9006e-01 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.2214e-01  1.3722e-01  2.6076e-02  ...  -6.8692e-01 -1.0000e+02 -1.0000e+02
  2.1308e-01  1.2813e-01  1.6969e-02  ...  -6.9582e-01 -1.0000e+02 -1.0000e+02
  2.0056e-01  1.1560e-01  4.4366e-03  ...  -7.0776e-01 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x7x61 (GPU 0)]

 Loss = 10.3120519975
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  2.4091e-01  1.2013e-01 -2.8420e-02  ...  -1.2332e+00 -8.8567e-01 -1.0000e+02
  2.7768e-01  1.5698e-01  8.4617e-03  ...  -1.1996e+00 -8.5069e-01 -1.0000e+02
  2.8275e-01  1.6207e-01  1.3563e-02  ...  -1.1949e+00 -8.4582e-01 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.2551e+00 -9.0835e-01 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.2551e+00 -9.0835e-01 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.2551e+00 -9.0835e-01 -1.0000e+02

( 1 ,.,.) = 
  2.4123e-01  1.2045e-01 -2.8095e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7804e-01  1.5735e-01  8.8260e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8297e-01  1.6230e-01  1.3795e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5861e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5861e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5861e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.4384e-01  1.2307e-01 -2.5480e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8168e-01  1.6100e-01  1.2484e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8667e-01  1.6601e-01  1.7507e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.4832e-01  1.2756e-01 -2.0982e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8745e-01  1.6679e-01  1.8288e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.9233e-01  1.7169e-01  2.3208e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.5374e-01  1.3300e-01 -1.5537e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.9455e-01  1.7392e-01  2.5446e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.9921e-01  1.7860e-01  3.0139e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5860e-02 -5.2688e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2688e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2688e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  2.4582e-01  1.2505e-01 -2.3494e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8373e-01  1.6305e-01  1.4547e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8847e-01  1.6781e-01  1.9319e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.4925e-01  1.2849e-01 -2.0046e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8963e-01  1.6898e-01  2.0492e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.9507e-01  1.7445e-01  2.5975e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5858e-02 -5.2690e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5858e-02 -5.2690e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5858e-02 -5.2690e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.4164e-01  1.2087e-01 -2.7676e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7876e-01  1.5807e-01  9.5534e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8386e-01  1.6319e-01  1.4692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5862e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5862e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5862e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.4309e-01  1.2232e-01 -2.6230e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8095e-01  1.6027e-01  1.1750e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8616e-01  1.6549e-01  1.6994e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5859e-02 -5.2689e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5859e-02 -5.2689e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5859e-02 -5.2689e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.4365e-01  1.2288e-01 -2.5671e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8140e-01  1.6072e-01  1.2207e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8637e-01  1.6570e-01  1.7204e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5856e-02 -5.2694e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5856e-02 -5.2694e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5856e-02 -5.2694e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.3644e-01  1.1565e-01 -3.2897e-02  ...  -1.1478e+00 -8.1213e-01 -1.0000e+02
  2.7146e-01  1.5075e-01  2.2114e-03  ...  -1.1154e+00 -7.7855e-01 -1.0000e+02
  2.7657e-01  1.5587e-01  7.3488e-03  ...  -1.1106e+00 -7.7360e-01 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5858e-02 -5.2690e-02  ...  -1.1659e+00 -8.3078e-01 -1.0000e+02
  2.1670e-01  9.5858e-02 -5.2690e-02  ...  -1.1659e+00 -8.3078e-01 -1.0000e+02
  2.1670e-01  9.5858e-02 -5.2690e-02  ...  -1.1659e+00 -8.3078e-01 -1.0000e+02

(14 ,.,.) = 
  2.3970e-01  1.1892e-01 -2.9644e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7623e-01  1.5553e-01  6.9895e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8125e-01  1.6057e-01  1.2049e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.3862e-01  1.1783e-01 -3.0716e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7473e-01  1.5402e-01  5.4945e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7987e-01  1.5919e-01  1.0672e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5863e-02 -5.2684e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5863e-02 -5.2684e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5863e-02 -5.2684e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.4441e-01  1.2364e-01 -2.4908e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8246e-01  1.6178e-01  1.3270e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8745e-01  1.6679e-01  1.8289e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.3714e-01  1.1635e-01 -3.2196e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7279e-01  1.5208e-01  3.5475e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7792e-01  1.5722e-01  8.7014e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5856e-02 -5.2693e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5856e-02 -5.2693e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5856e-02 -5.2693e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.4533e-01  1.2456e-01 -2.3986e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8378e-01  1.6311e-01  1.4594e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8870e-01  1.6804e-01  1.9545e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.4065e-01  1.1988e-01 -2.8671e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7720e-01  1.5651e-01  7.9852e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8216e-01  1.6148e-01  1.2977e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5862e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5862e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5862e-02 -5.2685e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  2.4568e-01  1.2491e-01 -2.3650e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8410e-01  1.6342e-01  1.4903e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8895e-01  1.6829e-01  1.9794e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.3942e-01  1.1864e-01 -2.9910e-02  ...  -1.2751e+00 -1.2082e+00 -8.6644e-01
  2.7574e-01  1.5504e-01  6.5122e-03  ...  -1.2422e+00 -1.1750e+00 -8.3184e-01
  2.8081e-01  1.6012e-01  1.1607e-02  ...  -1.2375e+00 -1.1703e+00 -8.2698e-01
                 ...                   ⋱                   ...                
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.2955e+00 -1.2289e+00 -8.8780e-01
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.2955e+00 -1.2289e+00 -8.8780e-01
  2.1670e-01  9.5855e-02 -5.2695e-02  ...  -1.2955e+00 -1.2289e+00 -8.8780e-01

( 1 ,.,.) = 
  2.3984e-01  1.1906e-01 -2.9485e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7658e-01  1.5588e-01  7.3568e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8180e-01  1.6112e-01  1.2608e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5859e-02 -5.2689e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5859e-02 -5.2689e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5859e-02 -5.2689e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.4199e-01  1.2121e-01 -2.7339e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7922e-01  1.5853e-01  1.0013e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8424e-01  1.6357e-01  1.5067e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5860e-02 -5.2688e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2688e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2688e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  2.4218e-01  1.2139e-01 -2.7167e-02  ...  -1.4341e+00 -1.3654e+00 -9.4684e-01
  2.7948e-01  1.5879e-01  1.0258e-02  ...  -1.4009e+00 -1.3318e+00 -9.1154e-01
  2.8441e-01  1.6373e-01  1.5217e-02  ...  -1.3964e+00 -1.3273e+00 -9.0679e-01
                 ...                   ⋱                   ...                
  2.1670e-01  9.5855e-02 -5.2694e-02  ...  -1.4562e+00 -1.3877e+00 -9.7042e-01
  2.1670e-01  9.5855e-02 -5.2694e-02  ...  -1.4562e+00 -1.3877e+00 -9.7042e-01
  2.1670e-01  9.5855e-02 -5.2694e-02  ...  -1.4562e+00 -1.3877e+00 -9.7042e-01

( 4 ,.,.) = 
  2.3521e-01  1.1442e-01 -3.4126e-02  ...  -8.2000e-01 -1.0000e+02 -1.0000e+02
  2.7014e-01  1.4943e-01  8.9017e-04  ...  -7.8658e-01 -1.0000e+02 -1.0000e+02
  2.7533e-01  1.5462e-01  6.1025e-03  ...  -7.8158e-01 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -8.3749e-01 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -8.3749e-01 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5857e-02 -5.2692e-02  ...  -8.3749e-01 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  2.3876e-01  1.1798e-01 -3.0568e-02  ...  -8.5127e-01 -1.0000e+02 -1.0000e+02
  2.7460e-01  1.5389e-01  5.3632e-03  ...  -8.1704e-01 -1.0000e+02 -1.0000e+02
  2.7965e-01  1.5896e-01  1.0444e-02  ...  -8.1217e-01 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -8.7204e-01 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -8.7204e-01 -1.0000e+02 -1.0000e+02
  2.1670e-01  9.5860e-02 -5.2687e-02  ...  -8.7204e-01 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  2.3527e-01  1.0962e-01 -4.5409e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7400e-01  1.4846e-01 -6.5466e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7931e-01  1.5378e-01 -1.2047e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0749e-01  8.1777e-02 -7.3246e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1777e-02 -7.3246e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1777e-02 -7.3246e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.2989e-01  1.0423e-01 -5.0808e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6770e-01  1.4212e-01 -1.2905e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7361e-01  1.4806e-01 -6.9502e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0750e-01  8.1795e-02 -7.3220e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0750e-01  8.1795e-02 -7.3220e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0750e-01  8.1795e-02 -7.3220e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.3545e-01  1.0981e-01 -4.5232e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7421e-01  1.4866e-01 -6.3522e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7950e-01  1.5397e-01 -1.0203e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0748e-01  8.1763e-02 -7.3266e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0748e-01  8.1763e-02 -7.3266e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0748e-01  8.1763e-02 -7.3266e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.3205e-01  1.0640e-01 -4.8633e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6961e-01  1.4405e-01 -1.0964e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7496e-01  1.4941e-01 -5.5780e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0749e-01  8.1783e-02 -7.3237e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1783e-02 -7.3237e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1783e-02 -7.3237e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.3859e-01  1.1295e-01 -4.2084e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7770e-01  1.5216e-01 -2.8340e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8258e-01  1.5706e-01  2.0840e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0748e-01  8.1767e-02 -7.3260e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0748e-01  8.1767e-02 -7.3260e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0748e-01  8.1767e-02 -7.3260e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  2.3527e-01  1.0962e-01 -4.5409e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7400e-01  1.4846e-01 -6.5466e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7931e-01  1.5378e-01 -1.2047e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0749e-01  8.1777e-02 -7.3246e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1777e-02 -7.3246e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1777e-02 -7.3246e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.3438e-01  1.0874e-01 -4.6281e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7311e-01  1.4757e-01 -7.4243e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7868e-01  1.5315e-01 -1.8223e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0750e-01  8.1790e-02 -7.3227e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0750e-01  8.1790e-02 -7.3227e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0750e-01  8.1790e-02 -7.3227e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.3438e-01  1.0874e-01 -4.6281e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7311e-01  1.4757e-01 -7.4243e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7868e-01  1.5315e-01 -1.8223e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0750e-01  8.1790e-02 -7.3227e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0750e-01  8.1790e-02 -7.3227e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0750e-01  8.1790e-02 -7.3227e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.3352e-01  1.0788e-01 -4.7153e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7192e-01  1.4637e-01 -8.6394e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7750e-01  1.5196e-01 -3.0280e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0749e-01  8.1772e-02 -7.3253e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1772e-02 -7.3253e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1772e-02 -7.3253e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  2.3499e-01  1.0934e-01 -4.5689e-02  ...  -1.4435e+00 -1.2712e+00 -9.1808e-01
  2.7303e-01  1.4748e-01 -7.5263e-03  ...  -1.4096e+00 -1.2367e+00 -8.8200e-01
  2.7807e-01  1.5254e-01 -2.4486e-03  ...  -1.4050e+00 -1.2320e+00 -8.7718e-01
                 ...                   ⋱                   ...                
  2.0748e-01  8.1767e-02 -7.3261e-02  ...  -1.4675e+00 -1.2960e+00 -9.4377e-01
  2.0748e-01  8.1767e-02 -7.3261e-02  ...  -1.4675e+00 -1.2960e+00 -9.4377e-01
  2.0748e-01  8.1767e-02 -7.3261e-02  ...  -1.4675e+00 -1.2960e+00 -9.4377e-01

( 4 ,.,.) = 
  2.2909e-01  1.0343e-01 -5.1601e-02  ...  -1.2409e+00 -9.0322e-01 -1.0000e+02
  2.6565e-01  1.4007e-01 -1.4944e-02  ...  -1.2077e+00 -8.6858e-01 -1.0000e+02
  2.7107e-01  1.4552e-01 -9.4859e-03  ...  -1.2027e+00 -8.6339e-01 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0749e-01  8.1778e-02 -7.3245e-02  ...  -1.2605e+00 -9.2344e-01 -1.0000e+02
  2.0749e-01  8.1778e-02 -7.3245e-02  ...  -1.2605e+00 -9.2344e-01 -1.0000e+02
  2.0749e-01  8.1778e-02 -7.3245e-02  ...  -1.2605e+00 -9.2344e-01 -1.0000e+02

( 5 ,.,.) = 
  2.3675e-01  1.1111e-01 -4.3919e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7551e-01  1.4997e-01 -5.0280e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8060e-01  1.5508e-01  9.6266e-05  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.0749e-01  8.1772e-02 -7.3254e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1772e-02 -7.3254e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0749e-01  8.1772e-02 -7.3254e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 4 @ 2018-04-12 20:35:57.093457
training
gt_where_seq [[7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.2787e-01  1.1339e-01 -5.4405e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6250e-01  1.4810e-01 -1.9654e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6085e-01  1.4642e-01 -2.1367e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.7788e-02 -6.6540e-02 -2.3360e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.7788e-02 -6.6540e-02 -2.3360e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.7788e-02 -6.6540e-02 -2.3360e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  2.5791e-01  1.3796e-01 -8.8613e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5996e-02 -7.3863e-02 -2.2018e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5996e-02 -7.3863e-02 -2.2018e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5996e-02 -7.3863e-02 -2.2018e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5996e-02 -7.3863e-02 -2.2018e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5996e-02 -7.3863e-02 -2.2018e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.4485e-01  1.2063e-01 -2.4909e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5627e-02 -6.8433e-02 -2.1339e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5627e-02 -6.8433e-02 -2.1339e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.5627e-02 -6.8433e-02 -2.1339e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5627e-02 -6.8433e-02 -2.1339e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5627e-02 -6.8433e-02 -2.1339e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  2.3405e-01  1.3405e-01  1.1023e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7423e-01  1.7429e-01  4.1362e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6650e-01  1.6653e-01  3.3570e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6738e-02 -5.3111e-02 -1.8558e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6738e-02 -5.3111e-02 -1.8558e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6738e-02 -5.3111e-02 -1.8558e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  2.5383e-01  1.3542e-01 -1.1318e-02  ...  -1.2780e+00 -1.1432e+00 -7.8328e-01
  5.8214e-02 -6.0109e-02 -2.0629e-01  ...  -1.4467e+00 -1.3163e+00 -9.6498e-01
  5.8214e-02 -6.0109e-02 -2.0629e-01  ...  -1.4467e+00 -1.3163e+00 -9.6498e-01
                 ...                   ⋱                   ...                
  5.8214e-02 -6.0109e-02 -2.0629e-01  ...  -1.4467e+00 -1.3163e+00 -9.6498e-01
  5.8214e-02 -6.0109e-02 -2.0629e-01  ...  -1.4467e+00 -1.3163e+00 -9.6498e-01
  5.8214e-02 -6.0109e-02 -2.0629e-01  ...  -1.4467e+00 -1.3163e+00 -9.6498e-01

(14,.,.) = 
  2.2844e-01  1.1113e-01 -5.1916e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0161e-02 -6.7000e-02 -2.2937e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0161e-02 -6.7000e-02 -2.2937e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.0161e-02 -6.7000e-02 -2.2937e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0161e-02 -6.7000e-02 -2.2937e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0161e-02 -6.7000e-02 -2.2937e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x61 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 0, 18, 0, 56, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.0533e-01  1.3828e-01 -5.0834e-02  ...  -1.5950e+00 -1.1883e+00 -1.0000e+02
  3.1281e-02 -1.3571e-01 -3.2386e-01  ...  -1.8221e+00 -1.4312e+00 -1.0000e+02
  3.1281e-02 -1.3571e-01 -3.2386e-01  ...  -1.8221e+00 -1.4312e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  3.1281e-02 -1.3571e-01 -3.2386e-01  ...  -1.8221e+00 -1.4312e+00 -1.0000e+02
  3.1281e-02 -1.3571e-01 -3.2386e-01  ...  -1.8221e+00 -1.4312e+00 -1.0000e+02
  3.1281e-02 -1.3571e-01 -3.2386e-01  ...  -1.8221e+00 -1.4312e+00 -1.0000e+02

(1 ,.,.) = 
  2.9011e-01  1.1534e-01 -7.1687e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2983e-01  1.5525e-01 -3.1711e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3894e-01  1.6440e-01 -2.2530e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.9687e-01  1.2207e-01 -6.4993e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4133e-02 -1.5048e-01 -3.3650e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4133e-02 -1.5048e-01 -3.3650e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.4980e-01  9.2647e-02 -8.0690e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.9727e-01  1.4022e-01 -3.3104e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2243e-01  1.6551e-01 -7.7493e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.0678e-01  1.4975e-01 -2.3578e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.8723e-01  1.3013e-01 -4.3233e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5032e-01  9.3109e-02 -8.0291e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  2.8092e-01  1.3855e-01 -3.9815e-02  ...  -1.5684e+00 -1.5707e+00 -1.0591e+00
  3.3836e-01  1.9619e-01  1.7962e-02  ...  -1.5170e+00 -1.5193e+00 -1.0046e+00
  3.5473e-01  2.1265e-01  3.4522e-02  ...  -1.5020e+00 -1.5044e+00 -9.8880e-01
                 ...                   ⋱                   ...                
  3.2342e-01  1.8117e-01  2.9201e-03  ...  -1.5303e+00 -1.5329e+00 -1.0187e+00
  3.6168e-02 -1.0607e-01 -2.8364e-01  ...  -1.7728e+00 -1.7760e+00 -1.2802e+00
  3.6168e-02 -1.0607e-01 -2.8364e-01  ...  -1.7728e+00 -1.7760e+00 -1.2802e+00

(13,.,.) = 
  2.2951e-01  7.1401e-02 -1.1739e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -6.8705e-04 -1.5855e-01 -3.4624e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -6.8705e-04 -1.5855e-01 -3.4624e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -6.8705e-04 -1.5855e-01 -3.4624e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -6.8705e-04 -1.5855e-01 -3.4624e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -6.8705e-04 -1.5855e-01 -3.4624e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.7560e-01  1.1402e-01 -7.8299e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2866e-01  1.6728e-01 -2.4965e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3288e-01  1.7149e-01 -2.0744e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.0699e-01  1.4551e-01 -4.6759e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0776e-02 -1.4063e-01 -3.3196e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0776e-02 -1.4063e-01 -3.3196e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 14, 0, 54, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.3314e-01  1.4570e-01 -9.8788e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.1814e-01  2.3129e-01 -1.2858e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3747e-01  2.5080e-01  6.8435e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.3505e-01  1.4760e-01 -9.6845e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2108e-02 -1.9949e-01 -4.4227e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2108e-02 -1.9949e-01 -4.4227e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.0533e-01  1.1177e-01 -1.0704e-01  ...  -2.0027e+00 -1.4044e+00 -1.0000e+02
 -3.8438e-03 -1.9727e-01 -4.1455e-01  ...  -2.2437e+00 -1.6725e+00 -1.0000e+02
 -3.8438e-03 -1.9727e-01 -4.1455e-01  ...  -2.2437e+00 -1.6725e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.8438e-03 -1.9727e-01 -4.1455e-01  ...  -2.2437e+00 -1.6725e+00 -1.0000e+02
 -3.8438e-03 -1.9727e-01 -4.1455e-01  ...  -2.2437e+00 -1.6725e+00 -1.0000e+02
 -3.8438e-03 -1.9727e-01 -4.1455e-01  ...  -2.2437e+00 -1.6725e+00 -1.0000e+02

(2 ,.,.) = 
  3.1747e-01  1.1153e-01 -1.3594e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9912e-01  1.9380e-01 -5.3299e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.1660e-01  2.1139e-01 -3.5654e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.1666e-01  1.1074e-01 -1.3664e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.0405e-01  9.8053e-02 -1.4936e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.9207e-01  8.6021e-02 -1.6140e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.9986e-01  1.8400e-01 -8.0093e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9714e-02 -1.9648e-01 -4.5874e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9714e-02 -1.9648e-01 -4.5874e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.9714e-02 -1.9648e-01 -4.5874e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9714e-02 -1.9648e-01 -4.5874e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9714e-02 -1.9648e-01 -4.5874e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.4271e-01  1.4563e-01 -1.0929e-01  ...  -1.7219e+00 -1.2602e+00 -1.0000e+02
 -1.4490e-02 -2.1148e-01 -4.6445e-01  ...  -2.0159e+00 -1.5765e+00 -1.0000e+02
 -1.4490e-02 -2.1148e-01 -4.6445e-01  ...  -2.0159e+00 -1.5765e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -1.4490e-02 -2.1148e-01 -4.6445e-01  ...  -2.0159e+00 -1.5765e+00 -1.0000e+02
 -1.4490e-02 -2.1148e-01 -4.6445e-01  ...  -2.0159e+00 -1.5765e+00 -1.0000e+02
 -1.4490e-02 -2.1148e-01 -4.6445e-01  ...  -2.0159e+00 -1.5765e+00 -1.0000e+02

(14,.,.) = 
  3.2839e-01  1.3061e-01 -1.1970e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2715e-02 -2.4036e-01 -4.8864e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2715e-02 -2.4036e-01 -4.8864e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -4.2715e-02 -2.4036e-01 -4.8864e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2715e-02 -2.4036e-01 -4.8864e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2715e-02 -2.4036e-01 -4.8864e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.3828    0.1426   -0.1920  ...    -2.1488   -2.0516   -1.4990
    0.4985    0.2593   -0.0748  ...    -2.0509   -1.9525   -1.3920
    0.5221    0.2832   -0.0508  ...    -2.0310   -1.9323   -1.3702
              ...                ⋱                ...             
    0.4831    0.2438   -0.0904  ...    -2.0656   -1.9674   -1.4076
    0.4349    0.1950   -0.1394  ...    -2.1070   -2.0092   -1.4525
    0.3843    0.1440   -0.1906  ...    -2.1505   -2.0532   -1.4999

(1 ,.,.) = 
    0.3896    0.1103   -0.2369  ...  -100.0000 -100.0000 -100.0000
   -0.0727   -0.3519   -0.6947  ...  -100.0000 -100.0000 -100.0000
   -0.0727   -0.3519   -0.6947  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0727   -0.3519   -0.6947  ...  -100.0000 -100.0000 -100.0000
   -0.0727   -0.3519   -0.6947  ...  -100.0000 -100.0000 -100.0000
   -0.0727   -0.3519   -0.6947  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    0.3352    0.0575   -0.2600  ...  -100.0000 -100.0000 -100.0000
    0.4689    0.1926   -0.1246  ...  -100.0000 -100.0000 -100.0000
    0.4958    0.2196   -0.0976  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.4482    0.1714   -0.1461  ...  -100.0000 -100.0000 -100.0000
   -0.1104   -0.3873   -0.7006  ...  -100.0000 -100.0000 -100.0000
   -0.1104   -0.3873   -0.7006  ...  -100.0000 -100.0000 -100.0000

(3 ,.,.) = 
    0.3526    0.0684   -0.2636  ...    -2.1711   -1.5625 -100.0000
   -0.0707   -0.3544   -0.6823  ...    -2.4957   -1.9244 -100.0000
   -0.0707   -0.3544   -0.6823  ...    -2.4957   -1.9244 -100.0000
              ...                ⋱                ...             
   -0.0707   -0.3544   -0.6823  ...    -2.4957   -1.9244 -100.0000
   -0.0707   -0.3544   -0.6823  ...    -2.4957   -1.9244 -100.0000
   -0.0707   -0.3544   -0.6823  ...    -2.4957   -1.9244 -100.0000

(4 ,.,.) = 
    0.3735    0.0910   -0.2185  ...  -100.0000 -100.0000 -100.0000
   -0.0845   -0.3664   -0.6719  ...  -100.0000 -100.0000 -100.0000
   -0.0845   -0.3664   -0.6719  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0845   -0.3664   -0.6719  ...  -100.0000 -100.0000 -100.0000
   -0.0845   -0.3664   -0.6719  ...  -100.0000 -100.0000 -100.0000
   -0.0845   -0.3664   -0.6719  ...  -100.0000 -100.0000 -100.0000

(5 ,.,.) = 
    0.3372    0.0957   -0.2574  ...  -100.0000 -100.0000 -100.0000
   -0.0801   -0.3213   -0.6702  ...  -100.0000 -100.0000 -100.0000
   -0.0801   -0.3213   -0.6702  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0801   -0.3213   -0.6702  ...  -100.0000 -100.0000 -100.0000
   -0.0801   -0.3213   -0.6702  ...  -100.0000 -100.0000 -100.0000
   -0.0801   -0.3213   -0.6702  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x7x62 (GPU 0)]

 Loss = 7.68960100062
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.2977e-01  8.7018e-02 -3.3651e-01  ...  -2.4395e+00 -1.8286e+00 -1.0000e+02
  6.2032e-01  2.8041e-01 -1.4204e-01  ...  -2.2795e+00 -1.6536e+00 -1.0000e+02
  6.7676e-01  3.3796e-01 -8.3792e-02  ...  -2.2302e+00 -1.6002e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7609e-01 -6.7843e-02 -4.9070e-01  ...  -2.5614e+00 -1.9634e+00 -1.0000e+02
  2.7609e-01 -6.7843e-02 -4.9070e-01  ...  -2.5614e+00 -1.9634e+00 -1.0000e+02
  2.7609e-01 -6.7843e-02 -4.9070e-01  ...  -2.5614e+00 -1.9634e+00 -1.0000e+02

( 1 ,.,.) = 
  4.3739e-01  9.4750e-02 -3.2873e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3151e-01  2.9185e-01 -1.3045e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8919e-01  3.5068e-01 -7.0864e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7619e-01 -6.7715e-02 -4.9055e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7619e-01 -6.7715e-02 -4.9055e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7619e-01 -6.7715e-02 -4.9055e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.4029e-01  9.7660e-02 -3.2585e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3596e-01  2.9637e-01 -1.2590e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9456e-01  3.5615e-01 -6.5340e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7609e-01 -6.7845e-02 -4.9071e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7609e-01 -6.7845e-02 -4.9071e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7609e-01 -6.7845e-02 -4.9071e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.5766e-01  1.1525e-01 -3.0822e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6099e-01  3.2193e-01 -1.0002e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2310e-01  3.8537e-01 -3.5664e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7613e-01 -6.7798e-02 -4.9065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7798e-02 -4.9065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7798e-02 -4.9065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.6778e-01  1.2552e-01 -2.9791e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7452e-01  3.3577e-01 -8.5963e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3683e-01  3.9944e-01 -2.1327e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7617e-01 -6.7746e-02 -4.9059e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7617e-01 -6.7746e-02 -4.9059e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7617e-01 -6.7746e-02 -4.9059e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.4741e-01  1.0490e-01 -3.1857e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4385e-01  3.0445e-01 -1.1768e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0190e-01  3.6369e-01 -5.7646e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7616e-01 -6.7747e-02 -4.9059e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7616e-01 -6.7747e-02 -4.9059e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7616e-01 -6.7747e-02 -4.9059e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.5591e-01  1.1348e-01 -3.1000e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5972e-01  3.2064e-01 -1.0131e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2183e-01  3.8407e-01 -3.6963e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7612e-01 -6.7806e-02 -4.9066e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7612e-01 -6.7806e-02 -4.9066e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7612e-01 -6.7806e-02 -4.9066e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.3673e-01  9.4098e-02 -3.2937e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3061e-01  2.9096e-01 -1.3132e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8820e-01  3.4970e-01 -7.1826e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7618e-01 -6.7720e-02 -4.9056e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7618e-01 -6.7720e-02 -4.9056e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7618e-01 -6.7720e-02 -4.9056e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.3761e-01  9.4957e-02 -3.2855e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3268e-01  2.9302e-01 -1.2928e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9122e-01  3.5274e-01 -6.8789e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7613e-01 -6.7791e-02 -4.9064e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7791e-02 -4.9064e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7791e-02 -4.9064e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.3892e-01  9.6273e-02 -3.2723e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3372e-01  2.9408e-01 -1.2820e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9189e-01  3.5342e-01 -6.8093e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7610e-01 -6.7835e-02 -4.9070e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7610e-01 -6.7835e-02 -4.9070e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7610e-01 -6.7835e-02 -4.9070e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.1286e-01  6.9938e-02 -3.5356e-01  ...  -2.3401e+00 -1.7355e+00 -1.0000e+02
  5.9336e-01  2.5296e-01 -1.6975e-01  ...  -2.1863e+00 -1.5682e+00 -1.0000e+02
  6.4531e-01  3.0586e-01 -1.1627e-01  ...  -2.1404e+00 -1.5188e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7613e-01 -6.7794e-02 -4.9065e-01  ...  -2.4510e+00 -1.8570e+00 -1.0000e+02
  2.7613e-01 -6.7794e-02 -4.9065e-01  ...  -2.4510e+00 -1.8570e+00 -1.0000e+02
  2.7613e-01 -6.7794e-02 -4.9065e-01  ...  -2.4510e+00 -1.8570e+00 -1.0000e+02

(14 ,.,.) = 
  4.3055e-01  8.7795e-02 -3.3574e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2207e-01  2.8219e-01 -1.4026e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7853e-01  3.3977e-01 -8.1955e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7613e-01 -6.7800e-02 -4.9066e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7800e-02 -4.9066e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7800e-02 -4.9066e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.2808e-01  8.5341e-02 -3.3815e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1877e-01  2.7887e-01 -1.4359e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7567e-01  3.3687e-01 -8.4866e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7622e-01 -6.7667e-02 -4.9050e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7622e-01 -6.7667e-02 -4.9050e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7622e-01 -6.7667e-02 -4.9050e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.4191e-01  9.9292e-02 -3.2422e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3846e-01  2.9891e-01 -1.2333e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9756e-01  3.5921e-01 -6.2235e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7609e-01 -6.7849e-02 -4.9071e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7609e-01 -6.7849e-02 -4.9071e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7609e-01 -6.7849e-02 -4.9071e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.2054e-01  7.7685e-02 -3.4583e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0781e-01  2.6766e-01 -1.5493e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6325e-01  3.2416e-01 -9.7775e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7611e-01 -6.7821e-02 -4.9068e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7611e-01 -6.7821e-02 -4.9068e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7611e-01 -6.7821e-02 -4.9068e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.4081e-01  9.8191e-02 -3.2533e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3697e-01  2.9738e-01 -1.2490e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9569e-01  3.5729e-01 -6.4197e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7617e-01 -6.7733e-02 -4.9058e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7617e-01 -6.7733e-02 -4.9058e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7617e-01 -6.7733e-02 -4.9058e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.3058e-01  8.7871e-02 -3.3561e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2131e-01  2.8146e-01 -1.4094e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7771e-01  3.3897e-01 -8.2724e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7619e-01 -6.7708e-02 -4.9055e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7619e-01 -6.7708e-02 -4.9055e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7619e-01 -6.7708e-02 -4.9055e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.4202e-01  9.9402e-02 -3.2413e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3868e-01  2.9914e-01 -1.2311e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9720e-01  3.5886e-01 -6.2575e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7613e-01 -6.7792e-02 -4.9065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7792e-02 -4.9065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7613e-01 -6.7792e-02 -4.9065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.2492e-01  8.2102e-02 -3.4143e-01  ...  -2.5412e+00 -2.4082e+00 -1.8053e+00
  6.1308e-01  2.7302e-01 -1.4952e-01  ...  -2.3859e+00 -2.2496e+00 -1.6322e+00
  6.6842e-01  3.2943e-01 -9.2444e-02  ...  -2.3383e+00 -2.2011e+00 -1.5799e+00
                 ...                   ⋱                   ...                
  2.7609e-01 -6.7851e-02 -4.9072e-01  ...  -2.6568e+00 -2.5270e+00 -1.9362e+00
  2.7609e-01 -6.7851e-02 -4.9072e-01  ...  -2.6568e+00 -2.5270e+00 -1.9362e+00
  2.7609e-01 -6.7851e-02 -4.9072e-01  ...  -2.6568e+00 -2.5270e+00 -1.9362e+00

( 1 ,.,.) = 
  4.2724e-01  8.4481e-02 -3.3903e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1826e-01  2.7833e-01 -1.4413e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7540e-01  3.3659e-01 -8.5157e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7615e-01 -6.7771e-02 -4.9062e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7615e-01 -6.7771e-02 -4.9062e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7615e-01 -6.7771e-02 -4.9062e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.3506e-01  9.2395e-02 -3.3110e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2793e-01  2.8820e-01 -1.3413e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8478e-01  3.4618e-01 -7.5419e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7616e-01 -6.7753e-02 -4.9060e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7616e-01 -6.7753e-02 -4.9060e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7616e-01 -6.7753e-02 -4.9060e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  4.3513e-01  9.2416e-02 -3.3112e-01  ...  -2.7659e+00 -2.6051e+00 -1.8977e+00
  6.2884e-01  2.8909e-01 -1.3329e-01  ...  -2.6125e+00 -2.4467e+00 -1.7209e+00
  6.8621e-01  3.4760e-01 -7.4012e-02  ...  -2.5648e+00 -2.3977e+00 -1.6668e+00
                 ...                   ⋱                   ...                
  2.7609e-01 -6.7846e-02 -4.9071e-01  ...  -2.8832e+00 -2.7267e+00 -2.0358e+00
  2.7609e-01 -6.7846e-02 -4.9071e-01  ...  -2.8832e+00 -2.7267e+00 -2.0358e+00
  2.7609e-01 -6.7846e-02 -4.9071e-01  ...  -2.8832e+00 -2.7267e+00 -2.0358e+00

( 4 ,.,.) = 
  4.1179e-01  6.8860e-02 -3.5464e-01  ...  -1.7385e+00 -1.0000e+02 -1.0000e+02
  5.9431e-01  2.5393e-01 -1.6877e-01  ...  -1.5696e+00 -1.0000e+02 -1.0000e+02
  6.4782e-01  3.0843e-01 -1.1368e-01  ...  -1.5188e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7612e-01 -6.7801e-02 -4.9066e-01  ...  -1.8590e+00 -1.0000e+02 -1.0000e+02
  2.7612e-01 -6.7801e-02 -4.9066e-01  ...  -1.8590e+00 -1.0000e+02 -1.0000e+02
  2.7612e-01 -6.7801e-02 -4.9066e-01  ...  -1.8590e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  4.2155e-01  7.8734e-02 -3.4476e-01  ...  -1.7832e+00 -1.0000e+02 -1.0000e+02
  6.0683e-01  2.6669e-01 -1.5588e-01  ...  -1.6122e+00 -1.0000e+02 -1.0000e+02
  6.6079e-01  3.2167e-01 -1.0026e-01  ...  -1.5611e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7616e-01 -6.7750e-02 -4.9059e-01  ...  -1.9117e+00 -1.0000e+02 -1.0000e+02
  2.7616e-01 -6.7750e-02 -4.9059e-01  ...  -1.9117e+00 -1.0000e+02 -1.0000e+02
  2.7616e-01 -6.7750e-02 -4.9059e-01  ...  -1.9117e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.0470e-01  4.8615e-02 -3.8677e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0382e-01  2.5071e-01 -1.8377e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6450e-01  3.1262e-01 -1.2111e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4040e-01 -1.1683e-01 -5.5124e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4040e-01 -1.1683e-01 -5.5124e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4040e-01 -1.1683e-01 -5.5124e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.8732e-01  3.1096e-02 -4.0428e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8189e-01  2.2839e-01 -2.0633e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4175e-01  2.8942e-01 -1.4462e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4068e-01 -1.1647e-01 -5.5083e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4068e-01 -1.1647e-01 -5.5083e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4068e-01 -1.1647e-01 -5.5083e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.0539e-01  4.9254e-02 -3.8617e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0451e-01  2.5136e-01 -1.8315e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6535e-01  3.1343e-01 -1.2033e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4022e-01 -1.1707e-01 -5.5151e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4022e-01 -1.1707e-01 -5.5151e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4022e-01 -1.1707e-01 -5.5151e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.9242e-01  3.6223e-02 -3.9914e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8583e-01  2.3239e-01 -2.0226e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4443e-01  2.9213e-01 -1.4187e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4047e-01 -1.1674e-01 -5.5114e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4047e-01 -1.1674e-01 -5.5114e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4047e-01 -1.1674e-01 -5.5114e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.1258e-01  5.6556e-02 -3.7884e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1276e-01  2.5981e-01 -1.7458e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7337e-01  3.2167e-01 -1.1196e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4031e-01 -1.1696e-01 -5.5139e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4031e-01 -1.1696e-01 -5.5139e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4031e-01 -1.1696e-01 -5.5139e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.0470e-01  4.8615e-02 -3.8677e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0382e-01  2.5071e-01 -1.8377e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6450e-01  3.1262e-01 -1.2111e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4040e-01 -1.1683e-01 -5.5124e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4040e-01 -1.1683e-01 -5.5124e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4040e-01 -1.1683e-01 -5.5124e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.0149e-01  4.5446e-02 -3.8990e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9968e-01  2.4657e-01 -1.8790e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6064e-01  3.0875e-01 -1.2499e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4062e-01 -1.1655e-01 -5.5093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4062e-01 -1.1655e-01 -5.5093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4062e-01 -1.1655e-01 -5.5093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.0149e-01  4.5446e-02 -3.8990e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9968e-01  2.4657e-01 -1.8790e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6064e-01  3.0875e-01 -1.2499e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4062e-01 -1.1655e-01 -5.5093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4062e-01 -1.1655e-01 -5.5093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4062e-01 -1.1655e-01 -5.5093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.9831e-01  4.2145e-02 -3.9325e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9489e-01  2.4160e-01 -1.9297e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5514e-01  3.0305e-01 -1.3082e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4034e-01 -1.1691e-01 -5.5133e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4034e-01 -1.1691e-01 -5.5133e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4034e-01 -1.1691e-01 -5.5133e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  4.0115e-01  4.4973e-02 -3.9041e-01  ...  -2.7505e+00 -2.4686e+00 -1.8558e+00
  5.9571e-01  2.4241e-01 -1.9213e-01  ...  -2.5957e+00 -2.3059e+00 -1.6777e+00
  6.5357e-01  3.0141e-01 -1.3246e-01  ...  -2.5475e+00 -2.2556e+00 -1.6233e+00
                 ...                   ⋱                   ...                
  2.4013e-01 -1.1719e-01 -5.5164e-01  ...  -2.8700e+00 -2.5959e+00 -1.9965e+00
  2.4013e-01 -1.1719e-01 -5.5164e-01  ...  -2.8700e+00 -2.5959e+00 -1.9965e+00
  2.4013e-01 -1.1719e-01 -5.5164e-01  ...  -2.8700e+00 -2.5959e+00 -1.9965e+00

( 4 ,.,.) = 
  3.8437e-01  2.8048e-02 -4.0732e-01  ...  -2.4259e+00 -1.8251e+00 -1.0000e+02
  5.7364e-01  2.1992e-01 -2.1488e-01  ...  -2.2676e+00 -1.6520e+00 -1.0000e+02
  6.3043e-01  2.7779e-01 -1.5640e-01  ...  -2.2182e+00 -1.5986e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4032e-01 -1.1694e-01 -5.5136e-01  ...  -2.5406e+00 -1.9515e+00 -1.0000e+02
  2.4032e-01 -1.1694e-01 -5.5136e-01  ...  -2.5406e+00 -1.9515e+00 -1.0000e+02
  2.4032e-01 -1.1694e-01 -5.5136e-01  ...  -2.5406e+00 -1.9515e+00 -1.0000e+02

( 5 ,.,.) = 
  4.0696e-01  5.0885e-02 -3.8450e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0475e-01  2.5166e-01 -1.8280e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6415e-01  3.1225e-01 -1.2148e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4033e-01 -1.1693e-01 -5.5135e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4033e-01 -1.1693e-01 -5.5135e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4033e-01 -1.1693e-01 -5.5135e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 5 @ 2018-04-12 20:35:59.441128
training
gt_where_seq [[7, 1], [7, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.3691    0.0392   -0.3999  ...    -1.8185 -100.0000 -100.0000
   -0.1572   -0.4857   -0.9164  ...    -2.2535 -100.0000 -100.0000
   -0.1572   -0.4857   -0.9164  ...    -2.2535 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.1572   -0.4857   -0.9164  ...    -2.2535 -100.0000 -100.0000
   -0.1572   -0.4857   -0.9164  ...    -2.2535 -100.0000 -100.0000
   -0.1572   -0.4857   -0.9164  ...    -2.2535 -100.0000 -100.0000

(1 ,.,.) = 
    0.4121    0.1157   -0.2688  ...    -2.3934   -1.8334 -100.0000
   -0.1496   -0.4452   -0.8231  ...    -2.8113   -2.2973 -100.0000
   -0.1496   -0.4452   -0.8231  ...    -2.8113   -2.2973 -100.0000
              ...                ⋱                ...             
   -0.1496   -0.4452   -0.8231  ...    -2.8113   -2.2973 -100.0000
   -0.1496   -0.4452   -0.8231  ...    -2.8113   -2.2973 -100.0000
   -0.1496   -0.4452   -0.8231  ...    -2.8113   -2.2973 -100.0000

(2 ,.,.) = 
    0.4334    0.1224   -0.2809  ...    -1.8808 -100.0000 -100.0000
    0.6230    0.3146   -0.0876  ...    -1.7085 -100.0000 -100.0000
    0.6737    0.3662   -0.0354  ...    -1.6619 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.1448   -0.4553   -0.8515  ...    -2.3543 -100.0000 -100.0000
   -0.1448   -0.4553   -0.8515  ...    -2.3543 -100.0000 -100.0000
   -0.1448   -0.4553   -0.8515  ...    -2.3543 -100.0000 -100.0000
...

(12,.,.) = 
    0.4876    0.1530   -0.2523  ...  -100.0000 -100.0000 -100.0000
   -0.1460   -0.4804   -0.8783  ...  -100.0000 -100.0000 -100.0000
   -0.1460   -0.4804   -0.8783  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.1460   -0.4804   -0.8783  ...  -100.0000 -100.0000 -100.0000
   -0.1460   -0.4804   -0.8783  ...  -100.0000 -100.0000 -100.0000
   -0.1460   -0.4804   -0.8783  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    0.4582    0.1420   -0.2851  ...  -100.0000 -100.0000 -100.0000
   -0.1252   -0.4411   -0.8607  ...  -100.0000 -100.0000 -100.0000
   -0.1252   -0.4411   -0.8607  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.1252   -0.4411   -0.8607  ...  -100.0000 -100.0000 -100.0000
   -0.1252   -0.4411   -0.8607  ...  -100.0000 -100.0000 -100.0000
   -0.1252   -0.4411   -0.8607  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    0.4485    0.1122   -0.2855  ...    -1.7107 -100.0000 -100.0000
    0.6570    0.3239   -0.0722  ...    -1.5148 -100.0000 -100.0000
    0.6957    0.3632   -0.0326  ...    -1.4782 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5025    0.1668   -0.2306  ...    -1.6606 -100.0000 -100.0000
    0.4491    0.1128   -0.2849  ...    -1.7095 -100.0000 -100.0000
    0.4322    0.0957   -0.3019  ...    -1.7251 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x9x61 (GPU 0)]

gt_where_seq [[7, 0, 0, 0, 60, 1], [7, 0, 14, 0, 54, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.7085e-01  8.3928e-02 -4.0483e-01  ...  -2.9647e+00 -2.7560e+00 -2.0548e+00
  8.1668e-01  4.3671e-01 -4.8836e-02  ...  -2.6916e+00 -2.4711e+00 -1.7365e+00
  8.4686e-01  4.6783e-01 -1.7035e-02  ...  -2.6660e+00 -2.4449e+00 -1.7078e+00
                 ...                   ⋱                   ...                
 -2.5001e-01 -6.3525e-01 -1.1109e+00  ...  -3.4397e+00 -3.2570e+00 -2.6346e+00
 -2.5001e-01 -6.3525e-01 -1.1109e+00  ...  -3.4397e+00 -3.2570e+00 -2.6346e+00
 -2.5001e-01 -6.3525e-01 -1.1109e+00  ...  -3.4397e+00 -3.2570e+00 -2.6346e+00

(1 ,.,.) = 
  5.9672e-01  2.2107e-01 -2.9917e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1139e-01  4.4013e-01 -7.7672e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.9584e-01  5.2696e-01  1.1114e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -1.9868e-01 -5.7476e-01 -1.0820e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9868e-01 -5.7476e-01 -1.0820e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9868e-01 -5.7476e-01 -1.0820e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  4.4987e-01  3.6070e-02 -4.6912e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4548e-01  3.3734e-01 -1.6588e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2764e-01  4.2175e-01 -8.0124e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.2988e-01 -6.4095e-01 -1.1315e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.2988e-01 -6.4095e-01 -1.1315e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.2988e-01 -6.4095e-01 -1.1315e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  5.3218e-01  1.3092e-01 -3.5370e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6963e-01 -6.6968e-01 -1.1409e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6963e-01 -6.6968e-01 -1.1409e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.6963e-01 -6.6968e-01 -1.1409e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6963e-01 -6.6968e-01 -1.1409e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6963e-01 -6.6968e-01 -1.1409e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  6.1349e-01  1.7564e-01 -3.4820e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.1752e-01 -6.5588e-01 -1.1654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.1752e-01 -6.5588e-01 -1.1654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.1752e-01 -6.5588e-01 -1.1654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.1752e-01 -6.5588e-01 -1.1654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.1752e-01 -6.5588e-01 -1.1654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  5.7584e-01  1.5474e-01 -3.4532e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.8382e-01  4.6961e-01 -2.7402e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.9937e-01  5.8871e-01  9.4179e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4610e-01  3.2779e-01 -1.7188e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9157e-01 -6.1221e-01 -1.0994e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9157e-01 -6.1221e-01 -1.0994e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  6.8648e-01  2.0481e-01 -4.2383e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8401e-01 -7.6501e-01 -1.3707e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8401e-01 -7.6501e-01 -1.3707e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.8401e-01 -7.6501e-01 -1.3707e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8401e-01 -7.6501e-01 -1.3707e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8401e-01 -7.6501e-01 -1.3707e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  7.1038e-01  1.9823e-01 -3.9962e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.3983e-01 -7.5199e-01 -1.3287e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.3983e-01 -7.5199e-01 -1.3287e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.3983e-01 -7.5199e-01 -1.3287e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.3983e-01 -7.5199e-01 -1.3287e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.3983e-01 -7.5199e-01 -1.3287e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  5.5404e-01  7.9600e-02 -5.3291e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8531e-01 -7.5712e-01 -1.3472e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8531e-01 -7.5712e-01 -1.3472e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.8531e-01 -7.5712e-01 -1.3472e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8531e-01 -7.5712e-01 -1.3472e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8531e-01 -7.5712e-01 -1.3472e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  6.0905e-01  1.1050e-01 -4.8383e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.2297e-01  4.3305e-01 -1.5824e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0281e+00  5.4196e-01 -4.7135e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.9495e-01  4.0341e-01 -1.8914e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0465e-01  3.1042e-01 -2.8325e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2848e-01 -8.2375e-01 -1.3941e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  6.0079e-01  7.6479e-02 -4.9645e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2033e-01 -8.4092e-01 -1.3903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2033e-01 -8.4092e-01 -1.3903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2033e-01 -8.4092e-01 -1.3903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2033e-01 -8.4092e-01 -1.3903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2033e-01 -8.4092e-01 -1.3903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  6.4131e-01  1.4899e-01 -4.6764e-01  ...  -3.1295e+00 -2.7457e+00 -2.0456e+00
  9.0092e-01  4.1548e-01 -1.9868e-01  ...  -2.9268e+00 -2.5271e+00 -1.8033e+00
  9.9736e-01  5.1506e-01 -9.7337e-02  ...  -2.8450e+00 -2.4402e+00 -1.7086e+00
                 ...                   ⋱                   ...                
  8.1715e-01  3.2842e-01 -2.8764e-01  ...  -2.9956e+00 -2.6015e+00 -1.8852e+00
  7.1675e-01  2.2537e-01 -3.9161e-01  ...  -3.0740e+00 -2.6857e+00 -1.9781e+00
  6.5435e-01  1.6165e-01 -4.5536e-01  ...  -3.1213e+00 -2.7370e+00 -2.0354e+00
[torch.cuda.FloatTensor of size 15x8x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  6.9697e-01  4.4713e-02 -6.7607e-01  ...  -2.4139e+00 -1.0000e+02 -1.0000e+02
 -4.8181e-01 -1.1254e+00 -1.8023e+00  ...  -3.2986e+00 -1.0000e+02 -1.0000e+02
 -4.8181e-01 -1.1254e+00 -1.8023e+00  ...  -3.2986e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -4.8181e-01 -1.1254e+00 -1.8023e+00  ...  -3.2986e+00 -1.0000e+02 -1.0000e+02
 -4.8181e-01 -1.1254e+00 -1.8023e+00  ...  -3.2986e+00 -1.0000e+02 -1.0000e+02
 -4.8181e-01 -1.1254e+00 -1.8023e+00  ...  -3.2986e+00 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  8.8259e-01  3.2141e-01 -4.0545e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2629e+00  7.1828e-01  1.8298e-04  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3371e+00  7.9613e-01  8.0754e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2116e+00  6.6389e-01 -5.6338e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.0728e-01 -8.7064e-01 -1.5652e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.0728e-01 -8.7064e-01 -1.5652e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  5.1994e-01 -1.0767e-01 -8.2919e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9604e-01 -1.1115e+00 -1.7899e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9604e-01 -1.1115e+00 -1.7899e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -4.9604e-01 -1.1115e+00 -1.7899e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9604e-01 -1.1115e+00 -1.7899e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9604e-01 -1.1115e+00 -1.7899e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(3 ,.,.) = 
  7.8820e-01  1.9165e-01 -5.2338e-01  ...  -3.5227e+00 -3.2498e+00 -2.4201e+00
 -4.0024e-01 -9.9340e-01 -1.6708e+00  ...  -4.2033e+00 -3.9900e+00 -3.3147e+00
 -4.0024e-01 -9.9340e-01 -1.6708e+00  ...  -4.2033e+00 -3.9900e+00 -3.3147e+00
                 ...                   ⋱                   ...                
 -4.0024e-01 -9.9340e-01 -1.6708e+00  ...  -4.2033e+00 -3.9900e+00 -3.3147e+00
 -4.0024e-01 -9.9340e-01 -1.6708e+00  ...  -4.2033e+00 -3.9900e+00 -3.3147e+00
 -4.0024e-01 -9.9340e-01 -1.6708e+00  ...  -4.2033e+00 -3.9900e+00 -3.3147e+00

(4 ,.,.) = 
  6.1212e-01  6.5681e-02 -6.0507e-01  ...  -3.6617e+00 -3.3520e+00 -2.5485e+00
 -4.3834e-01 -9.7829e-01 -1.6149e+00  ...  -4.2413e+00 -3.9932e+00 -3.3251e+00
 -4.3834e-01 -9.7829e-01 -1.6149e+00  ...  -4.2413e+00 -3.9932e+00 -3.3251e+00
                 ...                   ⋱                   ...                
 -4.3834e-01 -9.7829e-01 -1.6149e+00  ...  -4.2413e+00 -3.9932e+00 -3.3251e+00
 -4.3834e-01 -9.7829e-01 -1.6149e+00  ...  -4.2413e+00 -3.9932e+00 -3.3251e+00
 -4.3834e-01 -9.7829e-01 -1.6149e+00  ...  -4.2413e+00 -3.9932e+00 -3.3251e+00

(5 ,.,.) = 
  7.0118e-01  1.0229e-01 -5.7672e-01  ...  -2.2978e+00 -1.0000e+02 -1.0000e+02
  1.0007e+00  4.1144e-01 -2.6556e-01  ...  -2.0221e+00 -1.0000e+02 -1.0000e+02
  1.0996e+00  5.1495e-01 -1.5969e-01  ...  -1.9234e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.0102e+00  4.2144e-01 -2.5510e-01  ...  -2.0120e+00 -1.0000e+02 -1.0000e+02
  9.1167e-01  3.1931e-01 -3.5858e-01  ...  -2.1051e+00 -1.0000e+02 -1.0000e+02
  7.8012e-01  1.8353e-01 -4.9525e-01  ...  -2.2273e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x7x61 (GPU 0)]

 Loss = 5.91539332446
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  8.7282e-01  1.9482e-01 -6.2548e-01  ...  -3.3417e+00 -2.5056e+00 -1.0000e+02
  1.2160e+00  5.5323e-01 -2.6221e-01  ...  -3.0657e+00 -2.1865e+00 -1.0000e+02
  1.2854e+00  6.2651e-01 -1.8682e-01  ...  -3.0047e+00 -2.1179e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7491e-01 -4.1363e-01 -1.2235e+00  ...  -3.7517e+00 -2.9940e+00 -1.0000e+02
  2.7491e-01 -4.1363e-01 -1.2235e+00  ...  -3.7517e+00 -2.9940e+00 -1.0000e+02
  2.7491e-01 -4.1363e-01 -1.2235e+00  ...  -3.7517e+00 -2.9940e+00 -1.0000e+02

( 1 ,.,.) = 
  8.9117e-01  2.1397e-01 -6.0616e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2390e+00  5.7758e-01 -2.3708e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3092e+00  6.5179e-01 -1.6063e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7539e-01 -4.1302e-01 -1.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7539e-01 -4.1302e-01 -1.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7539e-01 -4.1302e-01 -1.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  8.9386e-01  2.1663e-01 -6.0358e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2429e+00  5.8162e-01 -2.3300e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3145e+00  6.5735e-01 -1.5494e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7493e-01 -4.1360e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7493e-01 -4.1360e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7493e-01 -4.1360e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  9.2203e-01  2.4592e-01 -5.7413e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2791e+00  6.1996e-01 -1.9349e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3537e+00  6.9895e-01 -1.1187e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7513e-01 -4.1335e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7513e-01 -4.1335e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7513e-01 -4.1335e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  9.3310e-01  2.5745e-01 -5.6250e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2921e+00  6.3383e-01 -1.7912e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3658e+00  7.1183e-01 -9.8438e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7528e-01 -4.1315e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7528e-01 -4.1315e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7528e-01 -4.1315e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  9.0218e-01  2.2540e-01 -5.9468e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2496e+00  5.8883e-01 -2.2545e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3191e+00  6.6231e-01 -1.4970e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7525e-01 -4.1319e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7525e-01 -4.1319e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7525e-01 -4.1319e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  9.1483e-01  2.3842e-01 -5.8169e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2701e+00  6.1040e-01 -2.0334e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3429e+00  6.8749e-01 -1.2371e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7504e-01 -4.1347e-01 -1.2233e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7504e-01 -4.1347e-01 -1.2233e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7504e-01 -4.1347e-01 -1.2233e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  8.8742e-01  2.1013e-01 -6.0999e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2339e+00  5.7229e-01 -2.4244e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3035e+00  6.4578e-01 -1.6675e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7534e-01 -4.1308e-01 -1.2229e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7534e-01 -4.1308e-01 -1.2229e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7534e-01 -4.1308e-01 -1.2229e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  8.8700e-01  2.0956e-01 -6.1068e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2345e+00  5.7282e-01 -2.4205e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3052e+00  6.4755e-01 -1.6506e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  8.9148e-01  2.1418e-01 -6.0602e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2392e+00  5.7778e-01 -2.3694e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3102e+00  6.5281e-01 -1.5962e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7497e-01 -4.1356e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7497e-01 -4.1356e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7497e-01 -4.1356e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  8.3405e-01  1.5480e-01 -6.6547e-01  ...  -3.2172e+00 -2.3936e+00 -1.0000e+02
  1.1627e+00  4.9718e-01 -3.1959e-01  ...  -2.9482e+00 -2.0860e+00 -1.0000e+02
  1.2254e+00  5.6314e-01 -2.5202e-01  ...  -2.8927e+00 -2.0240e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7508e-01 -4.1342e-01 -1.2232e+00  ...  -3.6134e+00 -2.8589e+00 -1.0000e+02
  2.7508e-01 -4.1342e-01 -1.2232e+00  ...  -3.6134e+00 -2.8589e+00 -1.0000e+02
  2.7508e-01 -4.1342e-01 -1.2232e+00  ...  -3.6134e+00 -2.8589e+00 -1.0000e+02

(14 ,.,.) = 
  8.7698e-01  1.9917e-01 -6.2109e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2236e+00  5.6132e-01 -2.5386e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2930e+00  6.3455e-01 -1.7847e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  8.7478e-01  1.9704e-01 -6.2317e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2195e+00  5.5713e-01 -2.5813e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2899e+00  6.3140e-01 -1.8171e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7557e-01 -4.1278e-01 -1.2226e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7557e-01 -4.1278e-01 -1.2226e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7557e-01 -4.1278e-01 -1.2226e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  8.9690e-01  2.1977e-01 -6.0044e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2467e+00  5.8568e-01 -2.2884e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3189e+00  6.6194e-01 -1.5020e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7492e-01 -4.1362e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7492e-01 -4.1362e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7492e-01 -4.1362e-01 -1.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  8.6316e-01  1.8484e-01 -6.3547e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2054e+00  5.4209e-01 -2.7364e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2752e+00  6.1568e-01 -1.9799e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7503e-01 -4.1348e-01 -1.2233e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7503e-01 -4.1348e-01 -1.2233e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7503e-01 -4.1348e-01 -1.2233e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  8.8824e-01  2.1086e-01 -6.0941e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2360e+00  5.7435e-01 -2.4055e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3076e+00  6.5000e-01 -1.6261e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7533e-01 -4.1310e-01 -1.2229e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7533e-01 -4.1310e-01 -1.2229e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7533e-01 -4.1310e-01 -1.2229e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  8.7438e-01  1.9659e-01 -6.2361e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2177e+00  5.5522e-01 -2.6005e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2869e+00  6.2827e-01 -1.8490e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7540e-01 -4.1300e-01 -1.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7540e-01 -4.1300e-01 -1.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7540e-01 -4.1300e-01 -1.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  8.8911e-01  2.1175e-01 -6.0850e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2397e+00  5.7835e-01 -2.3635e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3111e+00  6.5378e-01 -1.5857e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7512e-01 -4.1337e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7512e-01 -4.1337e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7512e-01 -4.1337e-01 -1.2232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  8.6659e-01  1.8834e-01 -6.3199e-01  ...  -3.5323e+00 -3.3224e+00 -2.4912e+00
  1.2084e+00  5.4523e-01 -2.7046e-01  ...  -3.2691e+00 -3.0465e+00 -2.1731e+00
  1.2769e+00  6.1749e-01 -1.9615e-01  ...  -3.2112e+00 -2.9863e+00 -2.1054e+00
                 ...                   ⋱                   ...                
  2.7490e-01 -4.1365e-01 -1.2235e+00  ...  -3.9178e+00 -3.7302e+00 -2.9756e+00
  2.7490e-01 -4.1365e-01 -1.2235e+00  ...  -3.9178e+00 -3.7302e+00 -2.9756e+00
  2.7490e-01 -4.1365e-01 -1.2235e+00  ...  -3.9178e+00 -3.7302e+00 -2.9756e+00

( 1 ,.,.) = 
  8.7003e-01  1.9201e-01 -6.2826e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2146e+00  5.5179e-01 -2.6365e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2853e+00  6.2647e-01 -1.8682e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7518e-01 -4.1329e-01 -1.2231e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7518e-01 -4.1329e-01 -1.2231e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7518e-01 -4.1329e-01 -1.2231e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  8.8230e-01  2.0476e-01 -6.1541e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2273e+00  5.6530e-01 -2.4971e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2967e+00  6.3853e-01 -1.7433e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7525e-01 -4.1320e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7525e-01 -4.1320e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7525e-01 -4.1320e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  8.8214e-01  2.0445e-01 -6.1584e-01  ...  -3.7893e+00 -3.5434e+00 -2.5743e+00
  1.2306e+00  5.6867e-01 -2.4633e-01  ...  -3.5383e+00 -3.2750e+00 -2.2523e+00
  1.3013e+00  6.4335e-01 -1.6939e-01  ...  -3.4818e+00 -3.2151e+00 -2.1826e+00
                 ...                   ⋱                   ...                
  2.7490e-01 -4.1365e-01 -1.2235e+00  ...  -4.1546e+00 -3.9373e+00 -3.0648e+00
  2.7490e-01 -4.1365e-01 -1.2235e+00  ...  -4.1546e+00 -3.9373e+00 -3.0648e+00
  2.7490e-01 -4.1365e-01 -1.2235e+00  ...  -4.1546e+00 -3.9373e+00 -3.0648e+00

( 4 ,.,.) = 
  8.4010e-01  1.6106e-01 -6.5921e-01  ...  -2.4016e+00 -1.0000e+02 -1.0000e+02
  1.1749e+00  5.1001e-01 -3.0648e-01  ...  -2.0882e+00 -1.0000e+02 -1.0000e+02
  1.2418e+00  5.8044e-01 -2.3424e-01  ...  -2.0219e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -2.8712e+00 -1.0000e+02 -1.0000e+02
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -2.8712e+00 -1.0000e+02 -1.0000e+02
  2.7510e-01 -4.1339e-01 -1.2232e+00  ...  -2.8712e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  8.5126e-01  1.7263e-01 -6.4762e-01  ...  -2.4396e+00 -1.0000e+02 -1.0000e+02
  1.1860e+00  5.2175e-01 -2.9442e-01  ...  -2.1271e+00 -1.0000e+02 -1.0000e+02
  1.2515e+00  5.9069e-01 -2.2368e-01  ...  -2.0623e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7525e-01 -4.1320e-01 -1.2230e+00  ...  -2.9156e+00 -1.0000e+02 -1.0000e+02
  2.7525e-01 -4.1320e-01 -1.2230e+00  ...  -2.9156e+00 -1.0000e+02 -1.0000e+02
  2.7525e-01 -4.1320e-01 -1.2230e+00  ...  -2.9156e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    0.8162    0.1144   -0.7195  ...  -100.0000 -100.0000 -100.0000
    1.1707    0.4841   -0.3462  ...  -100.0000 -100.0000 -100.0000
    1.2439    0.5615   -0.2669  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1966   -0.5144   -1.3345  ...  -100.0000 -100.0000 -100.0000
    0.1966   -0.5144   -1.3345  ...  -100.0000 -100.0000 -100.0000
    0.1966   -0.5144   -1.3345  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.7873    0.0847   -0.7492  ...  -100.0000 -100.0000 -100.0000
    1.1410    0.4531   -0.3781  ...  -100.0000 -100.0000 -100.0000
    1.2150    0.5311   -0.2982  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1976   -0.5132   -1.3333  ...  -100.0000 -100.0000 -100.0000
    0.1976   -0.5132   -1.3333  ...  -100.0000 -100.0000 -100.0000
    0.1976   -0.5132   -1.3333  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.8196    0.1177   -0.7162  ...  -100.0000 -100.0000 -100.0000
    1.1745    0.4880   -0.3424  ...  -100.0000 -100.0000 -100.0000
    1.2478    0.5654   -0.2629  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1959   -0.5153   -1.3354  ...  -100.0000 -100.0000 -100.0000
    0.1959   -0.5153   -1.3354  ...  -100.0000 -100.0000 -100.0000
    0.1959   -0.5153   -1.3354  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    0.7938    0.0913   -0.7425  ...  -100.0000 -100.0000 -100.0000
    1.1428    0.4548   -0.3762  ...  -100.0000 -100.0000 -100.0000
    1.2146    0.5305   -0.2988  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1968   -0.5141   -1.3342  ...  -100.0000 -100.0000 -100.0000
    0.1968   -0.5141   -1.3342  ...  -100.0000 -100.0000 -100.0000
    0.1968   -0.5141   -1.3342  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    0.8281    0.1267   -0.7073  ...  -100.0000 -100.0000 -100.0000
    1.1822    0.4963   -0.3338  ...  -100.0000 -100.0000 -100.0000
    1.2544    0.5725   -0.2555  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1963   -0.5148   -1.3349  ...  -100.0000 -100.0000 -100.0000
    0.1963   -0.5148   -1.3349  ...  -100.0000 -100.0000 -100.0000
    0.1963   -0.5148   -1.3349  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    0.8162    0.1144   -0.7195  ...  -100.0000 -100.0000 -100.0000
    1.1707    0.4841   -0.3462  ...  -100.0000 -100.0000 -100.0000
    1.2439    0.5615   -0.2669  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1966   -0.5144   -1.3345  ...  -100.0000 -100.0000 -100.0000
    0.1966   -0.5144   -1.3345  ...  -100.0000 -100.0000 -100.0000
    0.1966   -0.5144   -1.3345  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.8116    0.1098   -0.7240  ...  -100.0000 -100.0000 -100.0000
    1.1655    0.4789   -0.3516  ...  -100.0000 -100.0000 -100.0000
    1.2388    0.5562   -0.2723  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1975   -0.5134   -1.3335  ...  -100.0000 -100.0000 -100.0000
    0.1975   -0.5134   -1.3335  ...  -100.0000 -100.0000 -100.0000
    0.1975   -0.5134   -1.3335  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    0.8116    0.1098   -0.7240  ...  -100.0000 -100.0000 -100.0000
    1.1655    0.4789   -0.3516  ...  -100.0000 -100.0000 -100.0000
    1.2388    0.5562   -0.2723  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1975   -0.5134   -1.3335  ...  -100.0000 -100.0000 -100.0000
    0.1975   -0.5134   -1.3335  ...  -100.0000 -100.0000 -100.0000
    0.1975   -0.5134   -1.3335  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.8060    0.1038   -0.7301  ...  -100.0000 -100.0000 -100.0000
    1.1582    0.4710   -0.3597  ...  -100.0000 -100.0000 -100.0000
    1.2311    0.5479   -0.2809  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1964   -0.5147   -1.3348  ...  -100.0000 -100.0000 -100.0000
    0.1964   -0.5147   -1.3348  ...  -100.0000 -100.0000 -100.0000
    0.1964   -0.5147   -1.3348  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    0.8064    0.1041   -0.7297  ...    -3.7421   -3.3628   -2.5239
    1.1542    0.4666   -0.3641  ...    -3.4896   -3.0853   -2.2029
    1.2233    0.5395   -0.2894  ...    -3.4341   -3.0252   -2.1351
              ...                ⋱                ...             
    0.1954   -0.5159   -1.3360  ...    -4.1154   -3.7792   -3.0205
    0.1954   -0.5159   -1.3360  ...    -4.1154   -3.7792   -3.0205
    0.1954   -0.5159   -1.3360  ...    -4.1154   -3.7792   -3.0205

( 4 ,.,.) = 
    0.7846    0.0816   -0.7522  ...    -3.3356   -2.5026 -100.0000
    1.1294    0.4406   -0.3908  ...    -3.0607   -2.1849 -100.0000
    1.1989    0.5138   -0.3160  ...    -3.0004   -2.1169 -100.0000
              ...                ⋱                ...             
    0.1962   -0.5150   -1.3350  ...    -3.7390   -2.9824 -100.0000
    0.1962   -0.5150   -1.3350  ...    -3.7390   -2.9824 -100.0000
    0.1962   -0.5150   -1.3350  ...    -3.7390   -2.9824 -100.0000

( 5 ,.,.) = 
    0.8168    0.1150   -0.7189  ...  -100.0000 -100.0000 -100.0000
    1.1683    0.4816   -0.3488  ...  -100.0000 -100.0000 -100.0000
    1.2397    0.5570   -0.2715  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1963   -0.5148   -1.3349  ...  -100.0000 -100.0000 -100.0000
    0.1963   -0.5148   -1.3349  ...  -100.0000 -100.0000 -100.0000
    0.1963   -0.5148   -1.3349  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 6 @ 2018-04-12 20:36:01.840248
training
gt_where_seq [[7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 0, 22, 0, 55, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 22, 0, 54, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.8869    0.1880   -0.6242  ...    -2.3585 -100.0000 -100.0000
    1.1766    0.4913   -0.3156  ...    -2.0824 -100.0000 -100.0000
    1.2785    0.5986   -0.2056  ...    -1.9805 -100.0000 -100.0000
              ...                ⋱                ...             
    0.8615    0.1614   -0.6508  ...    -2.3829 -100.0000 -100.0000
    0.7511    0.0477   -0.7641  ...    -2.4805 -100.0000 -100.0000
    0.6513   -0.0547   -0.8656  ...    -2.5682 -100.0000 -100.0000

(1 ,.,.) = 
    0.8613    0.2049   -0.6473  ...  -100.0000 -100.0000 -100.0000
   -0.4489   -1.1017   -1.8989  ...  -100.0000 -100.0000 -100.0000
   -0.4489   -1.1017   -1.8989  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4489   -1.1017   -1.8989  ...  -100.0000 -100.0000 -100.0000
   -0.4489   -1.1017   -1.8989  ...  -100.0000 -100.0000 -100.0000
   -0.4489   -1.1017   -1.8989  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    0.8129    0.1364   -0.7161  ...  -100.0000 -100.0000 -100.0000
   -0.3914   -1.0625   -1.8621  ...  -100.0000 -100.0000 -100.0000
   -0.3914   -1.0625   -1.8621  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.3914   -1.0625   -1.8621  ...  -100.0000 -100.0000 -100.0000
   -0.3914   -1.0625   -1.8621  ...  -100.0000 -100.0000 -100.0000
   -0.3914   -1.0625   -1.8621  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    0.9422    0.2920   -0.5096  ...  -100.0000 -100.0000 -100.0000
   -0.3928   -1.0432   -1.7988  ...  -100.0000 -100.0000 -100.0000
   -0.3928   -1.0432   -1.7988  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.3928   -1.0432   -1.7988  ...  -100.0000 -100.0000 -100.0000
   -0.3928   -1.0432   -1.7988  ...  -100.0000 -100.0000 -100.0000
   -0.3928   -1.0432   -1.7988  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    0.7925    0.1632   -0.6563  ...  -100.0000 -100.0000 -100.0000
    1.1903    0.5768   -0.2370  ...  -100.0000 -100.0000 -100.0000
    1.2522    0.6419   -0.1700  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.8922    0.2654   -0.5550  ...  -100.0000 -100.0000 -100.0000
    0.7803    0.1498   -0.6712  ...  -100.0000 -100.0000 -100.0000
    0.6794    0.0463   -0.7739  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    0.8280    0.1635   -0.6621  ...  -100.0000 -100.0000 -100.0000
    1.2782    0.6334   -0.1845  ...  -100.0000 -100.0000 -100.0000
    1.3515    0.7112   -0.1037  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4425   -1.1014   -1.8748  ...  -100.0000 -100.0000 -100.0000
   -0.4425   -1.1014   -1.8748  ...  -100.0000 -100.0000 -100.0000
   -0.4425   -1.1014   -1.8748  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.9280    0.1710   -0.7680  ...    -3.6387   -3.4350   -2.6719
    1.2413    0.4989   -0.4379  ...    -3.4066   -3.1921   -2.3914
    1.2516    0.5100   -0.4262  ...    -3.3997   -3.1859   -2.3835
              ...                ⋱                ...             
    1.1210    0.3723   -0.5665  ...    -3.4995   -3.2903   -2.5027
    0.9418    0.1848   -0.7556  ...    -3.6334   -3.4308   -2.6641
    0.7852    0.0225   -0.9170  ...    -3.7434   -3.5464   -2.7987

(1 ,.,.) = 
    0.9907    0.2197   -0.7116  ...  -100.0000 -100.0000 -100.0000
   -0.4972   -1.2635   -2.1233  ...  -100.0000 -100.0000 -100.0000
   -0.4972   -1.2635   -2.1233  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4972   -1.2635   -2.1233  ...  -100.0000 -100.0000 -100.0000
   -0.4972   -1.2635   -2.1233  ...  -100.0000 -100.0000 -100.0000
   -0.4972   -1.2635   -2.1233  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    0.9556    0.2173   -0.6818  ...  -100.0000 -100.0000 -100.0000
   -0.5819   -1.3137   -2.1418  ...  -100.0000 -100.0000 -100.0000
   -0.5819   -1.3137   -2.1418  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5819   -1.3137   -2.1418  ...  -100.0000 -100.0000 -100.0000
   -0.5819   -1.3137   -2.1418  ...  -100.0000 -100.0000 -100.0000
   -0.5819   -1.3137   -2.1418  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    0.9702    0.2588   -0.6790  ...    -2.5205 -100.0000 -100.0000
   -0.5625   -1.2694   -2.1343  ...    -3.6561 -100.0000 -100.0000
   -0.5625   -1.2694   -2.1343  ...    -3.6561 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5625   -1.2694   -2.1343  ...    -3.6561 -100.0000 -100.0000
   -0.5625   -1.2694   -2.1343  ...    -3.6561 -100.0000 -100.0000
   -0.5625   -1.2694   -2.1343  ...    -3.6561 -100.0000 -100.0000

(13,.,.) = 
    0.8090    0.1057   -0.7696  ...  -100.0000 -100.0000 -100.0000
   -0.6030   -1.2936   -2.1017  ...  -100.0000 -100.0000 -100.0000
   -0.6030   -1.2936   -2.1017  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.6030   -1.2936   -2.1017  ...  -100.0000 -100.0000 -100.0000
   -0.6030   -1.2936   -2.1017  ...  -100.0000 -100.0000 -100.0000
   -0.6030   -1.2936   -2.1017  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    0.7717   -0.0382   -1.0130  ...  -100.0000 -100.0000 -100.0000
    1.0877    0.2916   -0.6838  ...  -100.0000 -100.0000 -100.0000
    1.1590    0.3669   -0.6074  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.9373    0.1337   -0.8428  ...  -100.0000 -100.0000 -100.0000
    0.8711    0.0651   -0.9111  ...  -100.0000 -100.0000 -100.0000
    0.7719   -0.0375   -1.0123  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x7x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.9051    0.0206   -1.0527  ...  -100.0000 -100.0000 -100.0000
   -0.5697   -1.4386   -2.4120  ...  -100.0000 -100.0000 -100.0000
   -0.5697   -1.4386   -2.4120  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5697   -1.4386   -2.4120  ...  -100.0000 -100.0000 -100.0000
   -0.5697   -1.4386   -2.4120  ...  -100.0000 -100.0000 -100.0000
   -0.5697   -1.4386   -2.4120  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    1.1133    0.2649   -0.7129  ...  -100.0000 -100.0000 -100.0000
   -0.5127   -1.3583   -2.2545  ...  -100.0000 -100.0000 -100.0000
   -0.5127   -1.3583   -2.2545  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5127   -1.3583   -2.2545  ...  -100.0000 -100.0000 -100.0000
   -0.5127   -1.3583   -2.2545  ...  -100.0000 -100.0000 -100.0000
   -0.5127   -1.3583   -2.2545  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    1.0900    0.2953   -0.6614  ...  -100.0000 -100.0000 -100.0000
   -0.5380   -1.3311   -2.2098  ...  -100.0000 -100.0000 -100.0000
   -0.5380   -1.3311   -2.2098  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5380   -1.3311   -2.2098  ...  -100.0000 -100.0000 -100.0000
   -0.5380   -1.3311   -2.2098  ...  -100.0000 -100.0000 -100.0000
   -0.5380   -1.3311   -2.2098  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    1.0797    0.3135   -0.7065  ...  -100.0000 -100.0000 -100.0000
   -0.4945   -1.2607   -2.2024  ...  -100.0000 -100.0000 -100.0000
   -0.4945   -1.2607   -2.2024  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4945   -1.2607   -2.2024  ...  -100.0000 -100.0000 -100.0000
   -0.4945   -1.2607   -2.2024  ...  -100.0000 -100.0000 -100.0000
   -0.4945   -1.2607   -2.2024  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    1.0344    0.2047   -0.7413  ...  -100.0000 -100.0000 -100.0000
   -0.5007   -1.3252   -2.1940  ...  -100.0000 -100.0000 -100.0000
   -0.5007   -1.3252   -2.1940  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5007   -1.3252   -2.1940  ...  -100.0000 -100.0000 -100.0000
   -0.5007   -1.3252   -2.1940  ...  -100.0000 -100.0000 -100.0000
   -0.5007   -1.3252   -2.1940  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    0.9153    0.0528   -0.9895  ...    -4.3017   -3.8041   -2.9174
   -0.5482   -1.3961   -2.3440  ...    -4.9650   -4.5970   -3.9257
   -0.5482   -1.3961   -2.3440  ...    -4.9650   -4.5970   -3.9257
              ...                ⋱                ...             
   -0.5482   -1.3961   -2.3440  ...    -4.9650   -4.5970   -3.9257
   -0.5482   -1.3961   -2.3440  ...    -4.9650   -4.5970   -3.9257
   -0.5482   -1.3961   -2.3440  ...    -4.9650   -4.5970   -3.9257
[torch.cuda.FloatTensor of size 15x7x62 (GPU 0)]

gt_where_seq [[7, 0, 8, 0, 55, 1], [7, 0, 0, 0, 60, 1], [7, 0, 24, 0, 60, 1], [7, 0, 18, 0, 56, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 32, 0, 0, 55, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    1.4385    0.6658   -0.4110  ...  -100.0000 -100.0000 -100.0000
    1.5883    0.8278   -0.2406  ...  -100.0000 -100.0000 -100.0000
    1.5367    0.7731   -0.2969  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2640    0.4825   -0.5968  ...  -100.0000 -100.0000 -100.0000
   -0.1757   -0.9740   -1.9937  ...  -100.0000 -100.0000 -100.0000
   -0.1757   -0.9740   -1.9937  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    1.3285    0.5335   -0.5920  ...    -4.1292   -3.8388   -2.6846
    1.5142    0.7329   -0.3854  ...    -3.9987   -3.6961   -2.5069
    1.3544    0.5631   -0.5595  ...    -4.1033   -3.8097   -2.6501
              ...                ⋱                ...             
    1.1313    0.3275   -0.7989  ...    -4.2482   -3.9675   -2.8502
   -0.2676   -1.0792   -2.1315  ...    -4.9193   -4.7111   -3.8523
   -0.2676   -1.0792   -2.1315  ...    -4.9193   -4.7111   -3.8523

(2 ,.,.) = 
    1.4471    0.6754   -0.4070  ...    -3.8096   -3.4336   -2.5366
    1.4651    0.6953   -0.3856  ...    -3.7885   -3.4109   -2.5124
    1.3719    0.5965   -0.4871  ...    -3.8558   -3.4845   -2.5986
              ...                ⋱                ...             
    1.1183    0.3282   -0.7602  ...    -4.0359   -3.6824   -2.8304
   -0.3459   -1.1415   -2.1546  ...    -4.7924   -4.5320   -3.8785
   -0.3459   -1.1415   -2.1546  ...    -4.7924   -4.5320   -3.8785

(3 ,.,.) = 
    1.3828    0.5178   -0.6085  ...  -100.0000 -100.0000 -100.0000
    1.4861    0.6287   -0.4951  ...  -100.0000 -100.0000 -100.0000
    1.4788    0.6219   -0.5006  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1518    0.2732   -0.8560  ...  -100.0000 -100.0000 -100.0000
   -0.2568   -1.1419   -2.1919  ...  -100.0000 -100.0000 -100.0000
   -0.2568   -1.1419   -2.1919  ...  -100.0000 -100.0000 -100.0000

(4 ,.,.) = 
    1.1933    0.4546   -0.6666  ...  -100.0000 -100.0000 -100.0000
    1.4919    0.7715   -0.3391  ...  -100.0000 -100.0000 -100.0000
    1.3638    0.6367   -0.4770  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.0774    0.3346   -0.7868  ...  -100.0000 -100.0000 -100.0000
    0.9556    0.2080   -0.9132  ...  -100.0000 -100.0000 -100.0000
    0.8246    0.0723   -1.0479  ...  -100.0000 -100.0000 -100.0000

(5 ,.,.) = 
    1.3319    0.5098   -0.6346  ...  -100.0000 -100.0000 -100.0000
    1.4217    0.6068   -0.5342  ...  -100.0000 -100.0000 -100.0000
    1.4355    0.6224   -0.5173  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.0692    0.2340   -0.9119  ...  -100.0000 -100.0000 -100.0000
    0.9149    0.0728   -1.0721  ...  -100.0000 -100.0000 -100.0000
    0.8131   -0.0329   -1.1760  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x7x63 (GPU 0)]

 Loss = 5.36568582759
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    1.2456    0.3448   -0.8056  ...    -3.6983   -2.8274 -100.0000
    1.3153    0.4213   -0.7264  ...    -3.6349   -2.7536 -100.0000
    1.1806    0.2787   -0.8703  ...    -3.7345   -2.8722 -100.0000
              ...                ⋱                ...             
    0.1307   -0.7979   -1.9081  ...    -4.3990   -3.6861 -100.0000
    0.1307   -0.7979   -1.9081  ...    -4.3990   -3.6861 -100.0000
    0.1307   -0.7979   -1.9081  ...    -4.3990   -3.6861 -100.0000

( 1 ,.,.) = 
    1.2662    0.3671   -0.7828  ...  -100.0000 -100.0000 -100.0000
    1.3378    0.4457   -0.7012  ...  -100.0000 -100.0000 -100.0000
    1.2018    0.3016   -0.8470  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1314   -0.7969   -1.9071  ...  -100.0000 -100.0000 -100.0000
    0.1314   -0.7969   -1.9071  ...  -100.0000 -100.0000 -100.0000
    0.1314   -0.7969   -1.9071  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.2768    0.3782   -0.7717  ...  -100.0000 -100.0000 -100.0000
    1.3489    0.4575   -0.6892  ...  -100.0000 -100.0000 -100.0000
    1.2139    0.3142   -0.8342  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1307   -0.7979   -1.9081  ...  -100.0000 -100.0000 -100.0000
    0.1307   -0.7979   -1.9081  ...  -100.0000 -100.0000 -100.0000
    0.1307   -0.7979   -1.9081  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.3122    0.4163   -0.7328  ...  -100.0000 -100.0000 -100.0000
    1.3890    0.5008   -0.6446  ...  -100.0000 -100.0000 -100.0000
    1.2532    0.3563   -0.7913  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1310   -0.7974   -1.9076  ...  -100.0000 -100.0000 -100.0000
    0.1310   -0.7974   -1.9076  ...  -100.0000 -100.0000 -100.0000
    0.1310   -0.7974   -1.9076  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.3217    0.4265   -0.7223  ...  -100.0000 -100.0000 -100.0000
    1.3981    0.5107   -0.6343  ...  -100.0000 -100.0000 -100.0000
    1.2609    0.3647   -0.7827  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1313   -0.7971   -1.9073  ...  -100.0000 -100.0000 -100.0000
    0.1313   -0.7971   -1.9073  ...  -100.0000 -100.0000 -100.0000
    0.1313   -0.7971   -1.9073  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.2786    0.3804   -0.7692  ...  -100.0000 -100.0000 -100.0000
    1.3476    0.4563   -0.6902  ...  -100.0000 -100.0000 -100.0000
    1.2109    0.3113   -0.8370  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1312   -0.7972   -1.9073  ...  -100.0000 -100.0000 -100.0000
    0.1312   -0.7972   -1.9073  ...  -100.0000 -100.0000 -100.0000
    0.1312   -0.7972   -1.9073  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.2978    0.4008   -0.7487  ...  -100.0000 -100.0000 -100.0000
    1.3716    0.4820   -0.6641  ...  -100.0000 -100.0000 -100.0000
    1.2347    0.3365   -0.8115  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1309   -0.7976   -1.9078  ...  -100.0000 -100.0000 -100.0000
    0.1309   -0.7976   -1.9078  ...  -100.0000 -100.0000 -100.0000
    0.1309   -0.7976   -1.9078  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.2577    0.3581   -0.7919  ...  -100.0000 -100.0000 -100.0000
    1.3277    0.4350   -0.7121  ...  -100.0000 -100.0000 -100.0000
    1.1921    0.2913   -0.8573  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1313   -0.7970   -1.9071  ...  -100.0000 -100.0000 -100.0000
    0.1313   -0.7970   -1.9071  ...  -100.0000 -100.0000 -100.0000
    0.1313   -0.7970   -1.9071  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.2638    0.3644   -0.7857  ...  -100.0000 -100.0000 -100.0000
    1.3349    0.4424   -0.7047  ...  -100.0000 -100.0000 -100.0000
    1.1993    0.2988   -0.8499  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1310   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
    0.1310   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
    0.1310   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.2734    0.3746   -0.7753  ...  -100.0000 -100.0000 -100.0000
    1.3445    0.4527   -0.6941  ...  -100.0000 -100.0000 -100.0000
    1.2092    0.3092   -0.8393  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1307   -0.7978   -1.9080  ...  -100.0000 -100.0000 -100.0000
    0.1307   -0.7978   -1.9080  ...  -100.0000 -100.0000 -100.0000
    0.1307   -0.7978   -1.9080  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.1814    0.2765   -0.8747  ...    -3.5361   -2.6998 -100.0000
    1.2424    0.3433   -0.8059  ...    -3.4791   -2.6345 -100.0000
    1.1063    0.1998   -0.9499  ...    -3.5827   -2.7554 -100.0000
              ...                ⋱                ...             
    0.1309   -0.7975   -1.9077  ...    -4.2273   -3.5278 -100.0000
    0.1309   -0.7975   -1.9077  ...    -4.2273   -3.5278 -100.0000
    0.1309   -0.7975   -1.9077  ...    -4.2273   -3.5278 -100.0000

(14 ,.,.) = 
    1.2536    0.3534   -0.7969  ...  -100.0000 -100.0000 -100.0000
    1.3280    0.4350   -0.7123  ...  -100.0000 -100.0000 -100.0000
    1.1918    0.2908   -0.8580  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1309   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
    0.1309   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
    0.1309   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.2476    0.3473   -0.8029  ...  -100.0000 -100.0000 -100.0000
    1.3190    0.4256   -0.7218  ...  -100.0000 -100.0000 -100.0000
    1.1847    0.2834   -0.8654  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1317   -0.7965   -1.9067  ...  -100.0000 -100.0000 -100.0000
    0.1317   -0.7965   -1.9067  ...  -100.0000 -100.0000 -100.0000
    0.1317   -0.7965   -1.9067  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.2806    0.3822   -0.7676  ...  -100.0000 -100.0000 -100.0000
    1.3529    0.4618   -0.6849  ...  -100.0000 -100.0000 -100.0000
    1.2179    0.3185   -0.8299  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1307   -0.7979   -1.9081  ...  -100.0000 -100.0000 -100.0000
    0.1307   -0.7979   -1.9081  ...  -100.0000 -100.0000 -100.0000
    0.1307   -0.7979   -1.9081  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.2405    0.3394   -0.8111  ...  -100.0000 -100.0000 -100.0000
    1.3114    0.4171   -0.7307  ...  -100.0000 -100.0000 -100.0000
    1.1776    0.2755   -0.8735  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1308   -0.7976   -1.9078  ...  -100.0000 -100.0000 -100.0000
    0.1308   -0.7976   -1.9078  ...  -100.0000 -100.0000 -100.0000
    0.1308   -0.7976   -1.9078  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.2600    0.3604   -0.7898  ...  -100.0000 -100.0000 -100.0000
    1.3321    0.4395   -0.7078  ...  -100.0000 -100.0000 -100.0000
    1.1982    0.2976   -0.8512  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1313   -0.7970   -1.9071  ...  -100.0000 -100.0000 -100.0000
    0.1313   -0.7970   -1.9071  ...  -100.0000 -100.0000 -100.0000
    0.1313   -0.7970   -1.9071  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.2435    0.3429   -0.8074  ...  -100.0000 -100.0000 -100.0000
    1.3129    0.4191   -0.7285  ...  -100.0000 -100.0000 -100.0000
    1.1780    0.2762   -0.8727  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1314   -0.7968   -1.9070  ...  -100.0000 -100.0000 -100.0000
    0.1314   -0.7968   -1.9070  ...  -100.0000 -100.0000 -100.0000
    0.1314   -0.7968   -1.9070  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.2695    0.3705   -0.7796  ...  -100.0000 -100.0000 -100.0000
    1.3462    0.4547   -0.6921  ...  -100.0000 -100.0000 -100.0000
    1.2111    0.3114   -0.8370  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1310   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
    0.1310   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
    0.1310   -0.7975   -1.9077  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.2430    0.3420   -0.8085  ...    -3.9121   -3.7000   -2.8303
    1.3127    0.4185   -0.7294  ...    -3.8517   -3.6366   -2.7566
    1.1776    0.2754   -0.8736  ...    -3.9461   -3.7364   -2.8753
              ...                ⋱                ...             
    0.1306   -0.7979   -1.9081  ...    -4.5681   -4.3989   -3.6865
    0.1306   -0.7979   -1.9081  ...    -4.5681   -4.3989   -3.6865
    0.1306   -0.7979   -1.9081  ...    -4.5681   -4.3989   -3.6865

( 1 ,.,.) = 
    1.2445    0.3438   -0.8067  ...  -100.0000 -100.0000 -100.0000
    1.3160    0.4222   -0.7254  ...  -100.0000 -100.0000 -100.0000
    1.1824    0.2808   -0.8681  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1311   -0.7973   -1.9075  ...  -100.0000 -100.0000 -100.0000
    0.1311   -0.7973   -1.9075  ...  -100.0000 -100.0000 -100.0000
    0.1311   -0.7973   -1.9075  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.2545    0.3546   -0.7956  ...  -100.0000 -100.0000 -100.0000
    1.3243    0.4312   -0.7161  ...  -100.0000 -100.0000 -100.0000
    1.1894    0.2882   -0.8605  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1312   -0.7972   -1.9073  ...  -100.0000 -100.0000 -100.0000
    0.1312   -0.7972   -1.9073  ...  -100.0000 -100.0000 -100.0000
    0.1312   -0.7972   -1.9073  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    1.2620    0.3623   -0.7880  ...    -4.2515   -3.9931   -2.9034
    1.3371    0.4447   -0.7024  ...    -4.1933   -3.9298   -2.8246
    1.2021    0.3016   -0.8470  ...    -4.2784   -4.0223   -2.9424
              ...                ⋱                ...             
    0.1306   -0.7979   -1.9081  ...    -4.8429   -4.6421   -3.7626
    0.1306   -0.7979   -1.9081  ...    -4.8429   -4.6421   -3.7626
    0.1306   -0.7979   -1.9081  ...    -4.8429   -4.6421   -3.7626

( 4 ,.,.) = 
    1.1976    0.2938   -0.8573  ...    -2.7139 -100.0000 -100.0000
    1.2656    0.3680   -0.7808  ...    -2.6419 -100.0000 -100.0000
    1.1326    0.2277   -0.9218  ...    -2.7600 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1310   -0.7975   -1.9077  ...    -3.5524 -100.0000 -100.0000
    0.1310   -0.7975   -1.9077  ...    -3.5524 -100.0000 -100.0000
    0.1310   -0.7975   -1.9077  ...    -3.5524 -100.0000 -100.0000

( 5 ,.,.) = 
    1.2023    0.2989   -0.8521  ...    -2.7370 -100.0000 -100.0000
    1.2672    0.3698   -0.7789  ...    -2.6681 -100.0000 -100.0000
    1.1319    0.2271   -0.9224  ...    -2.7879 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1312   -0.7972   -1.9073  ...    -3.5759 -100.0000 -100.0000
    0.1312   -0.7972   -1.9073  ...    -3.5759 -100.0000 -100.0000
    0.1312   -0.7972   -1.9073  ...    -3.5759 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  1.1812e+00  2.4141e-01 -9.2968e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2555e+00  3.2272e-01 -8.4616e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1173e+00  1.7657e-01 -9.9273e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.3163e-02 -9.4037e-01 -2.0599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3163e-02 -9.4037e-01 -2.0599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3163e-02 -9.4037e-01 -2.0599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.1527e+00  2.1132e-01 -9.6005e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2338e+00  2.9976e-01 -8.6960e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0982e+00  1.5668e-01 -1.0128e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4576e-02 -9.3854e-01 -2.0581e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4576e-02 -9.3854e-01 -2.0581e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4576e-02 -9.3854e-01 -2.0581e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.1894e+00  2.4982e-01 -9.2132e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2631e+00  3.3060e-01 -8.3825e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1238e+00  1.8327e-01 -9.8609e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.2099e-02 -9.4174e-01 -2.0613e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2099e-02 -9.4174e-01 -2.0613e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2099e-02 -9.4174e-01 -2.0613e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.1548e+00  2.1332e-01 -9.5798e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2278e+00  2.9317e-01 -8.7622e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0905e+00  1.4815e-01 -1.0213e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.3521e-02 -9.3991e-01 -2.0595e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3521e-02 -9.3991e-01 -2.0595e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3521e-02 -9.3991e-01 -2.0595e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.1965e+00  2.5762e-01 -9.1335e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2677e+00  3.3574e-01 -8.3289e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1273e+00  1.8716e-01 -9.8207e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.2691e-02 -9.4098e-01 -2.0606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2691e-02 -9.4098e-01 -2.0606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2691e-02 -9.4098e-01 -2.0606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.1812e+00  2.4141e-01 -9.2968e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2555e+00  3.2272e-01 -8.4616e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1173e+00  1.7657e-01 -9.9273e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.3163e-02 -9.4037e-01 -2.0599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3163e-02 -9.4037e-01 -2.0599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3163e-02 -9.4037e-01 -2.0599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.1772    0.2375   -0.9335  ...  -100.0000 -100.0000 -100.0000
    1.2517    0.3191   -0.8498  ...  -100.0000 -100.0000 -100.0000
    1.1135    0.1729   -0.9963  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0244   -0.9388   -2.0584  ...  -100.0000 -100.0000 -100.0000
    0.0244   -0.9388   -2.0584  ...  -100.0000 -100.0000 -100.0000
    0.0244   -0.9388   -2.0584  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.1772    0.2375   -0.9335  ...  -100.0000 -100.0000 -100.0000
    1.2517    0.3191   -0.8498  ...  -100.0000 -100.0000 -100.0000
    1.1135    0.1729   -0.9963  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0244   -0.9388   -2.0584  ...  -100.0000 -100.0000 -100.0000
    0.0244   -0.9388   -2.0584  ...  -100.0000 -100.0000 -100.0000
    0.0244   -0.9388   -2.0584  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.1706    0.2300   -0.9412  ...  -100.0000 -100.0000 -100.0000
    1.2441    0.3105   -0.8587  ...  -100.0000 -100.0000 -100.0000
    1.1060    0.1645   -1.0049  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0227   -0.9409   -2.0605  ...  -100.0000 -100.0000 -100.0000
    0.0227   -0.9409   -2.0605  ...  -100.0000 -100.0000 -100.0000
    0.0227   -0.9409   -2.0605  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    1.1622    0.2207   -0.9506  ...    -4.1360   -3.7191   -2.8424
    1.2311    0.2962   -0.8731  ...    -4.0803   -3.6569   -2.7700
    1.0915    0.1487   -1.0207  ...    -4.1711   -3.7591   -2.8919
              ...                ⋱                ...             
    0.0213   -0.9428   -2.0623  ...    -4.7572   -4.4293   -3.7148
    0.0213   -0.9428   -2.0623  ...    -4.7572   -4.4293   -3.7148
    0.0213   -0.9428   -2.0623  ...    -4.7572   -4.4293   -3.7148

( 4 ,.,.) = 
    1.1433    0.2008   -0.9707  ...    -3.7038   -2.8309 -100.0000
    1.2119    0.2757   -0.8940  ...    -3.6425   -2.7593 -100.0000
    1.0731    0.1294   -1.0402  ...    -3.7439   -2.8802 -100.0000
              ...                ⋱                ...             
    0.0224   -0.9413   -2.0608  ...    -4.4038   -3.6894 -100.0000
    0.0224   -0.9413   -2.0608  ...    -4.4038   -3.6894 -100.0000
    0.0224   -0.9413   -2.0608  ...    -4.4038   -3.6894 -100.0000

( 5 ,.,.) = 
    1.1777    0.2376   -0.9335  ...  -100.0000 -100.0000 -100.0000
    1.2489    0.3155   -0.8534  ...  -100.0000 -100.0000 -100.0000
    1.1101    0.1688   -1.0005  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0227   -0.9410   -2.0606  ...  -100.0000 -100.0000 -100.0000
    0.0227   -0.9410   -2.0606  ...  -100.0000 -100.0000 -100.0000
    0.0227   -0.9410   -2.0606  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 1, 4, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 7 @ 2018-04-12 20:36:04.199904
training
gt_where_seq [[7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 0, 14, 0, 54, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.3770e+00  5.4285e-01 -5.1884e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3434e+00  5.0920e-01 -5.5185e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1926e+00  3.4993e-01 -7.1291e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.7671e-01 -2.9137e-01 -1.3485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5742e-01 -4.1277e-01 -1.4653e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8140e-01 -4.8949e-01 -1.5382e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.5916e+00  7.6691e-01 -2.9949e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0445e-01 -1.0678e+00 -2.0798e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0445e-01 -1.0678e+00 -2.0798e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0445e-01 -1.0678e+00 -2.0798e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0445e-01 -1.0678e+00 -2.0798e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0445e-01 -1.0678e+00 -2.0798e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.1590e+00  3.0128e-01 -7.8930e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.8655e-01 -1.2506e+00 -2.2599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.8655e-01 -1.2506e+00 -2.2599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.8655e-01 -1.2506e+00 -2.2599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.8655e-01 -1.2506e+00 -2.2599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.8655e-01 -1.2506e+00 -2.2599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.3432e+00  5.2948e-01 -7.4776e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7748e-01 -1.3064e+00 -2.4760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7748e-01 -1.3064e+00 -2.4760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -4.7748e-01 -1.3064e+00 -2.4760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7748e-01 -1.3064e+00 -2.4760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7748e-01 -1.3064e+00 -2.4760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.3473e+00  4.9634e-01 -6.1408e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3399e+00  4.9002e-01 -6.1931e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2471e+00  3.9111e-01 -7.2087e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2824e-01 -2.5403e-01 -1.3600e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6440e-01 -1.2330e+00 -2.2654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6440e-01 -1.2330e+00 -2.2654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.4389e+00  5.8890e-01 -4.5411e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6581e-01 -1.2393e+00 -2.2109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6581e-01 -1.2393e+00 -2.2109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.6581e-01 -1.2393e+00 -2.2109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6581e-01 -1.2393e+00 -2.2109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6581e-01 -1.2393e+00 -2.2109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 0, 0, 60, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.1559e+00  2.8044e-01 -8.5927e-01  ...  -3.2902e+00 -2.5942e+00 -1.0000e+02
  1.0526e+00  1.7308e-01 -9.6614e-01  ...  -3.3634e+00 -2.6783e+00 -1.0000e+02
  9.2726e-01  4.3982e-02 -1.0927e+00  ...  -3.4544e+00 -2.7817e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.4348e-01 -6.5632e-01 -1.7677e+00  ...  -3.9393e+00 -3.3398e+00 -1.0000e+02
  1.7222e-01 -7.2756e-01 -1.8341e+00  ...  -3.9843e+00 -3.3923e+00 -1.0000e+02
 -4.9283e-01 -1.3714e+00 -2.4131e+00  ...  -4.3506e+00 -3.8303e+00 -1.0000e+02

(1 ,.,.) = 
  1.1726e+00  2.6639e-01 -9.6861e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2157e-01 -1.4306e+00 -2.5506e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2157e-01 -1.4306e+00 -2.5506e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -5.2157e-01 -1.4306e+00 -2.5506e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2157e-01 -1.4306e+00 -2.5506e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2157e-01 -1.4306e+00 -2.5506e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.1802e+00  2.7079e-01 -9.2438e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2964e-01 -1.4420e+00 -2.5281e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2964e-01 -1.4420e+00 -2.5281e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -5.2964e-01 -1.4420e+00 -2.5281e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2964e-01 -1.4420e+00 -2.5281e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2964e-01 -1.4420e+00 -2.5281e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.0680e+00  8.5979e-02 -1.2602e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0257e+00  4.5178e-02 -1.2976e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.0396e-01 -8.1877e-02 -1.4226e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1039e-01 -7.9209e-01 -2.0922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.8899e-01 -1.5612e+00 -2.7606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.8899e-01 -1.5612e+00 -2.7606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.0837e+00  6.9279e-02 -1.0249e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0783e+00  6.6339e-02 -1.0268e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.5480e-01 -1.6864e-01 -1.2595e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7657e-01 -7.6161e-01 -1.8302e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.8044e-01 -1.5867e+00 -2.5722e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.8044e-01 -1.5867e+00 -2.5722e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.2809e+00  3.5452e-01 -7.7412e-01  ...  -4.1698e+00 -3.8899e+00 -2.8449e+00
  1.2122e+00  2.8472e-01 -8.4167e-01  ...  -4.2020e+00 -3.9248e+00 -2.8902e+00
  9.4524e-01  3.2942e-03 -1.1233e+00  ...  -4.3698e+00 -4.1079e+00 -3.1192e+00
                 ...                   ⋱                   ...                
 -4.2254e-01 -1.3594e+00 -2.3929e+00  ...  -5.0086e+00 -4.8190e+00 -4.0604e+00
 -4.2254e-01 -1.3594e+00 -2.3929e+00  ...  -5.0086e+00 -4.8190e+00 -4.0604e+00
 -4.2254e-01 -1.3594e+00 -2.3929e+00  ...  -5.0086e+00 -4.8190e+00 -4.0604e+00
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 1], [7, 0, 18, 0, 56, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.9850   -0.0591   -1.2665  ...  -100.0000 -100.0000 -100.0000
   -0.5443   -1.5762   -2.6608  ...  -100.0000 -100.0000 -100.0000
   -0.5443   -1.5762   -2.6608  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5443   -1.5762   -2.6608  ...  -100.0000 -100.0000 -100.0000
   -0.5443   -1.5762   -2.6608  ...  -100.0000 -100.0000 -100.0000
   -0.5443   -1.5762   -2.6608  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    0.8272   -0.0856   -1.3446  ...    -4.3639   -3.9686   -3.1047
   -0.5933   -1.4929   -2.6351  ...    -5.0257   -4.7314   -4.0770
   -0.5933   -1.4929   -2.6351  ...    -5.0257   -4.7314   -4.0770
              ...                ⋱                ...             
   -0.5933   -1.4929   -2.6351  ...    -5.0257   -4.7314   -4.0770
   -0.5933   -1.4929   -2.6351  ...    -5.0257   -4.7314   -4.0770
   -0.5933   -1.4929   -2.6351  ...    -5.0257   -4.7314   -4.0770

(2 ,.,.) = 
    1.2678    0.2544   -0.9939  ...  -100.0000 -100.0000 -100.0000
   -0.5144   -1.5396   -2.6678  ...  -100.0000 -100.0000 -100.0000
   -0.5144   -1.5396   -2.6678  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.5144   -1.5396   -2.6678  ...  -100.0000 -100.0000 -100.0000
   -0.5144   -1.5396   -2.6678  ...  -100.0000 -100.0000 -100.0000
   -0.5144   -1.5396   -2.6678  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    0.8828   -0.1789   -1.4293  ...  -100.0000 -100.0000 -100.0000
   -0.7190   -1.7542   -2.8589  ...  -100.0000 -100.0000 -100.0000
   -0.7190   -1.7542   -2.8589  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.7190   -1.7542   -2.8589  ...  -100.0000 -100.0000 -100.0000
   -0.7190   -1.7542   -2.8589  ...  -100.0000 -100.0000 -100.0000
   -0.7190   -1.7542   -2.8589  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    0.9481   -0.1485   -1.4063  ...  -100.0000 -100.0000 -100.0000
    0.8164   -0.2848   -1.5378  ...  -100.0000 -100.0000 -100.0000
    0.5786   -0.5304   -1.7720  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2084   -0.9052   -2.1211  ...  -100.0000 -100.0000 -100.0000
   -0.6192   -1.6965   -2.8141  ...  -100.0000 -100.0000 -100.0000
   -0.6192   -1.6965   -2.8141  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    0.9713   -0.0886   -1.3266  ...  -100.0000 -100.0000 -100.0000
   -0.6139   -1.6600   -2.7660  ...  -100.0000 -100.0000 -100.0000
   -0.6139   -1.6600   -2.7660  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.6139   -1.6600   -2.7660  ...  -100.0000 -100.0000 -100.0000
   -0.6139   -1.6600   -2.7660  ...  -100.0000 -100.0000 -100.0000
   -0.6139   -1.6600   -2.7660  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x7x62 (GPU 0)]

gt_where_seq [[7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    1.0258    0.0107   -1.1879  ...  -100.0000 -100.0000 -100.0000
    0.7935   -0.2328   -1.4287  ...  -100.0000 -100.0000 -100.0000
    0.5352   -0.4990   -1.6846  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0186   -1.0192   -2.1700  ...  -100.0000 -100.0000 -100.0000
   -0.0906   -1.1268   -2.2674  ...  -100.0000 -100.0000 -100.0000
   -0.1605   -1.1949   -2.3286  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    1.1588    0.2509   -0.9400  ...    -3.8601   -3.7194   -2.7761
   -0.4802   -1.3979   -2.4920  ...    -4.7858   -4.6789   -3.9813
   -0.4802   -1.3979   -2.4920  ...    -4.7858   -4.6789   -3.9813
              ...                ⋱                ...             
   -0.4802   -1.3979   -2.4920  ...    -4.7858   -4.6789   -3.9813
   -0.4802   -1.3979   -2.4920  ...    -4.7858   -4.6789   -3.9813
   -0.4802   -1.3979   -2.4920  ...    -4.7858   -4.6789   -3.9813

(2 ,.,.) = 
    0.8399   -0.2042   -1.4351  ...    -3.7356   -3.5573   -2.7624
    0.6273   -0.4231   -1.6462  ...    -3.8817   -3.7092   -2.9384
    0.3573   -0.7000   -1.9101  ...    -4.0587   -3.8943   -3.1556
              ...                ⋱                ...             
   -0.0757   -1.1323   -2.3078  ...    -4.3209   -4.1708   -3.4852
   -0.1744   -1.2285   -2.3940  ...    -4.3756   -4.2287   -3.5552
   -0.2429   -1.2946   -2.4524  ...    -4.4122   -4.2676   -3.6026

(3 ,.,.) = 
    1.1347    0.1174   -1.0730  ...  -100.0000 -100.0000 -100.0000
   -0.6197   -1.6387   -2.7086  ...  -100.0000 -100.0000 -100.0000
   -0.6197   -1.6387   -2.7086  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.6197   -1.6387   -2.7086  ...  -100.0000 -100.0000 -100.0000
   -0.6197   -1.6387   -2.7086  ...  -100.0000 -100.0000 -100.0000
   -0.6197   -1.6387   -2.7086  ...  -100.0000 -100.0000 -100.0000

(4 ,.,.) = 
    0.9133   -0.1008   -1.4180  ...    -2.8106 -100.0000 -100.0000
    0.7904   -0.2252   -1.5358  ...    -2.9024 -100.0000 -100.0000
    0.4254   -0.6017   -1.8955  ...    -3.2022 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0476   -0.9803   -2.2432  ...    -3.4878 -100.0000 -100.0000
   -0.0123   -1.0395   -2.2963  ...    -3.5316 -100.0000 -100.0000
   -0.0722   -1.0983   -2.3486  ...    -3.5757 -100.0000 -100.0000

(5 ,.,.) = 
    0.9960    0.0865   -1.2359  ...    -3.4421   -2.6484 -100.0000
   -0.5786   -1.4852   -2.6807  ...    -4.4356   -3.8284 -100.0000
   -0.5786   -1.4852   -2.6807  ...    -4.4356   -3.8284 -100.0000
              ...                ⋱                ...             
   -0.5786   -1.4852   -2.6807  ...    -4.4356   -3.8284 -100.0000
   -0.5786   -1.4852   -2.6807  ...    -4.4356   -3.8284 -100.0000
   -0.5786   -1.4852   -2.6807  ...    -4.4356   -3.8284 -100.0000
[torch.cuda.FloatTensor of size 6x7x59 (GPU 0)]

 Loss = 5.16613188912
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    1.0091    0.0261   -1.2421  ...    -3.5462   -2.8548 -100.0000
    0.6321   -0.3655   -1.6232  ...    -3.8140   -3.1627 -100.0000
    0.3199   -0.6849   -1.9266  ...    -4.0229   -3.4058 -100.0000
              ...                ⋱                ...             
   -0.2063   -1.2075   -2.4009  ...    -4.3408   -3.7824 -100.0000
   -0.2063   -1.2075   -2.4009  ...    -4.3408   -3.7824 -100.0000
   -0.2063   -1.2075   -2.4009  ...    -4.3408   -3.7824 -100.0000

( 1 ,.,.) = 
    1.0282    0.0469   -1.2209  ...  -100.0000 -100.0000 -100.0000
    0.6493   -0.3471   -1.6050  ...  -100.0000 -100.0000 -100.0000
    0.3324   -0.6718   -1.9139  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2055   -1.2064   -2.3998  ...  -100.0000 -100.0000 -100.0000
   -0.2055   -1.2064   -2.3998  ...  -100.0000 -100.0000 -100.0000
   -0.2055   -1.2064   -2.3998  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.0487    0.0686   -1.1990  ...  -100.0000 -100.0000 -100.0000
    0.6642   -0.3316   -1.5900  ...  -100.0000 -100.0000 -100.0000
    0.3459   -0.6582   -1.9012  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2063   -1.2075   -2.4009  ...  -100.0000 -100.0000 -100.0000
   -0.2063   -1.2075   -2.4009  ...  -100.0000 -100.0000 -100.0000
   -0.2063   -1.2075   -2.4009  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.0886    0.1119   -1.1550  ...  -100.0000 -100.0000 -100.0000
    0.6991   -0.2947   -1.5536  ...  -100.0000 -100.0000 -100.0000
    0.3734   -0.6297   -1.8740  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2059   -1.2070   -2.4004  ...  -100.0000 -100.0000 -100.0000
   -0.2059   -1.2070   -2.4004  ...  -100.0000 -100.0000 -100.0000
   -0.2059   -1.2070   -2.4004  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.0978    0.1219   -1.1447  ...  -100.0000 -100.0000 -100.0000
    0.7043   -0.2890   -1.5479  ...  -100.0000 -100.0000 -100.0000
    0.3771   -0.6257   -1.8701  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2056   -1.2066   -2.4000  ...  -100.0000 -100.0000 -100.0000
   -0.2056   -1.2066   -2.4000  ...  -100.0000 -100.0000 -100.0000
   -0.2056   -1.2066   -2.4000  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.0441    0.0640   -1.2033  ...  -100.0000 -100.0000 -100.0000
    0.6575   -0.3384   -1.5963  ...  -100.0000 -100.0000 -100.0000
    0.3401   -0.6639   -1.9064  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2057   -1.2066   -2.4000  ...  -100.0000 -100.0000 -100.0000
   -0.2057   -1.2066   -2.4000  ...  -100.0000 -100.0000 -100.0000
   -0.2057   -1.2066   -2.4000  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.0670e+00  8.8509e-02 -1.1788e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7806e-01 -3.1693e-01 -1.5754e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5572e-01 -6.4794e-01 -1.8914e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0609e-01 -1.2072e+00 -2.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0609e-01 -1.2072e+00 -2.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0609e-01 -1.2072e+00 -2.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.0167e+00  3.4581e-02 -1.2331e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3803e-01 -3.5881e-01 -1.6163e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2431e-01 -6.8003e-01 -1.9217e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0554e-01 -1.2065e+00 -2.3999e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0554e-01 -1.2065e+00 -2.3999e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0554e-01 -1.2065e+00 -2.3999e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.0292e+00  4.7748e-02 -1.2201e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4793e-01 -3.4868e-01 -1.6066e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3221e-01 -6.7212e-01 -1.9143e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0599e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0599e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0599e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.0444e+00  6.4024e-02 -1.2036e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5990e-01 -3.3615e-01 -1.5943e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4224e-01 -6.6189e-01 -1.9047e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0624e-01 -1.2074e+00 -2.4008e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0624e-01 -1.2074e+00 -2.4008e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0624e-01 -1.2074e+00 -2.4008e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  9.3005e-01 -5.8465e-02 -1.3269e+00  ...  -3.3512e+00 -2.7220e+00 -1.0000e+02
  5.6462e-01 -4.3601e-01 -1.6917e+00  ...  -3.6208e+00 -3.0247e+00 -1.0000e+02
  2.6452e-01 -7.4146e-01 -1.9798e+00  ...  -3.8303e+00 -3.2626e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0598e-01 -1.2070e+00 -2.4005e+00  ...  -4.1306e+00 -3.6090e+00 -1.0000e+02
 -2.0598e-01 -1.2070e+00 -2.4005e+00  ...  -4.1306e+00 -3.6090e+00 -1.0000e+02
 -2.0598e-01 -1.2070e+00 -2.4005e+00  ...  -4.1306e+00 -3.6090e+00 -1.0000e+02

(14 ,.,.) = 
  1.0233e+00  4.1228e-02 -1.2268e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4801e-01 -3.4873e-01 -1.6067e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3036e-01 -6.7407e-01 -1.9162e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0603e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0603e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0603e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.0106e+00  2.8084e-02 -1.2398e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3595e-01 -3.6105e-01 -1.6186e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2325e-01 -6.8109e-01 -1.9227e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0516e-01 -1.2060e+00 -2.3993e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0516e-01 -1.2060e+00 -2.3993e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0516e-01 -1.2060e+00 -2.3993e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.0522e+00  7.2437e-02 -1.1951e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6689e-01 -3.2882e-01 -1.5872e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4800e-01 -6.5599e-01 -1.8991e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0630e-01 -1.2075e+00 -2.4009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0630e-01 -1.2075e+00 -2.4009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0630e-01 -1.2075e+00 -2.4009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.0098e+00  2.6742e-02 -1.2414e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3407e-01 -3.6338e-01 -1.6211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2192e-01 -6.8280e-01 -1.9245e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0611e-01 -1.2072e+00 -2.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0611e-01 -1.2072e+00 -2.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0611e-01 -1.2072e+00 -2.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.0221e+00  4.0132e-02 -1.2279e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4497e-01 -3.5190e-01 -1.6100e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3112e-01 -6.7331e-01 -1.9156e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0552e-01 -1.2064e+00 -2.3998e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0552e-01 -1.2064e+00 -2.3998e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0552e-01 -1.2064e+00 -2.3998e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.0043e+00  2.1285e-02 -1.2466e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2838e-01 -3.6901e-01 -1.6264e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.1650e-01 -6.8805e-01 -1.9293e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0542e-01 -1.2063e+00 -2.3997e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0542e-01 -1.2063e+00 -2.3997e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0542e-01 -1.2063e+00 -2.3997e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.0455e+00  6.5287e-02 -1.2024e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.6682e-01 -3.2885e-01 -1.5872e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4739e-01 -6.5655e-01 -1.8996e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.0599e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0599e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0599e-01 -1.2071e+00 -2.4005e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.0112    0.0282   -1.2399  ...    -3.7077   -3.5692   -2.8713
    0.6330   -0.3645   -1.6222  ...    -3.9663   -3.8365   -3.1793
    0.3205   -0.6843   -1.9260  ...    -4.1671   -4.0444   -3.4220
              ...                ⋱                ...             
   -0.2063   -1.2075   -2.4009  ...    -4.4711   -4.3606   -3.7977
   -0.2063   -1.2075   -2.4009  ...    -4.4711   -4.3606   -3.7977
   -0.2063   -1.2075   -2.4009  ...    -4.4711   -4.3606   -3.7977

( 1 ,.,.) = 
    1.0105    0.0277   -1.2403  ...  -100.0000 -100.0000 -100.0000
    0.6352   -0.3621   -1.6197  ...  -100.0000 -100.0000 -100.0000
    0.3231   -0.6815   -1.9232  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2058   -1.2069   -2.4003  ...  -100.0000 -100.0000 -100.0000
   -0.2058   -1.2069   -2.4003  ...  -100.0000 -100.0000 -100.0000
   -0.2058   -1.2069   -2.4003  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.0177    0.0355   -1.2324  ...  -100.0000 -100.0000 -100.0000
    0.6390   -0.3580   -1.6157  ...  -100.0000 -100.0000 -100.0000
    0.3257   -0.6787   -1.9206  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2057   -1.2067   -2.4001  ...  -100.0000 -100.0000 -100.0000
   -0.2057   -1.2067   -2.4001  ...  -100.0000 -100.0000 -100.0000
   -0.2057   -1.2067   -2.4001  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    1.0349    0.0537   -1.2141  ...    -4.1987   -3.9888   -2.9458
    0.6567   -0.3396   -1.5978  ...    -4.4229   -4.2282   -3.2505
    0.3389   -0.6653   -1.9080  ...    -4.5978   -4.4161   -3.4946
              ...                ⋱                ...             
   -0.2064   -1.2075   -2.4010  ...    -4.8606   -4.7013   -3.8781
   -0.2064   -1.2075   -2.4010  ...    -4.8606   -4.7013   -3.8781
   -0.2064   -1.2075   -2.4010  ...    -4.8606   -4.7013   -3.8781

( 4 ,.,.) = 
    0.9519   -0.0352   -1.3036  ...    -2.7327 -100.0000 -100.0000
    0.5893   -0.4102   -1.6668  ...    -3.0328 -100.0000 -100.0000
    0.2863   -0.7192   -1.9589  ...    -3.2730 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2060   -1.2070   -2.4004  ...    -3.6350 -100.0000 -100.0000
   -0.2060   -1.2070   -2.4004  ...    -3.6350 -100.0000 -100.0000
   -0.2060   -1.2070   -2.4004  ...    -3.6350 -100.0000 -100.0000

( 5 ,.,.) = 
    0.9503   -0.0368   -1.3051  ...    -2.7490 -100.0000 -100.0000
    0.5837   -0.4160   -1.6723  ...    -3.0519 -100.0000 -100.0000
    0.2804   -0.7252   -1.9644  ...    -3.2916 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2057   -1.2067   -2.4001  ...    -3.6476 -100.0000 -100.0000
   -0.2057   -1.2067   -2.4001  ...    -3.6476 -100.0000 -100.0000
   -0.2057   -1.2067   -2.4001  ...    -3.6476 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  9.5140e-01 -7.4368e-02 -1.3651e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.6172e-01 -4.7819e-01 -1.7552e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3737e-01 -8.0886e-01 -2.0664e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2331e-01 -1.3617e+00 -2.5621e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2331e-01 -1.3617e+00 -2.5621e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2331e-01 -1.3617e+00 -2.5621e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  9.3051e-01 -9.6602e-02 -1.3874e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5461e-01 -4.8547e-01 -1.7623e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3365e-01 -8.1239e-01 -2.0697e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2195e-01 -1.3599e+00 -2.5604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2195e-01 -1.3599e+00 -2.5604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2195e-01 -1.3599e+00 -2.5604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  9.6280e-01 -6.2477e-02 -1.3533e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.6842e-01 -4.7146e-01 -1.7488e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4164e-01 -8.0480e-01 -2.0627e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2458e-01 -1.3633e+00 -2.5637e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2458e-01 -1.3633e+00 -2.5637e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2458e-01 -1.3633e+00 -2.5637e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  9.2460e-01 -1.0301e-01 -1.3937e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4040e-01 -5.0042e-01 -1.7767e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2074e-01 -8.2574e-01 -2.0821e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2293e-01 -1.3612e+00 -2.5616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2293e-01 -1.3612e+00 -2.5616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2293e-01 -1.3612e+00 -2.5616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  9.6954e-01 -5.4946e-02 -1.3455e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7077e-01 -4.6870e-01 -1.7459e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4333e-01 -8.0283e-01 -2.0607e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2390e-01 -1.3624e+00 -2.5629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2390e-01 -1.3624e+00 -2.5629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2390e-01 -1.3624e+00 -2.5629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  9.5140e-01 -7.4368e-02 -1.3651e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.6172e-01 -4.7819e-01 -1.7552e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3737e-01 -8.0886e-01 -2.0664e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2331e-01 -1.3617e+00 -2.5621e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2331e-01 -1.3617e+00 -2.5621e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2331e-01 -1.3617e+00 -2.5621e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  9.4887e-01 -7.6656e-02 -1.3672e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5997e-01 -4.7959e-01 -1.7563e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3606e-01 -8.0977e-01 -2.0670e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2197e-01 -1.3600e+00 -2.5605e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2197e-01 -1.3600e+00 -2.5605e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2197e-01 -1.3600e+00 -2.5605e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  9.4887e-01 -7.6656e-02 -1.3672e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5997e-01 -4.7959e-01 -1.7563e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3606e-01 -8.0977e-01 -2.0670e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2197e-01 -1.3600e+00 -2.5605e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2197e-01 -1.3600e+00 -2.5605e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2197e-01 -1.3600e+00 -2.5605e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  9.4094e-01 -8.5722e-02 -1.3765e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5238e-01 -4.8811e-01 -1.7648e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2970e-01 -8.1684e-01 -2.0739e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2395e-01 -1.3625e+00 -2.5630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2395e-01 -1.3625e+00 -2.5630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2395e-01 -1.3625e+00 -2.5630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  9.2398e-01 -1.0422e-01 -1.3950e+00  ...  -3.9687e+00 -3.5708e+00 -2.8678e+00
  5.3579e-01 -5.0576e-01 -1.7819e+00  ...  -4.2149e+00 -3.8441e+00 -3.1831e+00
  2.1570e-01 -8.3148e-01 -2.0877e+00  ...  -4.4045e+00 -4.0563e+00 -3.4307e+00
                 ...                   ⋱                   ...                
 -3.2548e-01 -1.3644e+00 -2.5648e+00  ...  -4.6901e+00 -4.3802e+00 -3.8156e+00
 -3.2548e-01 -1.3644e+00 -2.5648e+00  ...  -4.6901e+00 -4.3802e+00 -3.8156e+00
 -3.2548e-01 -1.3644e+00 -2.5648e+00  ...  -4.6901e+00 -4.3802e+00 -3.8156e+00

( 4 ,.,.) = 
  9.0792e-01 -1.2120e-01 -1.4120e+00  ...  -3.5592e+00 -2.8615e+00 -1.0000e+02
  5.2184e-01 -5.2010e-01 -1.7958e+00  ...  -3.8312e+00 -3.1748e+00 -1.0000e+02
  2.0424e-01 -8.4286e-01 -2.0982e+00  ...  -4.0415e+00 -3.4202e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2414e-01 -1.3627e+00 -2.5631e+00  ...  -4.3582e+00 -3.7964e+00 -1.0000e+02
 -3.2414e-01 -1.3627e+00 -2.5631e+00  ...  -4.3582e+00 -3.7964e+00 -1.0000e+02
 -3.2414e-01 -1.3627e+00 -2.5631e+00  ...  -4.3582e+00 -3.7964e+00 -1.0000e+02

( 5 ,.,.) = 
  9.4388e-01 -8.2490e-02 -1.3731e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5298e-01 -4.8744e-01 -1.7641e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3053e-01 -8.1600e-01 -2.0731e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2391e-01 -1.3624e+00 -2.5629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2391e-01 -1.3624e+00 -2.5629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2391e-01 -1.3624e+00 -2.5629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 8 @ 2018-04-12 20:36:06.618877
training
gt_where_seq [[7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 0, 22, 0, 53, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  9.7362e-01  3.9399e-04 -1.2183e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5860e-01 -4.2911e-01 -1.6364e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0451e-01 -7.8792e-01 -1.9739e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -2.6609e-01 -1.2528e+00 -2.3963e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.7934e-01 -1.2656e+00 -2.4074e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8364e-01 -1.2697e+00 -2.4109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.0132e+00  8.2841e-02 -1.2077e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1221e-01 -3.3321e-01 -1.6120e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4852e-01 -6.0272e-01 -1.8684e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -5.1699e-01 -1.4493e+00 -2.6239e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1699e-01 -1.4493e+00 -2.6239e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1699e-01 -1.4493e+00 -2.6239e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.2365e+00  2.7564e-01 -9.6783e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6057e-01 -1.3438e+00 -2.4939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6057e-01 -1.3438e+00 -2.4939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.6057e-01 -1.3438e+00 -2.4939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6057e-01 -1.3438e+00 -2.4939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6057e-01 -1.3438e+00 -2.4939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.1474e+00  1.5776e-01 -1.1116e+00  ...  -3.4214e+00 -3.2905e+00 -2.5721e+00
  6.6449e-01 -3.4744e-01 -1.6070e+00  ...  -3.7784e+00 -3.6588e+00 -2.9901e+00
  3.7652e-01 -6.4215e-01 -1.8880e+00  ...  -3.9707e+00 -3.8579e+00 -3.2190e+00
                 ...                   ⋱                   ...                
 -6.5790e-02 -1.0847e+00 -2.2933e+00  ...  -4.2476e+00 -4.1455e+00 -3.5547e+00
 -4.2452e-01 -1.4269e+00 -2.5897e+00  ...  -4.4315e+00 -4.3369e+00 -3.7848e+00
 -4.2452e-01 -1.4269e+00 -2.5897e+00  ...  -4.4315e+00 -4.3369e+00 -3.7848e+00

(13,.,.) = 
  9.2992e-01 -1.2545e-01 -1.3189e+00  ...  -3.2292e+00 -2.8048e+00 -1.0000e+02
 -5.9609e-01 -1.6433e+00 -2.7177e+00  ...  -4.2545e+00 -3.9298e+00 -1.0000e+02
 -5.9609e-01 -1.6433e+00 -2.7177e+00  ...  -4.2545e+00 -3.9298e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -5.9609e-01 -1.6433e+00 -2.7177e+00  ...  -4.2545e+00 -3.9298e+00 -1.0000e+02
 -5.9609e-01 -1.6433e+00 -2.7177e+00  ...  -4.2545e+00 -3.9298e+00 -1.0000e+02
 -5.9609e-01 -1.6433e+00 -2.7177e+00  ...  -4.2545e+00 -3.9298e+00 -1.0000e+02

(14,.,.) = 
  8.6966e-01 -2.0771e-01 -1.5711e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6561e-01 -6.2454e-01 -1.9674e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8669e-01 -9.0706e-01 -2.2289e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -6.4085e-01 -1.7029e+00 -2.9166e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -6.4085e-01 -1.7029e+00 -2.9166e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -6.4085e-01 -1.7029e+00 -2.9166e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 0, 24, 0, 60, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.0535e+00  1.8681e-01 -1.0304e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.0917e-01 -1.2892e+00 -2.4200e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.0917e-01 -1.2892e+00 -2.4200e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -4.0917e-01 -1.2892e+00 -2.4200e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.0917e-01 -1.2892e+00 -2.4200e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.0917e-01 -1.2892e+00 -2.4200e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.1123e+00  1.8596e-01 -1.0502e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.7428e-01 -1.3168e+00 -2.4630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.7428e-01 -1.3168e+00 -2.4630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.7428e-01 -1.3168e+00 -2.4630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.7428e-01 -1.3168e+00 -2.4630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.7428e-01 -1.3168e+00 -2.4630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  8.9436e-01 -8.4623e-03 -1.1687e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.1332e-01 -4.0088e-01 -1.5519e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.9876e-02 -8.3130e-01 -1.9619e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -5.1101e-01 -1.4163e+00 -2.4872e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1101e-01 -1.4163e+00 -2.4872e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1101e-01 -1.4163e+00 -2.4872e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.0775e+00  2.0461e-01 -1.0671e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4167e-01 -1.2279e+00 -2.4115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4167e-01 -1.2279e+00 -2.4115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.4167e-01 -1.2279e+00 -2.4115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4167e-01 -1.2279e+00 -2.4115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4167e-01 -1.2279e+00 -2.4115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.1322e+00  2.0009e-01 -8.9988e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2445e-01 -1.2761e+00 -2.3045e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2445e-01 -1.2761e+00 -2.3045e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -3.2445e-01 -1.2761e+00 -2.3045e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2445e-01 -1.2761e+00 -2.3045e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2445e-01 -1.2761e+00 -2.3045e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.1592e+00  2.5458e-01 -8.6585e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9139e-01 -2.3583e-01 -1.3540e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7531e-01 -5.5994e-01 -1.6674e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.4423e-02 -1.0210e+00 -2.0990e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.0705e-01 -1.0434e+00 -2.1195e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5403e-01 -1.2795e+00 -2.3279e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x8x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 55, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.9270    0.0190   -1.2091  ...  -100.0000 -100.0000 -100.0000
   -0.3681   -1.2808   -2.4185  ...  -100.0000 -100.0000 -100.0000
   -0.3681   -1.2808   -2.4185  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.3681   -1.2808   -2.4185  ...  -100.0000 -100.0000 -100.0000
   -0.3681   -1.2808   -2.4185  ...  -100.0000 -100.0000 -100.0000
   -0.3681   -1.2808   -2.4185  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    1.1078    0.2206   -0.9518  ...    -3.1734   -2.5676 -100.0000
   -0.3043   -1.2105   -2.3096  ...    -4.1472   -3.6714 -100.0000
   -0.3043   -1.2105   -2.3096  ...    -4.1472   -3.6714 -100.0000
              ...                ⋱                ...             
   -0.3043   -1.2105   -2.3096  ...    -4.1472   -3.6714 -100.0000
   -0.3043   -1.2105   -2.3096  ...    -4.1472   -3.6714 -100.0000
   -0.3043   -1.2105   -2.3096  ...    -4.1472   -3.6714 -100.0000

(2 ,.,.) = 
    1.2442    0.4137   -0.8795  ...    -3.5788   -3.3581   -2.9013
   -0.1641   -1.0272   -2.2576  ...    -4.4749   -4.3050   -3.9474
   -0.1641   -1.0272   -2.2576  ...    -4.4749   -4.3050   -3.9474
              ...                ⋱                ...             
   -0.1641   -1.0272   -2.2576  ...    -4.4749   -4.3050   -3.9474
   -0.1641   -1.0272   -2.2576  ...    -4.4749   -4.3050   -3.9474
   -0.1641   -1.0272   -2.2576  ...    -4.4749   -4.3050   -3.9474
...

(12,.,.) = 
    1.2706    0.3610   -0.9137  ...  -100.0000 -100.0000 -100.0000
   -0.2124   -1.1584   -2.3605  ...  -100.0000 -100.0000 -100.0000
   -0.2124   -1.1584   -2.3605  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.2124   -1.1584   -2.3605  ...  -100.0000 -100.0000 -100.0000
   -0.2124   -1.1584   -2.3605  ...  -100.0000 -100.0000 -100.0000
   -0.2124   -1.1584   -2.3605  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    1.0954    0.3838   -0.8614  ...    -3.4675   -2.9336 -100.0000
    0.5201   -0.2131   -1.4556  ...    -3.8844   -3.3999 -100.0000
    0.2151   -0.5231   -1.7520  ...    -4.0796   -3.6219 -100.0000
              ...                ⋱                ...             
   -0.0302   -0.7691   -1.9801  ...    -4.2267   -3.7910 -100.0000
   -0.2354   -0.9692   -2.1563  ...    -4.3355   -3.9184 -100.0000
   -0.2354   -0.9692   -2.1563  ...    -4.3355   -3.9184 -100.0000

(14,.,.) = 
    1.0862    0.3509   -0.8112  ...    -3.8517   -2.7646 -100.0000
   -0.3278   -1.0863   -2.1912  ...    -4.6778   -3.8419 -100.0000
   -0.3278   -1.0863   -2.1912  ...    -4.6778   -3.8419 -100.0000
              ...                ⋱                ...             
   -0.3278   -1.0863   -2.1912  ...    -4.6778   -3.8419 -100.0000
   -0.3278   -1.0863   -2.1912  ...    -4.6778   -3.8419 -100.0000
   -0.3278   -1.0863   -2.1912  ...    -4.6778   -3.8419 -100.0000
[torch.cuda.FloatTensor of size 15x7x59 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    1.2098    0.4491   -0.6250  ...    -3.7548   -3.6047   -2.8460
   -0.2074   -1.0032   -2.0416  ...    -4.6211   -4.5108   -3.9267
   -0.2074   -1.0032   -2.0416  ...    -4.6211   -4.5108   -3.9267
   -0.2074   -1.0032   -2.0416  ...    -4.6211   -4.5108   -3.9267
   -0.2074   -1.0032   -2.0416  ...    -4.6211   -4.5108   -3.9267

(1 ,.,.) = 
    1.1738    0.4499   -0.7325  ...    -2.9726 -100.0000 -100.0000
   -0.0997   -0.8546   -2.0004  ...    -3.9132 -100.0000 -100.0000
   -0.0997   -0.8546   -2.0004  ...    -3.9132 -100.0000 -100.0000
   -0.0997   -0.8546   -2.0004  ...    -3.9132 -100.0000 -100.0000
   -0.0997   -0.8546   -2.0004  ...    -3.9132 -100.0000 -100.0000

(2 ,.,.) = 
    1.2823    0.5408   -0.6485  ...  -100.0000 -100.0000 -100.0000
    0.5923   -0.1797   -1.3709  ...  -100.0000 -100.0000 -100.0000
    0.3213   -0.4562   -1.6368  ...  -100.0000 -100.0000 -100.0000
    0.1818   -0.5970   -1.7696  ...  -100.0000 -100.0000 -100.0000
    0.1177   -0.6612   -1.8286  ...  -100.0000 -100.0000 -100.0000

(3 ,.,.) = 
    1.2598    0.5150   -0.6373  ...  -100.0000 -100.0000 -100.0000
   -0.2171   -1.0010   -2.1127  ...  -100.0000 -100.0000 -100.0000
   -0.2171   -1.0010   -2.1127  ...  -100.0000 -100.0000 -100.0000
   -0.2171   -1.0010   -2.1127  ...  -100.0000 -100.0000 -100.0000
   -0.2171   -1.0010   -2.1127  ...  -100.0000 -100.0000 -100.0000

(4 ,.,.) = 
    1.0647    0.2990   -0.8194  ...    -3.2861   -3.2314   -2.8588
   -0.1283   -0.9162   -1.9903  ...    -4.1079   -4.0587   -3.7600
   -0.1283   -0.9162   -1.9903  ...    -4.1079   -4.0587   -3.7600
   -0.1283   -0.9162   -1.9903  ...    -4.1079   -4.0587   -3.7600
   -0.1283   -0.9162   -1.9903  ...    -4.1079   -4.0587   -3.7600

(5 ,.,.) = 
    1.2003    0.4507   -0.7338  ...  -100.0000 -100.0000 -100.0000
   -0.0933   -0.8762   -2.0200  ...  -100.0000 -100.0000 -100.0000
   -0.0933   -0.8762   -2.0200  ...  -100.0000 -100.0000 -100.0000
   -0.0933   -0.8762   -2.0200  ...  -100.0000 -100.0000 -100.0000
   -0.0933   -0.8762   -2.0200  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x5x61 (GPU 0)]

 Loss = 5.02324140773
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    1.2981    0.6326   -0.4021  ...    -3.1430   -2.7314 -100.0000
    0.5508   -0.1455   -1.1901  ...    -3.7145   -3.3500 -100.0000
    0.2108   -0.4920   -1.5277  ...    -3.9407   -3.5981 -100.0000
              ...                ⋱                ...             
    0.2203   -0.4864   -1.5239  ...    -3.9505   -3.6075 -100.0000
    0.2203   -0.4864   -1.5239  ...    -3.9505   -3.6075 -100.0000
    0.2203   -0.4864   -1.5239  ...    -3.9505   -3.6075 -100.0000

( 1 ,.,.) = 
    1.3156    0.6517   -0.3816  ...  -100.0000 -100.0000 -100.0000
    0.5610   -0.1346   -1.1788  ...  -100.0000 -100.0000 -100.0000
    0.2130   -0.4894   -1.5249  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2208   -0.4859   -1.5232  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4859   -1.5232  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4859   -1.5232  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.3443    0.6828   -0.3481  ...  -100.0000 -100.0000 -100.0000
    0.5712   -0.1238   -1.1677  ...  -100.0000 -100.0000 -100.0000
    0.2179   -0.4843   -1.5199  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2203   -0.4864   -1.5240  ...  -100.0000 -100.0000 -100.0000
    0.2203   -0.4864   -1.5240  ...  -100.0000 -100.0000 -100.0000
    0.2203   -0.4864   -1.5240  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.3855    0.7276   -0.2998  ...  -100.0000 -100.0000 -100.0000
    0.5938   -0.0999   -1.1432  ...  -100.0000 -100.0000 -100.0000
    0.2270   -0.4748   -1.5103  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2205   -0.4862   -1.5237  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4862   -1.5237  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4862   -1.5237  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.3941    0.7371   -0.2892  ...  -100.0000 -100.0000 -100.0000
    0.5932   -0.1001   -1.1432  ...  -100.0000 -100.0000 -100.0000
    0.2258   -0.4758   -1.5111  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2207   -0.4859   -1.5233  ...  -100.0000 -100.0000 -100.0000
    0.2207   -0.4859   -1.5233  ...  -100.0000 -100.0000 -100.0000
    0.2207   -0.4859   -1.5233  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.3321    0.6699   -0.3615  ...  -100.0000 -100.0000 -100.0000
    0.5621   -0.1331   -1.1769  ...  -100.0000 -100.0000 -100.0000
    0.2137   -0.4885   -1.5239  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2207   -0.4860   -1.5233  ...  -100.0000 -100.0000 -100.0000
    0.2207   -0.4860   -1.5233  ...  -100.0000 -100.0000 -100.0000
    0.2207   -0.4860   -1.5233  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.3581    0.6979   -0.3318  ...  -100.0000 -100.0000 -100.0000
    0.5754   -0.1192   -1.1629  ...  -100.0000 -100.0000 -100.0000
    0.2184   -0.4837   -1.5192  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2205   -0.4863   -1.5237  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4863   -1.5237  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4863   -1.5237  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.3009    0.6360   -0.3980  ...  -100.0000 -100.0000 -100.0000
    0.5507   -0.1452   -1.1894  ...  -100.0000 -100.0000 -100.0000
    0.2091   -0.4935   -1.5288  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2208   -0.4859   -1.5232  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4859   -1.5232  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4859   -1.5232  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.3185    0.6549   -0.3780  ...  -100.0000 -100.0000 -100.0000
    0.5588   -0.1368   -1.1810  ...  -100.0000 -100.0000 -100.0000
    0.2129   -0.4896   -1.5252  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2205   -0.4862   -1.5236  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4862   -1.5236  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4862   -1.5236  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.3396    0.6777   -0.3536  ...  -100.0000 -100.0000 -100.0000
    0.5682   -0.1269   -1.1708  ...  -100.0000 -100.0000 -100.0000
    0.2165   -0.4858   -1.5213  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2204   -0.4864   -1.5239  ...  -100.0000 -100.0000 -100.0000
    0.2204   -0.4864   -1.5239  ...  -100.0000 -100.0000 -100.0000
    0.2204   -0.4864   -1.5239  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.2054    0.5326   -0.5086  ...    -2.9422   -2.6098 -100.0000
    0.5110   -0.1876   -1.2330  ...    -3.4899   -3.1910 -100.0000
    0.1990   -0.5047   -1.5405  ...    -3.7082   -3.4248 -100.0000
              ...                ⋱                ...             
    0.2205   -0.4862   -1.5236  ...    -3.7060   -3.4215 -100.0000
    0.2205   -0.4862   -1.5236  ...    -3.7060   -3.4215 -100.0000
    0.2205   -0.4862   -1.5236  ...    -3.7060   -3.4215 -100.0000

(14 ,.,.) = 
    1.3200    0.6562   -0.3770  ...  -100.0000 -100.0000 -100.0000
    0.5645   -0.1311   -1.1755  ...  -100.0000 -100.0000 -100.0000
    0.2138   -0.4888   -1.5244  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2205   -0.4863   -1.5238  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4863   -1.5238  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4863   -1.5238  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.2978    0.6325   -0.4020  ...  -100.0000 -100.0000 -100.0000
    0.5541   -0.1419   -1.1863  ...  -100.0000 -100.0000 -100.0000
    0.2122   -0.4904   -1.5259  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2210   -0.4856   -1.5229  ...  -100.0000 -100.0000 -100.0000
    0.2210   -0.4856   -1.5229  ...  -100.0000 -100.0000 -100.0000
    0.2210   -0.4856   -1.5229  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.3472    0.6860   -0.3447  ...  -100.0000 -100.0000 -100.0000
    0.5722   -0.1226   -1.1665  ...  -100.0000 -100.0000 -100.0000
    0.2182   -0.4841   -1.5197  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2203   -0.4864   -1.5240  ...  -100.0000 -100.0000 -100.0000
    0.2203   -0.4864   -1.5240  ...  -100.0000 -100.0000 -100.0000
    0.2203   -0.4864   -1.5240  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.3037    0.6387   -0.3956  ...  -100.0000 -100.0000 -100.0000
    0.5545   -0.1415   -1.1860  ...  -100.0000 -100.0000 -100.0000
    0.2124   -0.4903   -1.5260  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2204   -0.4863   -1.5238  ...  -100.0000 -100.0000 -100.0000
    0.2204   -0.4863   -1.5238  ...  -100.0000 -100.0000 -100.0000
    0.2204   -0.4863   -1.5238  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.3055    0.6407   -0.3935  ...  -100.0000 -100.0000 -100.0000
    0.5567   -0.1394   -1.1839  ...  -100.0000 -100.0000 -100.0000
    0.2151   -0.4875   -1.5233  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2208   -0.4858   -1.5232  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4858   -1.5232  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4858   -1.5232  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.2895    0.6235   -0.4115  ...  -100.0000 -100.0000 -100.0000
    0.5466   -0.1497   -1.1941  ...  -100.0000 -100.0000 -100.0000
    0.2083   -0.4944   -1.5298  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2208   -0.4858   -1.5231  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4858   -1.5231  ...  -100.0000 -100.0000 -100.0000
    0.2208   -0.4858   -1.5231  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.3465    0.6852   -0.3457  ...  -100.0000 -100.0000 -100.0000
    0.5763   -0.1185   -1.1625  ...  -100.0000 -100.0000 -100.0000
    0.2201   -0.4821   -1.5178  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2205   -0.4862   -1.5237  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4862   -1.5237  ...  -100.0000 -100.0000 -100.0000
    0.2205   -0.4862   -1.5237  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.3045    0.6396   -0.3946  ...    -3.2026   -3.1831   -2.7561
    0.5523   -0.1438   -1.1883  ...    -3.7727   -3.7539   -3.3765
    0.2112   -0.4916   -1.5272  ...    -3.9973   -3.9788   -3.6242
              ...                ⋱                ...             
    0.2203   -0.4865   -1.5240  ...    -4.0080   -3.9890   -3.6341
    0.2203   -0.4865   -1.5240  ...    -4.0080   -3.9890   -3.6341
    0.2203   -0.4865   -1.5240  ...    -4.0080   -3.9890   -3.6341

( 1 ,.,.) = 
    1.3014    0.6364   -0.3979  ...  -100.0000 -100.0000 -100.0000
    0.5532   -0.1428   -1.1872  ...  -100.0000 -100.0000 -100.0000
    0.2115   -0.4911   -1.5267  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2206   -0.4861   -1.5235  ...  -100.0000 -100.0000 -100.0000
    0.2206   -0.4861   -1.5235  ...  -100.0000 -100.0000 -100.0000
    0.2206   -0.4861   -1.5235  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.3055    0.6408   -0.3930  ...  -100.0000 -100.0000 -100.0000
    0.5534   -0.1426   -1.1869  ...  -100.0000 -100.0000 -100.0000
    0.2118   -0.4908   -1.5264  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2207   -0.4860   -1.5234  ...  -100.0000 -100.0000 -100.0000
    0.2207   -0.4860   -1.5234  ...  -100.0000 -100.0000 -100.0000
    0.2207   -0.4860   -1.5234  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    1.3330    0.6705   -0.3614  ...    -3.8266   -3.7333   -2.8311
    0.5682   -0.1270   -1.1711  ...    -4.3244   -4.2434   -3.4559
    0.2160   -0.4864   -1.5221  ...    -4.5177   -4.4426   -3.7081
              ...                ⋱                ...             
    0.2203   -0.4865   -1.5240  ...    -4.5274   -4.4535   -3.7231
    0.2203   -0.4865   -1.5240  ...    -4.5274   -4.4535   -3.7231
    0.2203   -0.4865   -1.5240  ...    -4.5274   -4.4535   -3.7231

( 4 ,.,.) = 
    1.2339    0.5631   -0.4764  ...    -2.6099 -100.0000 -100.0000
    0.5283   -0.1695   -1.2147  ...    -3.2013 -100.0000 -100.0000
    0.2050   -0.4984   -1.5342  ...    -3.4434 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2205   -0.4862   -1.5237  ...    -3.4460 -100.0000 -100.0000
    0.2205   -0.4862   -1.5237  ...    -3.4460 -100.0000 -100.0000
    0.2205   -0.4862   -1.5237  ...    -3.4460 -100.0000 -100.0000

( 5 ,.,.) = 
    1.2253    0.5541   -0.4858  ...    -2.6257 -100.0000 -100.0000
    0.5205   -0.1775   -1.2227  ...    -3.2150 -100.0000 -100.0000
    0.2016   -0.5018   -1.5375  ...    -3.4532 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2207   -0.4860   -1.5234  ...    -3.4526 -100.0000 -100.0000
    0.2207   -0.4860   -1.5234  ...    -3.4526 -100.0000 -100.0000
    0.2207   -0.4860   -1.5234  ...    -3.4526 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  1.2891e+00  5.8029e-01 -5.0344e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0500e-01 -2.3761e-01 -1.3287e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4508e-01 -6.0403e-01 -1.6830e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4143e-01 -6.1206e-01 -1.6919e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4143e-01 -6.1206e-01 -1.6919e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4143e-01 -6.1206e-01 -1.6919e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.2771e+00  5.6700e-01 -5.1802e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.1104e-01 -2.3149e-01 -1.3228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5152e-01 -5.9747e-01 -1.6766e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4206e-01 -6.1120e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4206e-01 -6.1120e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4206e-01 -6.1120e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.3033e+00  5.9550e-01 -4.8737e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0878e-01 -2.3376e-01 -1.3249e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4533e-01 -6.0393e-01 -1.6830e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4066e-01 -6.1315e-01 -1.6933e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4066e-01 -6.1315e-01 -1.6933e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4066e-01 -6.1315e-01 -1.6933e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.2629e+00  5.5177e-01 -5.3391e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9300e-01 -2.5027e-01 -1.3415e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4091e-01 -6.0839e-01 -1.6872e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4164e-01 -6.1178e-01 -1.6915e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4164e-01 -6.1178e-01 -1.6915e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4164e-01 -6.1178e-01 -1.6915e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.3091e+00  6.0213e-01 -4.7984e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0776e-01 -2.3452e-01 -1.3253e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4405e-01 -6.0501e-01 -1.6838e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4105e-01 -6.1263e-01 -1.6926e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4105e-01 -6.1263e-01 -1.6926e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4105e-01 -6.1263e-01 -1.6926e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.2891e+00  5.8029e-01 -5.0344e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0500e-01 -2.3761e-01 -1.3287e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4508e-01 -6.0403e-01 -1.6830e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4143e-01 -6.1206e-01 -1.6919e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4143e-01 -6.1206e-01 -1.6919e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4143e-01 -6.1206e-01 -1.6919e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.2873e+00  5.7851e-01 -5.0504e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0443e-01 -2.3796e-01 -1.3288e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4501e-01 -6.0387e-01 -1.6825e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4215e-01 -6.1113e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4215e-01 -6.1113e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4215e-01 -6.1113e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.2873e+00  5.7851e-01 -5.0504e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.0443e-01 -2.3796e-01 -1.3288e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4501e-01 -6.0387e-01 -1.6825e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4215e-01 -6.1113e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4215e-01 -6.1113e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4215e-01 -6.1113e-01 -1.6908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.2792e+00  5.6932e-01 -5.1532e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9933e-01 -2.4376e-01 -1.3351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4256e-01 -6.0685e-01 -1.6859e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4098e-01 -6.1275e-01 -1.6928e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4098e-01 -6.1275e-01 -1.6928e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4098e-01 -6.1275e-01 -1.6928e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  1.2568e+00  5.4484e-01 -5.4161e-01  ...  -3.4944e+00 -3.1730e+00 -2.7433e+00
  4.8739e-01 -2.5653e-01 -1.3482e+00  ...  -4.0389e+00 -3.7566e+00 -3.3772e+00
  1.3716e-01 -6.1268e-01 -1.6918e+00  ...  -4.2518e+00 -3.9873e+00 -3.6312e+00
                 ...                   ⋱                   ...                
  1.4018e-01 -6.1372e-01 -1.6939e+00  ...  -4.2657e+00 -4.0021e+00 -3.6457e+00
  1.4018e-01 -6.1372e-01 -1.6939e+00  ...  -4.2657e+00 -4.0021e+00 -3.6457e+00
  1.4018e-01 -6.1372e-01 -1.6939e+00  ...  -4.2657e+00 -4.0021e+00 -3.6457e+00

( 4 ,.,.) = 
  1.2407e+00  5.2756e-01 -5.5990e-01  ...  -3.1605e+00 -2.7411e+00 -1.0000e+02
  4.7814e-01 -2.6604e-01 -1.3575e+00  ...  -3.7385e+00 -3.3681e+00 -1.0000e+02
  1.3316e-01 -6.1657e-01 -1.6954e+00  ...  -3.9658e+00 -3.6181e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4095e-01 -6.1268e-01 -1.6926e+00  ...  -3.9765e+00 -3.6285e+00 -1.0000e+02
  1.4095e-01 -6.1268e-01 -1.6926e+00  ...  -3.9765e+00 -3.6285e+00 -1.0000e+02
  1.4095e-01 -6.1268e-01 -1.6926e+00  ...  -3.9765e+00 -3.6285e+00 -1.0000e+02

( 5 ,.,.) = 
  1.2780e+00  5.6813e-01 -5.1638e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9691e-01 -2.4621e-01 -1.3374e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4195e-01 -6.0744e-01 -1.6864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4112e-01 -6.1254e-01 -1.6925e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4112e-01 -6.1254e-01 -1.6925e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4112e-01 -6.1254e-01 -1.6925e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 9 @ 2018-04-12 20:36:09.154894
training
gt_where_seq [[7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.3110e+00  5.9274e-01 -4.3584e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1552e-02 -6.9884e-01 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1552e-02 -6.9884e-01 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.1552e-02 -6.9884e-01 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1552e-02 -6.9884e-01 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1552e-02 -6.9884e-01 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.2770e+00  5.5028e-01 -4.0463e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7504e-01 -1.8097e-01 -1.1417e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7884e-01 -5.8646e-01 -1.5385e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.3984e-02 -7.3303e-01 -1.6781e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.8567e-02 -6.6963e-01 -1.6185e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1841e-01 -6.5030e-01 -1.6001e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.2345e+00  5.3879e-01 -4.4975e-01  ...  -3.0194e+00 -3.1527e+00 -2.6326e+00
  5.3064e-01 -1.9161e-01 -1.1850e+00  ...  -3.5678e+00 -3.6844e+00 -3.2205e+00
  2.4950e-01 -4.7814e-01 -1.4644e+00  ...  -3.7637e+00 -3.8732e+00 -3.4322e+00
                 ...                   ⋱                   ...                
  8.3685e-02 -6.4565e-01 -1.6241e+00  ...  -3.8752e+00 -3.9801e+00 -3.5532e+00
  9.9195e-02 -6.3079e-01 -1.6100e+00  ...  -3.8673e+00 -3.9723e+00 -3.5442e+00
  1.5668e-01 -5.7400e-01 -1.5564e+00  ...  -3.8336e+00 -3.9397e+00 -3.5072e+00
...

(12,.,.) = 
  1.2826e+00  6.1421e-01 -4.1332e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1265e-01 -8.4731e-02 -1.1235e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1388e-01 -4.9230e-01 -1.5223e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.9598e-02 -6.2832e-01 -1.6515e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0737e-01 -6.0121e-01 -1.6258e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1858e-01 -5.9016e-01 -1.6150e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.3669e+00  6.8738e-01 -4.0727e-01  ...  -2.9668e+00 -2.6676e+00 -1.0000e+02
  6.2461e-02 -6.6048e-01 -1.7449e+00  ...  -3.9483e+00 -3.7073e+00 -1.0000e+02
  6.2461e-02 -6.6048e-01 -1.7449e+00  ...  -3.9483e+00 -3.7073e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2461e-02 -6.6048e-01 -1.7449e+00  ...  -3.9483e+00 -3.7073e+00 -1.0000e+02
  6.2461e-02 -6.6048e-01 -1.7449e+00  ...  -3.9483e+00 -3.7073e+00 -1.0000e+02
  6.2461e-02 -6.6048e-01 -1.7449e+00  ...  -3.9483e+00 -3.7073e+00 -1.0000e+02

(14,.,.) = 
  1.2685e+00  5.7167e-01 -4.3582e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7319e-02 -6.7621e-01 -1.6723e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7319e-02 -6.7621e-01 -1.6723e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.7319e-02 -6.7621e-01 -1.6723e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7319e-02 -6.7621e-01 -1.6723e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7319e-02 -6.7621e-01 -1.6723e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x62 (GPU 0)]

gt_where_seq [[7, 0, 22, 0, 53, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.3558e+00  7.8197e-01 -1.9979e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.1800e-01 -8.7565e-02 -9.0675e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6151e-01 -3.4919e-01 -1.1662e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.8813e-01 -4.2573e-01 -1.2411e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8813e-01 -4.2573e-01 -1.2411e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8813e-01 -4.2573e-01 -1.2411e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.4193e+00  8.1762e-01 -1.0818e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3111e-01 -2.4632e-03 -9.4585e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4510e-01 -3.9687e-01 -1.3348e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.1768e-01 -3.2692e-01 -1.2688e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6772e-01 -3.7663e-01 -1.3150e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6772e-01 -3.7663e-01 -1.3150e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.4251e+00  9.1403e-01  1.0614e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5958e-01  1.2073e-01 -7.0902e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3745e-01 -2.0848e-01 -1.0383e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.8330e-01 -2.6644e-01 -1.0972e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7201e-01 -2.7758e-01 -1.1067e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7201e-01 -2.7758e-01 -1.1067e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.4372e+00  8.6258e-01 -3.7259e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9258e-01 -4.2965e-01 -1.3487e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9258e-01 -4.2965e-01 -1.3487e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.9258e-01 -4.2965e-01 -1.3487e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9258e-01 -4.2965e-01 -1.3487e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9258e-01 -4.2965e-01 -1.3487e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.5579e+00  9.5921e-01  1.6654e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.1693e-01 -3.3603e-01 -1.1539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.1693e-01 -3.3603e-01 -1.1539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.1693e-01 -3.3603e-01 -1.1539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.1693e-01 -3.3603e-01 -1.1539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.1693e-01 -3.3603e-01 -1.1539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.4007e+00  9.2067e-01  3.6122e-02  ...  -2.7967e+00 -1.0000e+02 -1.0000e+02
  2.2330e-01 -2.9599e-01 -1.2039e+00  ...  -3.7394e+00 -1.0000e+02 -1.0000e+02
  2.2330e-01 -2.9599e-01 -1.2039e+00  ...  -3.7394e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.2330e-01 -2.9599e-01 -1.2039e+00  ...  -3.7394e+00 -1.0000e+02 -1.0000e+02
  2.2330e-01 -2.9599e-01 -1.2039e+00  ...  -3.7394e+00 -1.0000e+02 -1.0000e+02
  2.2330e-01 -2.9599e-01 -1.2039e+00  ...  -3.7394e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 18, 0, 56, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.4899e+00  1.0028e+00  1.8068e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2314e-01 -2.0700e-01 -1.0572e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2314e-01 -2.0700e-01 -1.0572e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.2314e-01 -2.0700e-01 -1.0572e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2314e-01 -2.0700e-01 -1.0572e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2314e-01 -2.0700e-01 -1.0572e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.4999e+00  1.0671e+00  2.1034e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9040e-01  2.3056e-02 -8.6813e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0812e-01 -2.6350e-01 -1.1521e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.2522e-01 -1.4894e-01 -1.0420e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2522e-01 -1.4894e-01 -1.0420e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.2522e-01 -1.4894e-01 -1.0420e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.4054e+00  9.6993e-01  2.5599e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5662e-01 -1.1234e-01 -8.5065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5662e-01 -1.1234e-01 -8.5065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.5662e-01 -1.1234e-01 -8.5065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5662e-01 -1.1234e-01 -8.5065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5662e-01 -1.1234e-01 -8.5065e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.5283e+00  1.0997e+00  2.8397e-01  ...  -3.6637e+00 -3.0746e+00 -2.5737e+00
  3.0755e-01 -1.6413e-01 -1.0212e+00  ...  -4.4783e+00 -4.0164e+00 -3.6108e+00
  3.0755e-01 -1.6413e-01 -1.0212e+00  ...  -4.4783e+00 -4.0164e+00 -3.6108e+00
                 ...                   ⋱                   ...                
  3.0755e-01 -1.6413e-01 -1.0212e+00  ...  -4.4783e+00 -4.0164e+00 -3.6108e+00
  3.0755e-01 -1.6413e-01 -1.0212e+00  ...  -4.4783e+00 -4.0164e+00 -3.6108e+00
  3.0755e-01 -1.6413e-01 -1.0212e+00  ...  -4.4783e+00 -4.0164e+00 -3.6108e+00

(13,.,.) = 
  1.3661e+00  8.8339e-01  1.5142e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3463e-01  2.3119e-02 -7.3023e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5840e-01 -2.5752e-01 -1.0092e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.7835e-01 -1.3992e-01 -8.9550e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7835e-01 -1.3992e-01 -8.9550e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7835e-01 -1.3992e-01 -8.9550e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.4570e+00  1.0401e+00  2.0368e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.6547e-01 -8.9160e-02 -9.6143e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.6547e-01 -8.9160e-02 -9.6143e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.6547e-01 -8.9160e-02 -9.6143e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.6547e-01 -8.9160e-02 -9.6143e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.6547e-01 -8.9160e-02 -9.6143e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x8x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 24, 0, 60, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.4179e+00  1.0256e+00  2.9658e-01  ...  -2.7639e+00 -1.0000e+02 -1.0000e+02
  4.4318e-01  1.8877e-02 -7.3936e-01  ...  -3.5607e+00 -1.0000e+02 -1.0000e+02
  4.4318e-01  1.8877e-02 -7.3936e-01  ...  -3.5607e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.4318e-01  1.8877e-02 -7.3936e-01  ...  -3.5607e+00 -1.0000e+02 -1.0000e+02
  4.4318e-01  1.8877e-02 -7.3936e-01  ...  -3.5607e+00 -1.0000e+02 -1.0000e+02
  4.4318e-01  1.8877e-02 -7.3936e-01  ...  -3.5607e+00 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.3764e+00  9.8082e-01  3.3240e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9430e-01 -2.7923e-02 -6.9975e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5040e-01 -2.7440e-01 -9.4475e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.7221e-01 -5.4637e-02 -7.3046e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7221e-01 -5.4637e-02 -7.3046e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7221e-01 -5.4637e-02 -7.3046e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.3767e+00  9.8813e-01  1.8414e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5416e-01 -6.1665e-02 -8.9276e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0338e-01 -3.1530e-01 -1.1439e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.2342e-01 -9.7351e-02 -9.3335e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9702e-01 -2.3647e-02 -8.6147e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.2489e-01  4.2539e-03 -8.3435e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(3 ,.,.) = 
  1.4243e+00  1.0571e+00  3.7330e-01  ...  -2.7530e+00 -2.7168e+00 -2.5641e+00
  5.5793e-01  1.6698e-01 -5.4288e-01  ...  -3.4514e+00 -3.4187e+00 -3.2881e+00
  2.6409e-01 -1.3070e-01 -8.4015e-01  ...  -3.6516e+00 -3.6197e+00 -3.4956e+00
                 ...                   ⋱                   ...                
  5.2582e-01  1.3012e-01 -5.8397e-01  ...  -3.4915e+00 -3.4573e+00 -3.3261e+00
  5.2582e-01  1.3012e-01 -5.8397e-01  ...  -3.4915e+00 -3.4573e+00 -3.3261e+00
  5.2582e-01  1.3012e-01 -5.8397e-01  ...  -3.4915e+00 -3.4573e+00 -3.3261e+00

(4 ,.,.) = 
  1.4376e+00  9.4732e-01  2.5852e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5322e-01 -6.9959e-02 -7.8079e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1620e-01 -3.0973e-01 -1.0179e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.5854e-01 -1.6977e-01 -8.8239e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0354e-01 -1.2461e-01 -8.3748e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0354e-01 -1.2461e-01 -8.3748e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(5 ,.,.) = 
  1.4844e+00  1.1083e+00  3.7358e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9826e-01  9.0982e-02 -6.7859e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9826e-01  9.0982e-02 -6.7859e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.9826e-01  9.0982e-02 -6.7859e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9826e-01  9.0982e-02 -6.7859e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9826e-01  9.0982e-02 -6.7859e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x9x63 (GPU 0)]

 Loss = 4.91717621859
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  1.3868e+00  9.7775e-01  2.4987e-01  ...  -2.6621e+00 -2.5232e+00 -1.0000e+02
  2.6330e-01 -1.7628e-01 -9.2990e-01  ...  -3.5552e+00 -3.4420e+00 -1.0000e+02
 -2.2453e-02 -4.6439e-01 -1.2136e+00  ...  -3.7450e+00 -3.6376e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3291e-01 -1.1667e-02 -7.7425e-01  ...  -3.4709e+00 -3.3522e+00 -1.0000e+02
  4.3291e-01 -1.1667e-02 -7.7425e-01  ...  -3.4709e+00 -3.3522e+00 -1.0000e+02
  4.3291e-01 -1.1667e-02 -7.7425e-01  ...  -3.4709e+00 -3.3522e+00 -1.0000e+02

( 1 ,.,.) = 
  1.4069e+00  9.9887e-01  2.7260e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6734e-01 -1.7209e-01 -9.2540e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8547e-02 -4.7044e-01 -1.2192e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3330e-01 -1.1364e-02 -7.7389e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3330e-01 -1.1364e-02 -7.7389e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3330e-01 -1.1364e-02 -7.7389e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.4433e+00  1.0379e+00  3.1535e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6243e-01 -1.7647e-01 -9.2912e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.1920e-02 -4.8348e-01 -1.2317e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3294e-01 -1.1684e-02 -7.7430e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3294e-01 -1.1684e-02 -7.7430e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3294e-01 -1.1684e-02 -7.7430e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.4890e+00  1.0864e+00  3.6812e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6955e-01 -1.6880e-01 -9.2075e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2210e-02 -4.9351e-01 -1.2411e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3312e-01 -1.1555e-02 -7.7416e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3312e-01 -1.1555e-02 -7.7416e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3312e-01 -1.1555e-02 -7.7416e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.4961e+00  1.0943e+00  3.7721e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6189e-01 -1.7638e-01 -9.2798e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.7859e-02 -4.9909e-01 -1.2464e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3329e-01 -1.1380e-02 -7.7391e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3329e-01 -1.1380e-02 -7.7391e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3329e-01 -1.1380e-02 -7.7391e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.4212e+00  1.0146e+00  2.9048e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5627e-01 -1.8291e-01 -9.3566e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.8567e-02 -4.8027e-01 -1.2286e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3324e-01 -1.1402e-02 -7.7393e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3324e-01 -1.1402e-02 -7.7393e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3324e-01 -1.1402e-02 -7.7393e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.4518e+00  1.0470e+00  3.2541e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6028e-01 -1.7855e-01 -9.3103e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.4979e-02 -4.8650e-01 -1.2346e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3302e-01 -1.1582e-02 -7.7415e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3302e-01 -1.1582e-02 -7.7415e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3302e-01 -1.1582e-02 -7.7415e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.3857e+00  9.7669e-01  2.4909e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5948e-01 -1.8012e-01 -9.3350e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6681e-02 -4.6864e-01 -1.2176e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3329e-01 -1.1364e-02 -7.7388e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3329e-01 -1.1364e-02 -7.7388e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3329e-01 -1.1364e-02 -7.7388e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.4086e+00  1.0010e+00  2.7521e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6122e-01 -1.7811e-01 -9.3128e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.1565e-02 -4.7336e-01 -1.2221e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3306e-01 -1.1549e-02 -7.7411e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3306e-01 -1.1549e-02 -7.7411e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3306e-01 -1.1549e-02 -7.7411e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.4383e+00  1.0326e+00  3.0953e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6170e-01 -1.7727e-01 -9.2998e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.0600e-02 -4.8219e-01 -1.2305e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3295e-01 -1.1665e-02 -7.7427e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3295e-01 -1.1665e-02 -7.7427e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3295e-01 -1.1665e-02 -7.7427e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.2768e+00  8.6081e-01  1.2349e-01  ...  -2.4857e+00 -2.4264e+00 -1.0000e+02
  2.7271e-01 -1.6816e-01 -9.2361e-01  ...  -3.3054e+00 -3.2574e+00 -1.0000e+02
  2.3399e-02 -4.1936e-01 -1.1706e+00  ...  -3.4804e+00 -3.4346e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3308e-01 -1.1542e-02 -7.7411e-01  ...  -3.2129e+00 -3.1618e+00 -1.0000e+02
  4.3308e-01 -1.1542e-02 -7.7411e-01  ...  -3.2129e+00 -3.1618e+00 -1.0000e+02
  4.3308e-01 -1.1542e-02 -7.7411e-01  ...  -3.2129e+00 -3.1618e+00 -1.0000e+02

(14 ,.,.) = 
  1.4207e+00  1.0134e+00  2.8817e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6902e-01 -1.7025e-01 -9.2351e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.2504e-02 -4.7431e-01 -1.2230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3304e-01 -1.1604e-02 -7.7421e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3304e-01 -1.1604e-02 -7.7421e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3304e-01 -1.1604e-02 -7.7421e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.3868e+00  9.7745e-01  2.4946e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6757e-01 -1.7209e-01 -9.2565e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.1517e-02 -4.6356e-01 -1.2127e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3346e-01 -1.1239e-02 -7.7374e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3346e-01 -1.1239e-02 -7.7374e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3346e-01 -1.1239e-02 -7.7374e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.4458e+00  1.0405e+00  3.1823e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6206e-01 -1.7681e-01 -9.2939e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3162e-02 -4.8469e-01 -1.2328e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3293e-01 -1.1686e-02 -7.7430e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3293e-01 -1.1686e-02 -7.7430e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3293e-01 -1.1686e-02 -7.7430e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.3983e+00  9.8983e-01  2.6294e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6399e-01 -1.7547e-01 -9.2888e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6594e-02 -4.6848e-01 -1.2174e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3302e-01 -1.1611e-02 -7.7421e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3302e-01 -1.1611e-02 -7.7421e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3302e-01 -1.1611e-02 -7.7421e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.3870e+00  9.7777e-01  2.4977e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6596e-01 -1.7379e-01 -9.2749e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.7854e-02 -4.5995e-01 -1.2092e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3335e-01 -1.1329e-02 -7.7385e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3335e-01 -1.1329e-02 -7.7385e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3335e-01 -1.1329e-02 -7.7385e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.3736e+00  9.6370e-01  2.3481e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6194e-01 -1.7785e-01 -9.3152e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9874e-02 -4.6196e-01 -1.2112e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3334e-01 -1.1321e-02 -7.7383e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3334e-01 -1.1321e-02 -7.7383e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3334e-01 -1.1321e-02 -7.7383e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.4513e+00  1.0463e+00  3.2423e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6737e-01 -1.7151e-01 -9.2421e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.1152e-02 -4.8275e-01 -1.2310e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3305e-01 -1.1574e-02 -7.7415e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3305e-01 -1.1574e-02 -7.7415e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3305e-01 -1.1574e-02 -7.7415e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.3975e+00  9.8920e-01  2.6237e-01  ...  -2.6476e+00 -2.7091e+00 -2.5495e+00
  2.6150e-01 -1.7796e-01 -9.3137e-01  ...  -3.5562e+00 -3.6053e+00 -3.4750e+00
 -2.6788e-02 -4.6865e-01 -1.2176e+00  ...  -3.7490e+00 -3.7943e+00 -3.6709e+00
                 ...                   ⋱                   ...                
  4.3290e-01 -1.1693e-02 -7.7429e-01  ...  -3.4729e+00 -3.5219e+00 -3.3857e+00
  4.3290e-01 -1.1693e-02 -7.7429e-01  ...  -3.4729e+00 -3.5219e+00 -3.3857e+00
  4.3290e-01 -1.1693e-02 -7.7429e-01  ...  -3.4729e+00 -3.5219e+00 -3.3857e+00

( 1 ,.,.) = 
  1.3937e+00  9.8506e-01  2.5791e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6223e-01 -1.7729e-01 -9.3066e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6838e-02 -4.6876e-01 -1.2177e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3316e-01 -1.1498e-02 -7.7407e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3316e-01 -1.1498e-02 -7.7407e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3316e-01 -1.1498e-02 -7.7407e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.3938e+00  9.8523e-01  2.5821e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.6068e-01 -1.7888e-01 -9.3227e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5873e-02 -4.6783e-01 -1.2168e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3323e-01 -1.1425e-02 -7.7396e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3323e-01 -1.1425e-02 -7.7396e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3323e-01 -1.1425e-02 -7.7396e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  1.4343e+00  1.0283e+00  3.0473e-01  ...  -3.3424e+00 -3.3714e+00 -2.6248e+00
  2.6361e-01 -1.7539e-01 -9.2824e-01  ...  -4.1546e+00 -4.1753e+00 -3.5687e+00
 -3.9654e-02 -4.8127e-01 -1.2296e+00  ...  -4.3221e+00 -4.3411e+00 -3.7708e+00
                 ...                   ⋱                   ...                
  4.3289e-01 -1.1705e-02 -7.7432e-01  ...  -4.0868e+00 -4.1087e+00 -3.4868e+00
  4.3289e-01 -1.1705e-02 -7.7432e-01  ...  -4.0868e+00 -4.1087e+00 -3.4868e+00
  4.3289e-01 -1.1705e-02 -7.7432e-01  ...  -4.0868e+00 -4.1087e+00 -3.4868e+00

( 4 ,.,.) = 
  1.3142e+00  9.0027e-01  1.6571e-01  ...  -2.4161e+00 -1.0000e+02 -1.0000e+02
  2.7389e-01 -1.6653e-01 -9.2141e-01  ...  -3.2786e+00 -1.0000e+02 -1.0000e+02
  7.3173e-03 -4.3517e-01 -1.1856e+00  ...  -3.4672e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3310e-01 -1.1551e-02 -7.7414e-01  ...  -3.1871e+00 -1.0000e+02 -1.0000e+02
  4.3310e-01 -1.1551e-02 -7.7414e-01  ...  -3.1871e+00 -1.0000e+02 -1.0000e+02
  4.3310e-01 -1.1551e-02 -7.7414e-01  ...  -3.1871e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  1.2974e+00  8.8265e-01  1.4697e-01  ...  -2.4344e+00 -1.0000e+02 -1.0000e+02
  2.7089e-01 -1.6977e-01 -9.2485e-01  ...  -3.2832e+00 -1.0000e+02 -1.0000e+02
  1.3575e-02 -4.2906e-01 -1.1798e+00  ...  -3.4651e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3321e-01 -1.1435e-02 -7.7398e-01  ...  -3.1882e+00 -1.0000e+02 -1.0000e+02
  4.3321e-01 -1.1435e-02 -7.7398e-01  ...  -3.1882e+00 -1.0000e+02 -1.0000e+02
  4.3321e-01 -1.1435e-02 -7.7398e-01  ...  -3.1882e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  1.4176e+00  9.7617e-01  1.9974e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2248e-01 -2.5445e-01 -1.0583e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7019e-02 -5.6632e-01 -1.3637e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8455e-01 -9.8664e-02 -9.1307e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8455e-01 -9.8664e-02 -9.1307e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8455e-01 -9.8664e-02 -9.1307e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.4157e+00  9.7360e-01  1.9609e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3929e-01 -2.3763e-01 -1.0419e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.6338e-02 -5.5571e-01 -1.3534e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8488e-01 -9.8289e-02 -9.1254e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8488e-01 -9.8289e-02 -9.1254e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8488e-01 -9.8289e-02 -9.1254e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.4350e+00  9.9471e-01  2.1982e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2109e-01 -2.5570e-01 -1.0595e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.3229e-02 -5.7246e-01 -1.3697e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8399e-01 -9.9325e-02 -9.1400e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8399e-01 -9.9325e-02 -9.1400e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8399e-01 -9.9325e-02 -9.1400e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.3897e+00  9.4632e-01  1.6723e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2141e-01 -2.5587e-01 -1.0601e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.9125e-02 -5.5861e-01 -1.3563e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8468e-01 -9.8519e-02 -9.1287e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8468e-01 -9.8519e-02 -9.1287e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8468e-01 -9.8519e-02 -9.1287e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.4403e+00  1.0007e+00  2.2682e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1576e-01 -2.6094e-01 -1.0644e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.8033e-02 -5.7718e-01 -1.3741e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8429e-01 -9.9025e-02 -9.1360e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8429e-01 -9.9025e-02 -9.1360e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8429e-01 -9.9025e-02 -9.1360e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.4176e+00  9.7617e-01  1.9974e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2248e-01 -2.5445e-01 -1.0583e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7019e-02 -5.6632e-01 -1.3637e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8455e-01 -9.8664e-02 -9.1307e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8455e-01 -9.8664e-02 -9.1307e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8455e-01 -9.8664e-02 -9.1307e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.4169e+00  9.7533e-01  1.9899e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2308e-01 -2.5386e-01 -1.0576e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.6416e-02 -5.6573e-01 -1.3629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8504e-01 -9.8196e-02 -9.1246e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8504e-01 -9.8196e-02 -9.1246e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8504e-01 -9.8196e-02 -9.1246e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.4169e+00  9.7533e-01  1.9899e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2308e-01 -2.5386e-01 -1.0576e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.6416e-02 -5.6573e-01 -1.3629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8504e-01 -9.8196e-02 -9.1246e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8504e-01 -9.8196e-02 -9.1246e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8504e-01 -9.8196e-02 -9.1246e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.4072e+00  9.6495e-01  1.8735e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2125e-01 -2.5594e-01 -1.0602e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.4609e-02 -5.6411e-01 -1.3618e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8423e-01 -9.9138e-02 -9.1378e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8423e-01 -9.9138e-02 -9.1378e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8423e-01 -9.9138e-02 -9.1378e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  1.3780e+00  9.3386e-01  1.5349e-01  ...  -2.9444e+00 -2.6938e+00 -2.5320e+00
  2.2039e-01 -2.5704e-01 -1.0618e+00  ...  -3.8197e+00 -3.6082e+00 -3.4760e+00
 -7.6941e-02 -5.5653e-01 -1.3548e+00  ...  -4.0046e+00 -3.8034e+00 -3.6781e+00
                 ...                   ⋱                   ...                
  3.8361e-01 -9.9608e-02 -9.1431e-01  ...  -3.7496e+00 -3.5319e+00 -3.3933e+00
  3.8361e-01 -9.9608e-02 -9.1431e-01  ...  -3.7496e+00 -3.5319e+00 -3.3933e+00
  3.8361e-01 -9.9608e-02 -9.1431e-01  ...  -3.7496e+00 -3.5319e+00 -3.3933e+00

( 4 ,.,.) = 
  1.3599e+00  9.1462e-01  1.3283e-01  ...  -2.6810e+00 -2.5353e+00 -1.0000e+02
  2.1608e-01 -2.6156e-01 -1.0663e+00  ...  -3.5844e+00 -3.4659e+00 -1.0000e+02
 -7.3125e-02 -5.5278e-01 -1.3510e+00  ...  -3.7746e+00 -3.6626e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8415e-01 -9.9027e-02 -9.1352e-01  ...  -3.5021e+00 -3.3782e+00 -1.0000e+02
  3.8415e-01 -9.9027e-02 -9.1352e-01  ...  -3.5021e+00 -3.3782e+00 -1.0000e+02
  3.8415e-01 -9.9027e-02 -9.1352e-01  ...  -3.5021e+00 -3.3782e+00 -1.0000e+02

( 5 ,.,.) = 
  1.4011e+00  9.5856e-01  1.8075e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1725e-01 -2.5998e-01 -1.0641e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.4334e-02 -5.6383e-01 -1.3615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8440e-01 -9.8924e-02 -9.1347e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8440e-01 -9.8924e-02 -9.1347e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8440e-01 -9.8924e-02 -9.1347e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 10 @ 2018-04-12 20:36:11.734064
training
gt_where_seq [[7, 0, 14, 0, 54, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 0, 8, 0, 55, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.3436e+00  8.9715e-01  1.8538e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1873e-01 -2.6182e-01 -9.9959e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2875e-02 -5.2518e-01 -1.2580e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.6301e-02 -4.4769e-01 -1.1832e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4477e-01 -1.4030e-01 -8.8411e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4477e-01 -1.4030e-01 -8.8411e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.4425e+00  9.9148e-01  2.8870e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3848e-01 -5.1113e-02 -7.8507e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3848e-01 -5.1113e-02 -7.8507e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3848e-01 -5.1113e-02 -7.8507e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3848e-01 -5.1113e-02 -7.8507e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3848e-01 -5.1113e-02 -7.8507e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.3566e+00  1.0053e+00  2.8743e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8339e-01  1.6782e-03 -7.5257e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8339e-01  1.6782e-03 -7.5257e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8339e-01  1.6782e-03 -7.5257e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8339e-01  1.6782e-03 -7.5257e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8339e-01  1.6782e-03 -7.5257e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.3542e+00  9.3137e-01  2.5429e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1774e-01 -2.3747e-01 -9.3928e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.1632e-02 -4.8888e-01 -1.1867e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2361e-01 -3.3537e-01 -1.0381e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.4449e-01 -2.1504e-01 -9.2092e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4219e-01 -1.1744e-01 -8.2561e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.4079e+00  1.0194e+00  3.2565e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7702e-01 -4.6635e-02 -7.7467e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7702e-01 -4.6635e-02 -7.7467e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.7702e-01 -4.6635e-02 -7.7467e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7702e-01 -4.6635e-02 -7.7467e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7702e-01 -4.6635e-02 -7.7467e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.3145e+00  9.4800e-01  2.1849e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4460e-01 -5.5413e-02 -8.2093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4460e-01 -5.5413e-02 -8.2093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.4460e-01 -5.5413e-02 -8.2093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4460e-01 -5.5413e-02 -8.2093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.4460e-01 -5.5413e-02 -8.2093e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 18, 0, 56, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 0, 22, 0, 53, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.3502e+00  9.2001e-01  1.1405e-01  ...  -2.5275e+00 -1.0000e+02 -1.0000e+02
  3.6781e-01 -1.0210e-01 -9.4555e-01  ...  -3.3922e+00 -1.0000e+02 -1.0000e+02
  3.6781e-01 -1.0210e-01 -9.4555e-01  ...  -3.3922e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.6781e-01 -1.0210e-01 -9.4555e-01  ...  -3.3922e+00 -1.0000e+02 -1.0000e+02
  3.6781e-01 -1.0210e-01 -9.4555e-01  ...  -3.3922e+00 -1.0000e+02 -1.0000e+02
  3.6781e-01 -1.0210e-01 -9.4555e-01  ...  -3.3922e+00 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.2914e+00  8.6936e-01  1.3402e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5736e-01 -1.0006e-01 -8.6794e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5736e-01 -1.0006e-01 -8.6794e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.5736e-01 -1.0006e-01 -8.6794e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5736e-01 -1.0006e-01 -8.6794e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5736e-01 -1.0006e-01 -8.6794e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.2888e+00  8.6309e-01  1.2674e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8068e-01 -7.8744e-02 -8.4555e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8068e-01 -7.8744e-02 -8.4555e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8068e-01 -7.8744e-02 -8.4555e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8068e-01 -7.8744e-02 -8.4555e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.8068e-01 -7.8744e-02 -8.4555e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.4920e+00  1.1122e+00  4.0711e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.1230e-01 -1.1018e-02 -7.6434e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.1230e-01 -1.1018e-02 -7.6434e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.1230e-01 -1.1018e-02 -7.6434e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.1230e-01 -1.1018e-02 -7.6434e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.1230e-01 -1.1018e-02 -7.6434e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.3760e+00  9.1790e-01  1.8224e-01  ...  -2.3491e+00 -2.5788e+00 -2.3803e+00
  9.5499e-02 -3.9714e-01 -1.1524e+00  ...  -3.3982e+00 -3.5839e+00 -3.4274e+00
 -8.1851e-02 -5.7629e-01 -1.3278e+00  ...  -3.5245e+00 -3.7048e+00 -3.5530e+00
                 ...                   ⋱                   ...                
  8.7479e-02 -4.0911e-01 -1.1666e+00  ...  -3.4170e+00 -3.6028e+00 -3.4448e+00
  4.3516e-01 -6.2356e-02 -8.2970e-01  ...  -3.1878e+00 -3.3845e+00 -3.2154e+00
  4.3516e-01 -6.2356e-02 -8.2970e-01  ...  -3.1878e+00 -3.3845e+00 -3.2154e+00

(14,.,.) = 
  1.2649e+00  9.0155e-01  1.9170e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.3599e-02 -3.0432e-01 -1.0344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1174e-01 -5.0049e-01 -1.2267e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1641e-01 -2.7440e-01 -1.0082e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.4314e-01  5.1926e-02 -6.8912e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.4314e-01  5.1926e-02 -6.8912e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 55, 1], [7, 0, 22, 0, 54, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.2316e+00  7.9225e-01 -4.9238e-02  ...  -2.4975e+00 -1.0000e+02 -1.0000e+02
  3.2101e-01 -1.5698e-01 -1.0325e+00  ...  -3.3017e+00 -1.0000e+02 -1.0000e+02
  3.2101e-01 -1.5698e-01 -1.0325e+00  ...  -3.3017e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.2101e-01 -1.5698e-01 -1.0325e+00  ...  -3.3017e+00 -1.0000e+02 -1.0000e+02
  3.2101e-01 -1.5698e-01 -1.0325e+00  ...  -3.3017e+00 -1.0000e+02 -1.0000e+02
  3.2101e-01 -1.5698e-01 -1.0325e+00  ...  -3.3017e+00 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.1726e+00  6.6192e-01 -2.3945e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8760e-01 -3.6490e-01 -1.2918e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8760e-01 -3.6490e-01 -1.2918e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.8760e-01 -3.6490e-01 -1.2918e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8760e-01 -3.6490e-01 -1.2918e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8760e-01 -3.6490e-01 -1.2918e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.0982e+00  6.3473e-01 -2.5110e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7808e-01 -2.1632e-01 -1.1222e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7808e-01 -2.1632e-01 -1.1222e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7808e-01 -2.1632e-01 -1.1222e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7808e-01 -2.1632e-01 -1.1222e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7808e-01 -2.1632e-01 -1.1222e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.1457e+00  6.9370e-01 -4.7661e-02  ...  -2.5429e+00 -2.5055e+00 -1.0000e+02
  2.9641e-01 -1.8567e-01 -9.4712e-01  ...  -3.2630e+00 -3.2285e+00 -1.0000e+02
  2.9641e-01 -1.8567e-01 -9.4712e-01  ...  -3.2630e+00 -3.2285e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.9641e-01 -1.8567e-01 -9.4712e-01  ...  -3.2630e+00 -3.2285e+00 -1.0000e+02
  2.9641e-01 -1.8567e-01 -9.4712e-01  ...  -3.2630e+00 -3.2285e+00 -1.0000e+02
  2.9641e-01 -1.8567e-01 -9.4712e-01  ...  -3.2630e+00 -3.2285e+00 -1.0000e+02

(13,.,.) = 
  1.0978e+00  6.8027e-01 -1.3956e-01  ...  -2.2473e+00 -2.2050e+00 -2.3018e+00
 -5.2167e-05 -4.3755e-01 -1.2613e+00  ...  -3.1480e+00 -3.1088e+00 -3.1928e+00
 -2.1162e-01 -6.4834e-01 -1.4632e+00  ...  -3.2943e+00 -3.2561e+00 -3.3367e+00
                 ...                   ⋱                   ...                
  1.3045e-01 -3.0951e-01 -1.1381e+00  ...  -3.0589e+00 -3.0197e+00 -3.1035e+00
  2.3692e-01 -2.0344e-01 -1.0358e+00  ...  -2.9842e+00 -2.9446e+00 -3.0297e+00
  2.9453e-01 -1.4584e-01 -9.8004e-01  ...  -2.9426e+00 -2.9027e+00 -2.9886e+00

(14,.,.) = 
  1.2374e+00  8.2966e-01  3.2718e-02  ...  -2.2114e+00 -2.2196e+00 -1.0000e+02
  2.8041e-01 -1.6147e-01 -9.9109e-01  ...  -3.0725e+00 -3.0819e+00 -1.0000e+02
  2.8041e-01 -1.6147e-01 -9.9109e-01  ...  -3.0725e+00 -3.0819e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  2.8041e-01 -1.6147e-01 -9.9109e-01  ...  -3.0725e+00 -3.0819e+00 -1.0000e+02
  2.8041e-01 -1.6147e-01 -9.9109e-01  ...  -3.0725e+00 -3.0819e+00 -1.0000e+02
  2.8041e-01 -1.6147e-01 -9.9109e-01  ...  -3.0725e+00 -3.0819e+00 -1.0000e+02
[torch.cuda.FloatTensor of size 15x8x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    1.2458    0.7974    0.0429  ...    -2.4399 -100.0000 -100.0000
    0.2182   -0.2727   -1.0601  ...    -3.3381 -100.0000 -100.0000
    0.2182   -0.2727   -1.0601  ...    -3.3381 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2182   -0.2727   -1.0601  ...    -3.3381 -100.0000 -100.0000
    0.2182   -0.2727   -1.0601  ...    -3.3381 -100.0000 -100.0000
    0.2182   -0.2727   -1.0601  ...    -3.3381 -100.0000 -100.0000

(1 ,.,.) = 
    1.2156    0.7508   -0.0644  ...    -2.4323   -2.4090 -100.0000
    0.2571   -0.2502   -1.0977  ...    -3.2793   -3.2575 -100.0000
    0.2571   -0.2502   -1.0977  ...    -3.2793   -3.2575 -100.0000
              ...                ⋱                ...             
    0.2571   -0.2502   -1.0977  ...    -3.2793   -3.2575 -100.0000
    0.2571   -0.2502   -1.0977  ...    -3.2793   -3.2575 -100.0000
    0.2571   -0.2502   -1.0977  ...    -3.2793   -3.2575 -100.0000

(2 ,.,.) = 
    1.0664    0.5628   -0.2484  ...    -2.1140   -2.2456   -2.3117
   -0.4501   -0.9789   -1.7792  ...    -3.3458   -3.4490   -3.5111
   -0.6481   -1.1737   -1.9612  ...    -3.4800   -3.5785   -3.6393
              ...                ⋱                ...             
    0.0538   -0.4858   -1.3135  ...    -3.0149   -3.1262   -3.1897
    0.1321   -0.4081   -1.2393  ...    -2.9591   -3.0720   -3.1358
    0.1753   -0.3652   -1.1984  ...    -2.9289   -3.0428   -3.1068

(3 ,.,.) = 
    0.9702    0.4803   -0.3910  ...    -2.2050   -2.2638 -100.0000
   -0.3530   -0.8606   -1.7146  ...    -3.2628   -3.3155 -100.0000
   -0.5125   -1.0180   -1.8607  ...    -3.3709   -3.4214 -100.0000
              ...                ⋱                ...             
    0.1037   -0.4114   -1.2887  ...    -2.9493   -3.0025 -100.0000
    0.1803   -0.3353   -1.2162  ...    -2.8951   -2.9488 -100.0000
    0.1966   -0.3189   -1.2006  ...    -2.8831   -2.9369 -100.0000

(4 ,.,.) = 
    1.2052    0.7326   -0.0119  ...  -100.0000 -100.0000 -100.0000
    0.1807   -0.3365   -1.1116  ...  -100.0000 -100.0000 -100.0000
    0.1807   -0.3365   -1.1116  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1807   -0.3365   -1.1116  ...  -100.0000 -100.0000 -100.0000
    0.1807   -0.3365   -1.1116  ...  -100.0000 -100.0000 -100.0000
    0.1807   -0.3365   -1.1116  ...  -100.0000 -100.0000 -100.0000

(5 ,.,.) = 
    1.1082    0.5745   -0.2806  ...    -2.3539   -2.4106 -100.0000
    0.2128   -0.3613   -1.2393  ...    -3.1505   -3.2049 -100.0000
    0.2128   -0.3613   -1.2393  ...    -3.1505   -3.2049 -100.0000
              ...                ⋱                ...             
    0.2128   -0.3613   -1.2393  ...    -3.1505   -3.2049 -100.0000
    0.2128   -0.3613   -1.2393  ...    -3.1505   -3.2049 -100.0000
    0.2128   -0.3613   -1.2393  ...    -3.1505   -3.2049 -100.0000
[torch.cuda.FloatTensor of size 6x9x60 (GPU 0)]

 Loss = 4.84425314735
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    0.9701    0.4246   -0.4973  ...    -2.2230   -2.3188 -100.0000
   -0.6932   -1.2560   -2.1361  ...    -3.5123   -3.5951 -100.0000
   -0.8539   -1.4117   -2.2760  ...    -3.6144   -3.6943 -100.0000
              ...                ⋱                ...             
    0.0557   -0.5248   -1.4561  ...    -3.0252   -3.1128 -100.0000
    0.0557   -0.5248   -1.4561  ...    -3.0252   -3.1128 -100.0000
    0.0557   -0.5248   -1.4561  ...    -3.0252   -3.1128 -100.0000

( 1 ,.,.) = 
    0.9961    0.4520   -0.4682  ...  -100.0000 -100.0000 -100.0000
   -0.6958   -1.2583   -2.1379  ...  -100.0000 -100.0000 -100.0000
   -0.8670   -1.4242   -2.2871  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0561   -0.5244   -1.4555  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5244   -1.4555  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5244   -1.4555  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.0416    0.5015   -0.4144  ...  -100.0000 -100.0000 -100.0000
   -0.7260   -1.2872   -2.1642  ...  -100.0000 -100.0000 -100.0000
   -0.9036   -1.4594   -2.3191  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0557   -0.5249   -1.4562  ...  -100.0000 -100.0000 -100.0000
    0.0557   -0.5249   -1.4562  ...  -100.0000 -100.0000 -100.0000
    0.0557   -0.5249   -1.4562  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.0969    0.5608   -0.3505  ...  -100.0000 -100.0000 -100.0000
   -0.7380   -1.2985   -2.1741  ...  -100.0000 -100.0000 -100.0000
   -0.9317   -1.4863   -2.3433  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0559   -0.5247   -1.4559  ...  -100.0000 -100.0000 -100.0000
    0.0559   -0.5247   -1.4559  ...  -100.0000 -100.0000 -100.0000
    0.0559   -0.5247   -1.4559  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.1005    0.5654   -0.3444  ...  -100.0000 -100.0000 -100.0000
   -0.7525   -1.3124   -2.1865  ...  -100.0000 -100.0000 -100.0000
   -0.9403   -1.4945   -2.3505  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0561   -0.5245   -1.4555  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5245   -1.4555  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5245   -1.4555  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.0060    0.4638   -0.4540  ...  -100.0000 -100.0000 -100.0000
   -0.7218   -1.2833   -2.1606  ...  -100.0000 -100.0000 -100.0000
   -0.8877   -1.4440   -2.3050  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0560   -0.5245   -1.4556  ...  -100.0000 -100.0000 -100.0000
    0.0560   -0.5245   -1.4556  ...  -100.0000 -100.0000 -100.0000
    0.0560   -0.5245   -1.4556  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.0439e+00  5.0405e-01 -4.1136e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.2916e-01 -1.2903e+00 -2.1670e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.0350e-01 -1.4593e+00 -2.3189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.5837e-02 -5.2473e-01 -1.4559e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5837e-02 -5.2473e-01 -1.4559e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5837e-02 -5.2473e-01 -1.4559e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  9.6426e-01  4.1865e-01 -5.0297e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -6.9782e-01 -1.2604e+00 -2.1399e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.5747e-01 -1.4150e+00 -2.2788e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.6070e-02 -5.2443e-01 -1.4555e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.6070e-02 -5.2443e-01 -1.4555e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.6070e-02 -5.2443e-01 -1.4555e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  9.9443e-01  4.5083e-01 -4.6879e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.0772e-01 -1.2698e+00 -2.1485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7345e-01 -1.4304e+00 -2.2929e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.5871e-02 -5.2469e-01 -1.4559e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5871e-02 -5.2469e-01 -1.4559e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5871e-02 -5.2469e-01 -1.4559e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.0362e+00  4.9570e-01 -4.2056e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.2398e-01 -1.2854e+00 -2.1625e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.9971e-01 -1.4556e+00 -2.3157e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.5752e-02 -5.2486e-01 -1.4561e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5752e-02 -5.2486e-01 -1.4561e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5752e-02 -5.2486e-01 -1.4561e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  8.4029e-01  2.8541e-01 -6.4586e-01  ...  -2.0805e+00 -2.2493e+00 -1.0000e+02
 -6.1338e-01 -1.1794e+00 -2.0666e+00  ...  -3.2417e+00 -3.3863e+00 -1.0000e+02
 -7.4589e-01 -1.3078e+00 -2.1818e+00  ...  -3.3309e+00 -3.4718e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  5.5879e-02 -5.2468e-01 -1.4559e+00  ...  -2.7743e+00 -2.9298e+00 -1.0000e+02
  5.5879e-02 -5.2468e-01 -1.4559e+00  ...  -2.7743e+00 -2.9298e+00 -1.0000e+02
  5.5879e-02 -5.2468e-01 -1.4559e+00  ...  -2.7743e+00 -2.9298e+00 -1.0000e+02

(14 ,.,.) = 
  1.0215e+00  4.7908e-01 -4.3964e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.0289e-01 -1.2652e+00 -2.1443e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.8089e-01 -1.4376e+00 -2.2995e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.5808e-02 -5.2480e-01 -1.4560e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5808e-02 -5.2480e-01 -1.4560e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5808e-02 -5.2480e-01 -1.4560e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.9729    0.4274   -0.4945  ...  -100.0000 -100.0000 -100.0000
   -0.6882   -1.2510   -2.1313  ...  -100.0000 -100.0000 -100.0000
   -0.8540   -1.4117   -2.2758  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0562   -0.5243   -1.4553  ...  -100.0000 -100.0000 -100.0000
    0.0562   -0.5243   -1.4553  ...  -100.0000 -100.0000 -100.0000
    0.0562   -0.5243   -1.4553  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.0437    0.5037   -0.4119  ...  -100.0000 -100.0000 -100.0000
   -0.7274   -1.2887   -2.1655  ...  -100.0000 -100.0000 -100.0000
   -0.9056   -1.4613   -2.3208  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0557   -0.5249   -1.4562  ...  -100.0000 -100.0000 -100.0000
    0.0557   -0.5249   -1.4562  ...  -100.0000 -100.0000 -100.0000
    0.0557   -0.5249   -1.4562  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.9896    0.4455   -0.4748  ...  -100.0000 -100.0000 -100.0000
   -0.7019   -1.2642   -2.1435  ...  -100.0000 -100.0000 -100.0000
   -0.8685   -1.4257   -2.2887  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0558   -0.5248   -1.4560  ...  -100.0000 -100.0000 -100.0000
    0.0558   -0.5248   -1.4560  ...  -100.0000 -100.0000 -100.0000
    0.0558   -0.5248   -1.4560  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    0.9558    0.4092   -0.5135  ...  -100.0000 -100.0000 -100.0000
   -0.6864   -1.2494   -2.1299  ...  -100.0000 -100.0000 -100.0000
   -0.8407   -1.3989   -2.2642  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0561   -0.5244   -1.4554  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5244   -1.4554  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5244   -1.4554  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    0.9504    0.4036   -0.5193  ...  -100.0000 -100.0000 -100.0000
   -0.6873   -1.2502   -2.1307  ...  -100.0000 -100.0000 -100.0000
   -0.8434   -1.4015   -2.2665  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0561   -0.5244   -1.4554  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5244   -1.4554  ...  -100.0000 -100.0000 -100.0000
    0.0561   -0.5244   -1.4554  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.0571    0.5178   -0.3973  ...  -100.0000 -100.0000 -100.0000
   -0.7234   -1.2848   -2.1620  ...  -100.0000 -100.0000 -100.0000
   -0.9049   -1.4607   -2.3203  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0558   -0.5247   -1.4560  ...  -100.0000 -100.0000 -100.0000
    0.0558   -0.5247   -1.4560  ...  -100.0000 -100.0000 -100.0000
    0.0558   -0.5247   -1.4560  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    0.9853    0.4410   -0.4794  ...    -2.1721   -2.2686   -2.3422
   -0.7027   -1.2650   -2.1443  ...    -3.4943   -3.5667   -3.6315
   -0.8658   -1.4231   -2.2864  ...    -3.5999   -3.6690   -3.7314
              ...                ⋱                ...             
    0.0557   -0.5249   -1.4561  ...    -2.9994   -3.0809   -3.1483
    0.0557   -0.5249   -1.4561  ...    -2.9994   -3.0809   -3.1483
    0.0557   -0.5249   -1.4561  ...    -2.9994   -3.0809   -3.1483

( 1 ,.,.) = 
    0.9813    0.4366   -0.4841  ...  -100.0000 -100.0000 -100.0000
   -0.7012   -1.2636   -2.1428  ...  -100.0000 -100.0000 -100.0000
   -0.8655   -1.4228   -2.2859  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0559   -0.5246   -1.4558  ...  -100.0000 -100.0000 -100.0000
    0.0559   -0.5246   -1.4558  ...  -100.0000 -100.0000 -100.0000
    0.0559   -0.5246   -1.4558  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    0.9755    0.4307   -0.4902  ...  -100.0000 -100.0000 -100.0000
   -0.7014   -1.2638   -2.1430  ...  -100.0000 -100.0000 -100.0000
   -0.8608   -1.4183   -2.2818  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0560   -0.5245   -1.4556  ...  -100.0000 -100.0000 -100.0000
    0.0560   -0.5245   -1.4556  ...  -100.0000 -100.0000 -100.0000
    0.0560   -0.5245   -1.4556  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    1.0354    0.4946   -0.4220  ...    -2.9380   -3.0361   -2.4153
   -0.7209   -1.2824   -2.1599  ...    -4.1265   -4.1941   -3.7385
   -0.8982   -1.4543   -2.3145  ...    -4.2186   -4.2832   -3.8446
              ...                ⋱                ...             
    0.0557   -0.5249   -1.4562  ...    -3.7070   -3.7867   -3.2601
    0.0557   -0.5249   -1.4562  ...    -3.7070   -3.7867   -3.2601
    0.0557   -0.5249   -1.4562  ...    -3.7070   -3.7867   -3.2601

( 4 ,.,.) = 
    0.8877    0.3358   -0.5929  ...    -2.2327 -100.0000 -100.0000
   -0.6387   -1.2036   -2.0886  ...    -3.4255 -100.0000 -100.0000
   -0.7882   -1.3485   -2.2188  ...    -3.5214 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0559   -0.5247   -1.4559  ...    -2.9575 -100.0000 -100.0000
    0.0559   -0.5247   -1.4559  ...    -2.9575 -100.0000 -100.0000
    0.0559   -0.5247   -1.4559  ...    -2.9575 -100.0000 -100.0000

( 5 ,.,.) = 
    0.8618    0.3083   -0.6215  ...    -2.2527 -100.0000 -100.0000
   -0.6283   -1.1937   -2.0796  ...    -3.4156 -100.0000 -100.0000
   -0.7669   -1.3280   -2.2001  ...    -3.5045 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0560   -0.5245   -1.4557  ...    -2.9524 -100.0000 -100.0000
    0.0560   -0.5245   -1.4557  ...    -2.9524 -100.0000 -100.0000
    0.0560   -0.5245   -1.4557  ...    -2.9524 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  1.0076e+00  4.2423e-01 -5.4614e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.8398e-01 -1.3863e+00 -2.3034e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6393e-01 -1.5596e+00 -2.4568e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.3994e-03 -6.3310e-01 -1.6109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.3994e-03 -6.3310e-01 -1.6109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.3994e-03 -6.3310e-01 -1.6109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.0210e+00  4.3735e-01 -5.3394e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.6059e-01 -1.3637e+00 -2.2829e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.5451e-01 -1.5505e+00 -2.4488e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.1401e-03 -6.3272e-01 -1.6103e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.1401e-03 -6.3272e-01 -1.6103e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.1401e-03 -6.3272e-01 -1.6103e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.0295e+00  4.4762e-01 -5.2123e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.9327e-01 -1.3954e+00 -2.3118e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.7779e-01 -1.5731e+00 -2.4693e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -9.0753e-03 -6.3411e-01 -1.6123e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.0753e-03 -6.3411e-01 -1.6123e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.0753e-03 -6.3411e-01 -1.6123e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  9.7627e-01  3.9038e-01 -5.8257e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.7249e-01 -1.3754e+00 -2.2936e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.4547e-01 -1.5419e+00 -2.4410e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.2862e-03 -6.3294e-01 -1.6107e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.2862e-03 -6.3294e-01 -1.6107e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.2862e-03 -6.3294e-01 -1.6107e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.0349e+00  4.5402e-01 -5.1344e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.0323e-01 -1.4048e+00 -2.3200e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.8557e-01 -1.5803e+00 -2.4755e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.7664e-03 -6.3367e-01 -1.6117e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7664e-03 -6.3367e-01 -1.6117e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7664e-03 -6.3367e-01 -1.6117e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.0076e+00  4.2423e-01 -5.4614e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.8398e-01 -1.3863e+00 -2.3034e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6393e-01 -1.5596e+00 -2.4568e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.3994e-03 -6.3310e-01 -1.6109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.3994e-03 -6.3310e-01 -1.6109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.3994e-03 -6.3310e-01 -1.6109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.0086e+00  4.2533e-01 -5.4475e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.8286e-01 -1.3851e+00 -2.3020e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6321e-01 -1.5587e+00 -2.4558e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -7.9696e-03 -6.3253e-01 -1.6101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.9696e-03 -6.3253e-01 -1.6101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.9696e-03 -6.3253e-01 -1.6101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.0086e+00  4.2533e-01 -5.4475e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.8286e-01 -1.3851e+00 -2.3020e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6321e-01 -1.5587e+00 -2.4558e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -7.9696e-03 -6.3253e-01 -1.6101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.9696e-03 -6.3253e-01 -1.6101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.9696e-03 -6.3253e-01 -1.6101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  9.9521e-01  4.1058e-01 -5.6112e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.8011e-01 -1.3830e+00 -2.3008e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.5695e-01 -1.5532e+00 -2.4515e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.9170e-03 -6.3393e-01 -1.6121e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.9170e-03 -6.3393e-01 -1.6121e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.9170e-03 -6.3393e-01 -1.6121e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  9.5711e-01  3.6937e-01 -6.0566e-01  ...  -2.4538e+00 -2.2453e+00 -2.3166e+00
 -7.6318e-01 -1.3670e+00 -2.2869e+00  ...  -3.7376e+00 -3.5710e+00 -3.6333e+00
 -9.3392e-01 -1.5314e+00 -2.4323e+00  ...  -3.8413e+00 -3.6787e+00 -3.7383e+00
                 ...                   ⋱                   ...                
 -9.3895e-03 -6.3449e-01 -1.6128e+00  ...  -3.2780e+00 -3.0890e+00 -3.1533e+00
 -9.3895e-03 -6.3449e-01 -1.6128e+00  ...  -3.2780e+00 -3.0890e+00 -3.1533e+00
 -9.3895e-03 -6.3449e-01 -1.6128e+00  ...  -3.2780e+00 -3.0890e+00 -3.1533e+00

( 4 ,.,.) = 
  9.3599e-01  3.4711e-01 -6.2881e-01  ...  -2.2364e+00 -2.3267e+00 -1.0000e+02
 -7.6188e-01 -1.3656e+00 -2.2852e+00  ...  -3.5458e+00 -3.6239e+00 -1.0000e+02
 -9.2350e-01 -1.5211e+00 -2.4227e+00  ...  -3.6478e+00 -3.7233e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.8081e-03 -6.3365e-01 -1.6117e+00  ...  -3.0599e+00 -3.1425e+00 -1.0000e+02
 -8.8081e-03 -6.3365e-01 -1.6117e+00  ...  -3.0599e+00 -3.1425e+00 -1.0000e+02
 -8.8081e-03 -6.3365e-01 -1.6117e+00  ...  -3.0599e+00 -3.1425e+00 -1.0000e+02

( 5 ,.,.) = 
  9.8152e-01  3.9639e-01 -5.7555e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -7.8323e-01 -1.3859e+00 -2.3033e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.5381e-01 -1.5501e+00 -2.4485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -8.6595e-03 -6.3354e-01 -1.6115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.6595e-03 -6.3354e-01 -1.6115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.6595e-03 -6.3354e-01 -1.6115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 11 @ 2018-04-12 20:36:14.194703
training
gt_where_seq [[7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 14, 0, 54, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    0.9789    0.4675   -0.4022  ...  -100.0000 -100.0000 -100.0000
    0.0995   -0.4403   -1.3163  ...  -100.0000 -100.0000 -100.0000
    0.0995   -0.4403   -1.3163  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.0995   -0.4403   -1.3163  ...  -100.0000 -100.0000 -100.0000
    0.0995   -0.4403   -1.3163  ...  -100.0000 -100.0000 -100.0000
    0.0995   -0.4403   -1.3163  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    0.9255    0.4764   -0.3323  ...    -1.9397   -2.1461   -2.3439
   -0.7222   -1.1845   -1.9637  ...    -3.2674   -3.4303   -3.5942
   -0.8414   -1.3010   -2.0705  ...    -3.3478   -3.5056   -3.6660
              ...                ⋱                ...             
   -0.0104   -0.4869   -1.3066  ...    -2.7730   -2.9537   -3.1320
    0.0444   -0.4325   -1.2548  ...    -2.7332   -2.9155   -3.0950
    0.0785   -0.3988   -1.2229  ...    -2.7093   -2.8927   -3.0732

(2 ,.,.) = 
    1.0257    0.4887   -0.3814  ...    -2.2425   -2.4143 -100.0000
    0.1206   -0.4550   -1.3416  ...    -3.0483   -3.2012 -100.0000
    0.1206   -0.4550   -1.3416  ...    -3.0483   -3.2012 -100.0000
              ...                ⋱                ...             
    0.1206   -0.4550   -1.3416  ...    -3.0483   -3.2012 -100.0000
    0.1206   -0.4550   -1.3416  ...    -3.0483   -3.2012 -100.0000
    0.1206   -0.4550   -1.3416  ...    -3.0483   -3.2012 -100.0000
...

(12,.,.) = 
    0.9985    0.4705   -0.5486  ...    -2.4372 -100.0000 -100.0000
    0.1047   -0.4538   -1.4751  ...    -3.1888 -100.0000 -100.0000
    0.1047   -0.4538   -1.4751  ...    -3.1888 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1047   -0.4538   -1.4751  ...    -3.1888 -100.0000 -100.0000
    0.1047   -0.4538   -1.4751  ...    -3.1888 -100.0000 -100.0000
    0.1047   -0.4538   -1.4751  ...    -3.1888 -100.0000 -100.0000

(13,.,.) = 
    0.9237    0.4836   -0.4245  ...    -2.4238   -2.4995 -100.0000
    0.1012   -0.3707   -1.3011  ...    -3.1476   -3.2169 -100.0000
    0.1012   -0.3707   -1.3011  ...    -3.1476   -3.2169 -100.0000
              ...                ⋱                ...             
    0.1012   -0.3707   -1.3011  ...    -3.1476   -3.2169 -100.0000
    0.1012   -0.3707   -1.3011  ...    -3.1476   -3.2169 -100.0000
    0.1012   -0.3707   -1.3011  ...    -3.1476   -3.2169 -100.0000

(14,.,.) = 
    0.9343    0.4135   -0.4631  ...  -100.0000 -100.0000 -100.0000
   -0.6981   -1.2345   -2.0736  ...  -100.0000 -100.0000 -100.0000
   -0.8397   -1.3721   -2.1984  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1421   -0.4116   -1.3021  ...  -100.0000 -100.0000 -100.0000
    0.1421   -0.4116   -1.3021  ...  -100.0000 -100.0000 -100.0000
    0.1421   -0.4116   -1.3021  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x9x60 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 0, 18, 0, 56, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    1.0475    0.4614   -0.4138  ...  -100.0000 -100.0000 -100.0000
    0.1747   -0.4502   -1.3377  ...  -100.0000 -100.0000 -100.0000
    0.1747   -0.4502   -1.3377  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1747   -0.4502   -1.3377  ...  -100.0000 -100.0000 -100.0000
    0.1747   -0.4502   -1.3377  ...  -100.0000 -100.0000 -100.0000
    0.1747   -0.4502   -1.3377  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    0.9171    0.4075   -0.4259  ...  -100.0000 -100.0000 -100.0000
   -0.6792   -1.2013   -1.9987  ...  -100.0000 -100.0000 -100.0000
   -0.8126   -1.3307   -2.1168  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4585   -0.9861   -1.7952  ...  -100.0000 -100.0000 -100.0000
   -0.2036   -0.7369   -1.5623  ...  -100.0000 -100.0000 -100.0000
   -0.0620   -0.5976   -1.4309  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    0.9268    0.4180   -0.5503  ...  -100.0000 -100.0000 -100.0000
   -0.7977   -1.3192   -2.2354  ...  -100.0000 -100.0000 -100.0000
   -0.8528   -1.3728   -2.2816  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4353   -0.9672   -1.9092  ...  -100.0000 -100.0000 -100.0000
    0.1487   -0.3930   -1.3747  ...  -100.0000 -100.0000 -100.0000
    0.1487   -0.3930   -1.3747  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    1.0096    0.5400   -0.2889  ...  -100.0000 -100.0000 -100.0000
    0.1413   -0.3627   -1.2119  ...  -100.0000 -100.0000 -100.0000
    0.1413   -0.3627   -1.2119  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1413   -0.3627   -1.2119  ...  -100.0000 -100.0000 -100.0000
    0.1413   -0.3627   -1.2119  ...  -100.0000 -100.0000 -100.0000
    0.1413   -0.3627   -1.2119  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    0.9682    0.4257   -0.4980  ...    -1.9167   -2.0219   -2.1574
   -0.8685   -1.4251   -2.2951  ...    -3.3961   -3.4707   -3.5837
   -0.9180   -1.4730   -2.3357  ...    -3.4316   -3.5038   -3.6159
              ...                ⋱                ...             
   -0.4006   -0.9724   -1.8773  ...    -3.0811   -3.1609   -3.2813
    0.1536   -0.4278   -1.3689  ...    -2.6899   -2.7787   -2.9069
    0.1536   -0.4278   -1.3689  ...    -2.6899   -2.7787   -2.9069

(14,.,.) = 
    1.2050    0.6324   -0.2513  ...  -100.0000 -100.0000 -100.0000
    0.1585   -0.4702   -1.3826  ...  -100.0000 -100.0000 -100.0000
    0.1585   -0.4702   -1.3826  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1585   -0.4702   -1.3826  ...  -100.0000 -100.0000 -100.0000
    0.1585   -0.4702   -1.3826  ...  -100.0000 -100.0000 -100.0000
    0.1585   -0.4702   -1.3826  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.2747e+00  6.9098e-01 -1.1744e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9372e-01 -4.4874e-01 -1.2864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9372e-01 -4.4874e-01 -1.2864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.9372e-01 -4.4874e-01 -1.2864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9372e-01 -4.4874e-01 -1.2864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9372e-01 -4.4874e-01 -1.2864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.0915e+00  5.6685e-01 -2.3581e-01  ...  -2.2419e+00 -1.0000e+02 -1.0000e+02
  1.3712e-01 -4.3459e-01 -1.2642e+00  ...  -3.1002e+00 -1.0000e+02 -1.0000e+02
  1.3712e-01 -4.3459e-01 -1.2642e+00  ...  -3.1002e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3712e-01 -4.3459e-01 -1.2642e+00  ...  -3.1002e+00 -1.0000e+02 -1.0000e+02
  1.3712e-01 -4.3459e-01 -1.2642e+00  ...  -3.1002e+00 -1.0000e+02 -1.0000e+02
  1.3712e-01 -4.3459e-01 -1.2642e+00  ...  -3.1002e+00 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  9.1704e-01  3.3070e-01 -6.6550e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7737e-01 -1.4694e+00 -2.3880e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.8794e-01 -1.5745e+00 -2.4786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -5.3065e-02 -6.6856e-01 -1.6538e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.7104e-02 -5.2007e-01 -1.5145e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.7104e-02 -5.2007e-01 -1.5145e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.1053e+00  5.4698e-01 -3.6676e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6811e-01 -4.3521e-01 -1.3673e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6811e-01 -4.3521e-01 -1.3673e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6811e-01 -4.3521e-01 -1.3673e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6811e-01 -4.3521e-01 -1.3673e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6811e-01 -4.3521e-01 -1.3673e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  9.4239e-01  3.7239e-01 -5.9088e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6889e-01 -1.5469e+00 -2.4346e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.0743e+00 -1.6474e+00 -2.5223e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -1.4132e-01 -7.4481e-01 -1.6999e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0626e-01 -5.0070e-01 -1.4712e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0626e-01 -5.0070e-01 -1.4712e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.1579e+00  5.9145e-01 -3.8208e-01  ...  -2.2195e+00 -2.1708e+00 -1.0000e+02
  7.7022e-02 -5.3878e-01 -1.5276e+00  ...  -3.1693e+00 -3.1297e+00 -1.0000e+02
  7.7022e-02 -5.3878e-01 -1.5276e+00  ...  -3.1693e+00 -3.1297e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7022e-02 -5.3878e-01 -1.5276e+00  ...  -3.1693e+00 -3.1297e+00 -1.0000e+02
  7.7022e-02 -5.3878e-01 -1.5276e+00  ...  -3.1693e+00 -3.1297e+00 -1.0000e+02
  7.7022e-02 -5.3878e-01 -1.5276e+00  ...  -3.1693e+00 -3.1297e+00 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 0, 22, 0, 55, 1], [7, 0, 22, 0, 54, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    1.1560    0.6614   -0.2498  ...  -100.0000 -100.0000 -100.0000
   -0.9962   -1.5020   -2.3482  ...  -100.0000 -100.0000 -100.0000
   -1.1386   -1.6380   -2.4664  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4850   -1.0061   -1.8904  ...  -100.0000 -100.0000 -100.0000
    0.2108   -0.3215   -1.2503  ...  -100.0000 -100.0000 -100.0000
    0.2108   -0.3215   -1.2503  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    0.9929    0.4301   -0.4785  ...  -100.0000 -100.0000 -100.0000
   -1.3043   -1.8683   -2.6831  ...  -100.0000 -100.0000 -100.0000
   -1.3040   -1.8663   -2.6769  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.6631   -1.2536   -2.1239  ...  -100.0000 -100.0000 -100.0000
    0.0474   -0.5619   -1.4866  ...  -100.0000 -100.0000 -100.0000
    0.0474   -0.5619   -1.4866  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    1.1313    0.5539   -0.4676  ...  -100.0000 -100.0000 -100.0000
   -0.9564   -1.5436   -2.4792  ...  -100.0000 -100.0000 -100.0000
   -1.0511   -1.6336   -2.5547  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4455   -1.0503   -2.0291  ...  -100.0000 -100.0000 -100.0000
   -0.1124   -0.7260   -1.7343  ...  -100.0000 -100.0000 -100.0000
    0.0259   -0.5901   -1.6088  ...  -100.0000 -100.0000 -100.0000

(3 ,.,.) = 
    1.1726    0.6260   -0.3327  ...    -1.7243   -1.9093   -2.1159
    0.1109   -0.4887   -1.4704  ...    -2.7280   -2.8799   -3.0724
    0.1109   -0.4887   -1.4704  ...    -2.7280   -2.8799   -3.0724
              ...                ⋱                ...             
    0.1109   -0.4887   -1.4704  ...    -2.7280   -2.8799   -3.0724
    0.1109   -0.4887   -1.4704  ...    -2.7280   -2.8799   -3.0724
    0.1109   -0.4887   -1.4704  ...    -2.7280   -2.8799   -3.0724

(4 ,.,.) = 
    1.0511    0.4476   -0.7213  ...  -100.0000 -100.0000 -100.0000
   -0.9085   -1.5195   -2.5790  ...  -100.0000 -100.0000 -100.0000
   -0.9968   -1.6021   -2.6447  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.4332   -1.0596   -2.1648  ...  -100.0000 -100.0000 -100.0000
   -0.0805   -0.7163   -1.8575  ...  -100.0000 -100.0000 -100.0000
    0.0548   -0.5836   -1.7376  ...  -100.0000 -100.0000 -100.0000

(5 ,.,.) = 
    1.0617    0.4384   -0.6081  ...  -100.0000 -100.0000 -100.0000
    0.1477   -0.5157   -1.5644  ...  -100.0000 -100.0000 -100.0000
    0.1477   -0.5157   -1.5644  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.1477   -0.5157   -1.5644  ...  -100.0000 -100.0000 -100.0000
    0.1477   -0.5157   -1.5644  ...  -100.0000 -100.0000 -100.0000
    0.1477   -0.5157   -1.5644  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x7x61 (GPU 0)]

 Loss = 4.77847506018
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  1.1786e+00  6.1493e-01 -3.9099e-01  ...  -1.8088e+00 -2.0334e+00 -1.0000e+02
 -1.2977e+00 -1.8646e+00 -2.7571e+00  ...  -3.7126e+00 -3.8807e+00 -1.0000e+02
 -1.3192e+00 -1.8830e+00 -2.7680e+00  ...  -3.7198e+00 -3.8861e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  5.9364e-03 -6.0519e-01 -1.6189e+00  ...  -2.8552e+00 -3.0553e+00 -1.0000e+02
  5.9364e-03 -6.0519e-01 -1.6189e+00  ...  -2.8552e+00 -3.0553e+00 -1.0000e+02
  5.9364e-03 -6.0519e-01 -1.6189e+00  ...  -2.8552e+00 -3.0553e+00 -1.0000e+02

( 1 ,.,.) = 
  1.2133e+00  6.5194e-01 -3.5158e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3014e+00 -1.8679e+00 -2.7598e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3357e+00 -1.8983e+00 -2.7812e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2161e-03 -6.0472e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2161e-03 -6.0472e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2161e-03 -6.0472e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.2902e+00  7.3513e-01 -2.6090e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3492e+00 -1.9131e+00 -2.7993e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3889e+00 -1.9487e+00 -2.8252e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.8998e-03 -6.0526e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8998e-03 -6.0526e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8998e-03 -6.0526e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.3660e+00  8.1690e-01 -1.7213e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3683e+00 -1.9309e+00 -2.8147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4262e+00 -1.9837e+00 -2.8556e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0227e-03 -6.0506e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0227e-03 -6.0506e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0227e-03 -6.0506e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.3679e+00  8.1985e-01 -1.6753e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3866e+00 -1.9480e+00 -2.8293e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4344e+00 -1.9913e+00 -2.8619e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2214e-03 -6.0471e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2214e-03 -6.0471e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2214e-03 -6.0471e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.2323e+00  6.7365e-01 -3.2621e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3397e+00 -1.9040e+00 -2.7911e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3637e+00 -1.9247e+00 -2.8041e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.1957e-03 -6.0475e-01 -1.6183e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1957e-03 -6.0475e-01 -1.6183e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1957e-03 -6.0475e-01 -1.6183e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.2792e+00  7.2352e-01 -2.7319e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3482e+00 -1.9121e+00 -2.7984e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3809e+00 -1.9411e+00 -2.8186e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0113e-03 -6.0507e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0113e-03 -6.0507e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0113e-03 -6.0507e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.1656e+00  6.0145e-01 -4.0464e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3009e+00 -1.8674e+00 -2.7593e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3203e+00 -1.8838e+00 -2.7684e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2273e-03 -6.0470e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2273e-03 -6.0470e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2273e-03 -6.0470e-01 -1.6182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.2124e+00  6.5145e-01 -3.5126e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3181e+00 -1.8837e+00 -2.7736e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3436e+00 -1.9059e+00 -2.7879e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0398e-03 -6.0502e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0398e-03 -6.0502e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0398e-03 -6.0502e-01 -1.6187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.2825e+00  7.2684e-01 -2.6988e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3461e+00 -1.9101e+00 -2.7967e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3835e+00 -1.9436e+00 -2.8208e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.9190e-03 -6.0523e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9190e-03 -6.0523e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9190e-03 -6.0523e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  9.6951e-01  3.9097e-01 -6.2970e-01  ...  -1.7433e+00 -2.0426e+00 -1.0000e+02
 -1.1698e+00 -1.7436e+00 -2.6514e+00  ...  -3.4317e+00 -3.6632e+00 -1.0000e+02
 -1.1682e+00 -1.7401e+00 -2.6430e+00  ...  -3.4241e+00 -3.6544e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0451e-03 -6.0501e-01 -1.6187e+00  ...  -2.6043e+00 -2.8754e+00 -1.0000e+02
  6.0451e-03 -6.0501e-01 -1.6187e+00  ...  -2.6043e+00 -2.8754e+00 -1.0000e+02
  6.0451e-03 -6.0501e-01 -1.6187e+00  ...  -2.6043e+00 -2.8754e+00 -1.0000e+02

(14 ,.,.) = 
  1.2499e+00  6.9078e-01 -3.1042e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3110e+00 -1.8771e+00 -2.7681e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3533e+00 -1.9152e+00 -2.7962e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.9579e-03 -6.0517e-01 -1.6189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9579e-03 -6.0517e-01 -1.6189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9579e-03 -6.0517e-01 -1.6189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.1831e+00  6.1961e-01 -3.8607e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2921e+00 -1.8590e+00 -2.7519e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3207e+00 -1.8841e+00 -2.7687e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3232e-03 -6.0454e-01 -1.6180e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3232e-03 -6.0454e-01 -1.6180e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3232e-03 -6.0454e-01 -1.6180e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  1.2929e+00  7.3810e-01 -2.5765e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3510e+00 -1.9147e+00 -2.8007e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3913e+00 -1.9510e+00 -2.8272e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.9028e-03 -6.0526e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9028e-03 -6.0526e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9028e-03 -6.0526e-01 -1.6190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.2164e+00  6.5551e-01 -3.4722e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3151e+00 -1.8810e+00 -2.7713e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3439e+00 -1.9062e+00 -2.7882e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.9737e-03 -6.0514e-01 -1.6189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9737e-03 -6.0514e-01 -1.6189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.9737e-03 -6.0514e-01 -1.6189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  1.1373e+00  5.7093e-01 -4.3760e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2827e+00 -1.8501e+00 -2.7442e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2937e+00 -1.8586e+00 -2.7464e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2681e-03 -6.0463e-01 -1.6181e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2681e-03 -6.0463e-01 -1.6181e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2681e-03 -6.0463e-01 -1.6181e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  1.1438e+00  5.7788e-01 -4.3020e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2854e+00 -1.8528e+00 -2.7465e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3015e+00 -1.8660e+00 -2.7529e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2596e-03 -6.0464e-01 -1.6181e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2596e-03 -6.0464e-01 -1.6181e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2596e-03 -6.0464e-01 -1.6181e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  1.3005e+00  7.4601e-01 -2.4969e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3428e+00 -1.9070e+00 -2.7941e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3853e+00 -1.9454e+00 -2.8224e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0014e-03 -6.0509e-01 -1.6188e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0014e-03 -6.0509e-01 -1.6188e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0014e-03 -6.0509e-01 -1.6188e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  1.2049e+00  6.4335e-01 -3.6014e-01  ...  -1.7178e+00 -1.8495e+00 -2.0495e+00
 -1.3134e+00 -1.8794e+00 -2.7700e+00  ...  -3.6829e+00 -3.7702e+00 -3.9194e+00
 -1.3372e+00 -1.9000e+00 -2.7828e+00  ...  -3.6930e+00 -3.7786e+00 -3.9261e+00
                 ...                   ⋱                   ...                
  5.9061e-03 -6.0524e-01 -1.6190e+00  ...  -2.8061e+00 -2.9159e+00 -3.0936e+00
  5.9061e-03 -6.0524e-01 -1.6190e+00  ...  -2.8061e+00 -2.9159e+00 -3.0936e+00
  5.9061e-03 -6.0524e-01 -1.6190e+00  ...  -2.8061e+00 -2.9159e+00 -3.0936e+00

( 1 ,.,.) = 
  1.1982e+00  6.3622e-01 -3.6772e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3109e+00 -1.8769e+00 -2.7677e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3360e+00 -1.8987e+00 -2.7815e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0767e-03 -6.0496e-01 -1.6186e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0767e-03 -6.0496e-01 -1.6186e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0767e-03 -6.0496e-01 -1.6186e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  1.1844e+00  6.2169e-01 -3.8286e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3099e+00 -1.8759e+00 -2.7668e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3276e+00 -1.8907e+00 -2.7745e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.1624e-03 -6.0481e-01 -1.6184e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1624e-03 -6.0481e-01 -1.6184e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1624e-03 -6.0481e-01 -1.6184e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  1.2749e+00  7.1849e-01 -2.7934e-01  ...  -2.5175e+00 -2.6727e+00 -2.1013e+00
 -1.3390e+00 -1.9036e+00 -2.7911e+00  ...  -4.2828e+00 -4.3745e+00 -4.0181e+00
 -1.3782e+00 -1.9387e+00 -2.8166e+00  ...  -4.2962e+00 -4.3866e+00 -4.0335e+00
                 ...                   ⋱                   ...                
  5.8709e-03 -6.0531e-01 -1.6191e+00  ...  -3.5457e+00 -3.6675e+00 -3.2020e+00
  5.8709e-03 -6.0531e-01 -1.6191e+00  ...  -3.5457e+00 -3.6675e+00 -3.2020e+00
  5.8709e-03 -6.0531e-01 -1.6191e+00  ...  -3.5457e+00 -3.6675e+00 -3.2020e+00

( 4 ,.,.) = 
  1.0503e+00  4.7675e-01 -5.3951e-01  ...  -1.9933e+00 -1.0000e+02 -1.0000e+02
 -1.2146e+00 -1.7860e+00 -2.6885e+00  ...  -3.7111e+00 -1.0000e+02 -1.0000e+02
 -1.2306e+00 -1.7991e+00 -2.6948e+00  ...  -3.7133e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0314e-03 -6.0504e-01 -1.6187e+00  ...  -2.9029e+00 -1.0000e+02 -1.0000e+02
  6.0314e-03 -6.0504e-01 -1.6187e+00  ...  -2.9029e+00 -1.0000e+02 -1.0000e+02
  6.0314e-03 -6.0504e-01 -1.6187e+00  ...  -2.9029e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  1.0025e+00  4.2616e-01 -5.9254e-01  ...  -2.0311e+00 -1.0000e+02 -1.0000e+02
 -1.1925e+00 -1.7650e+00 -2.6700e+00  ...  -3.6920e+00 -1.0000e+02 -1.0000e+02
 -1.1957e+00 -1.7661e+00 -2.6657e+00  ...  -3.6862e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.1425e-03 -6.0484e-01 -1.6184e+00  ...  -2.8944e+00 -1.0000e+02 -1.0000e+02
  6.1425e-03 -6.0484e-01 -1.6184e+00  ...  -2.8944e+00 -1.0000e+02 -1.0000e+02
  6.1425e-03 -6.0484e-01 -1.6184e+00  ...  -2.8944e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    1.2566    0.6533   -0.4057  ...  -100.0000 -100.0000 -100.0000
   -1.4098   -2.0158   -2.9378  ...  -100.0000 -100.0000 -100.0000
   -1.4488   -2.0502   -2.9616  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0616   -0.7222   -1.7862  ...  -100.0000 -100.0000 -100.0000
   -0.0616   -0.7222   -1.7862  ...  -100.0000 -100.0000 -100.0000
   -0.0616   -0.7222   -1.7862  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.2672    0.6631   -0.3977  ...  -100.0000 -100.0000 -100.0000
   -1.3768   -1.9848   -2.9113  ...  -100.0000 -100.0000 -100.0000
   -1.4367   -2.0389   -2.9520  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0614   -0.7218   -1.7857  ...  -100.0000 -100.0000 -100.0000
   -0.0614   -0.7218   -1.7857  ...  -100.0000 -100.0000 -100.0000
   -0.0614   -0.7218   -1.7857  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.2916    0.6907   -0.3657  ...  -100.0000 -100.0000 -100.0000
   -1.4235   -2.0290   -2.9496  ...  -100.0000 -100.0000 -100.0000
   -1.4681   -2.0687   -2.9779  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0623   -0.7235   -1.7881  ...  -100.0000 -100.0000 -100.0000
   -0.0623   -0.7235   -1.7881  ...  -100.0000 -100.0000 -100.0000
   -0.0623   -0.7235   -1.7881  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.2119    0.6048   -0.4582  ...  -100.0000 -100.0000 -100.0000
   -1.3929   -2.0000   -2.9242  ...  -100.0000 -100.0000 -100.0000
   -1.4248   -2.0277   -2.9422  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0615   -0.7220   -1.7860  ...  -100.0000 -100.0000 -100.0000
   -0.0615   -0.7220   -1.7860  ...  -100.0000 -100.0000 -100.0000
   -0.0615   -0.7220   -1.7860  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.3000    0.7006   -0.3539  ...  -100.0000 -100.0000 -100.0000
   -1.4365   -2.0410   -2.9595  ...  -100.0000 -100.0000 -100.0000
   -1.4770   -2.0768   -2.9846  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0620   -0.7229   -1.7873  ...  -100.0000 -100.0000 -100.0000
   -0.0620   -0.7229   -1.7873  ...  -100.0000 -100.0000 -100.0000
   -0.0620   -0.7229   -1.7873  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    1.2566    0.6533   -0.4057  ...  -100.0000 -100.0000 -100.0000
   -1.4098   -2.0158   -2.9378  ...  -100.0000 -100.0000 -100.0000
   -1.4488   -2.0502   -2.9616  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0616   -0.7222   -1.7862  ...  -100.0000 -100.0000 -100.0000
   -0.0616   -0.7222   -1.7862  ...  -100.0000 -100.0000 -100.0000
   -0.0616   -0.7222   -1.7862  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.2564    0.6532   -0.4057  ...  -100.0000 -100.0000 -100.0000
   -1.4078   -2.0137   -2.9357  ...  -100.0000 -100.0000 -100.0000
   -1.4470   -2.0482   -2.9596  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0612   -0.7216   -1.7854  ...  -100.0000 -100.0000 -100.0000
   -0.0612   -0.7216   -1.7854  ...  -100.0000 -100.0000 -100.0000
   -0.0612   -0.7216   -1.7854  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.2564    0.6532   -0.4057  ...  -100.0000 -100.0000 -100.0000
   -1.4078   -2.0137   -2.9357  ...  -100.0000 -100.0000 -100.0000
   -1.4470   -2.0482   -2.9596  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0612   -0.7216   -1.7854  ...  -100.0000 -100.0000 -100.0000
   -0.0612   -0.7216   -1.7854  ...  -100.0000 -100.0000 -100.0000
   -0.0612   -0.7216   -1.7854  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.2390    0.6338   -0.4273  ...  -100.0000 -100.0000 -100.0000
   -1.4032   -2.0101   -2.9333  ...  -100.0000 -100.0000 -100.0000
   -1.4389   -2.0413   -2.9544  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0622   -0.7233   -1.7878  ...  -100.0000 -100.0000 -100.0000
   -0.0622   -0.7233   -1.7878  ...  -100.0000 -100.0000 -100.0000
   -0.0622   -0.7233   -1.7878  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    1.1811    0.5707   -0.4960  ...    -1.9856   -1.8128   -2.0126
   -1.3745   -1.9836   -2.9110  ...    -3.8957   -3.7695   -3.9177
   -1.4061   -2.0109   -2.9288  ...    -3.9098   -3.7833   -3.9292
              ...                ⋱                ...             
   -0.0626   -0.7239   -1.7887  ...    -3.0744   -2.9183   -3.0944
   -0.0626   -0.7239   -1.7887  ...    -3.0744   -2.9183   -3.0944
   -0.0626   -0.7239   -1.7887  ...    -3.0744   -2.9183   -3.0944

( 4 ,.,.) = 
    1.1534    0.5417   -0.5260  ...    -1.8176   -2.0362 -100.0000
   -1.3744   -1.9830   -2.9100  ...    -3.7519   -3.9144 -100.0000
   -1.3943   -1.9994   -2.9183  ...    -3.7582   -3.9190 -100.0000
              ...                ⋱                ...             
   -0.0620   -0.7229   -1.7873  ...    -2.8957   -3.0899 -100.0000
   -0.0620   -0.7229   -1.7873  ...    -2.8957   -3.0899 -100.0000
   -0.0620   -0.7229   -1.7873  ...    -2.8957   -3.0899 -100.0000

( 5 ,.,.) = 
    1.2171    0.6109   -0.4510  ...  -100.0000 -100.0000 -100.0000
   -1.4068   -2.0132   -2.9357  ...  -100.0000 -100.0000 -100.0000
   -1.4336   -2.0362   -2.9497  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
   -0.0619   -0.7227   -1.7870  ...  -100.0000 -100.0000 -100.0000
   -0.0619   -0.7227   -1.7870  ...  -100.0000 -100.0000 -100.0000
   -0.0619   -0.7227   -1.7870  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 12 @ 2018-04-12 20:36:16.578304
training
gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  9.7151e-01  3.3218e-01 -7.5493e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4856e-01 -5.2792e-01 -1.6112e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4856e-01 -5.2792e-01 -1.6112e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4856e-01 -5.2792e-01 -1.6112e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4856e-01 -5.2792e-01 -1.6112e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4856e-01 -5.2792e-01 -1.6112e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.1232e+00  5.2012e-01 -4.6282e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2518e-01 -5.3131e-01 -1.5318e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2518e-01 -5.3131e-01 -1.5318e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2518e-01 -5.3131e-01 -1.5318e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2518e-01 -5.3131e-01 -1.5318e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2518e-01 -5.3131e-01 -1.5318e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.2403e+00  7.1649e-01 -2.4520e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6467e-01 -4.1038e-01 -1.3992e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6467e-01 -4.1038e-01 -1.3992e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6467e-01 -4.1038e-01 -1.3992e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6467e-01 -4.1038e-01 -1.3992e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6467e-01 -4.1038e-01 -1.3992e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.0681e+00  5.2927e-01 -4.5400e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4099e+00 -1.9465e+00 -2.8129e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3407e+00 -1.8793e+00 -2.7501e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4208e-01 -4.4317e-01 -1.4477e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4208e-01 -4.4317e-01 -1.4477e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4208e-01 -4.4317e-01 -1.4477e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.4703e+00  9.8747e-01  1.0652e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2682e-01 -3.1317e-01 -1.2326e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2682e-01 -3.1317e-01 -1.2326e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.2682e-01 -3.1317e-01 -1.2326e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2682e-01 -3.1317e-01 -1.2326e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.2682e-01 -3.1317e-01 -1.2326e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.3656e+00  7.8395e-01 -1.1959e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3153e+00 -1.9126e+00 -2.7289e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3258e+00 -1.9208e+00 -2.7312e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -5.2564e-02 -6.9699e-01 -1.6189e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5098e-01 -4.9601e-01 -1.4296e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5098e-01 -4.9601e-01 -1.4296e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 0, 24, 0, 60, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.4547e+00  9.2232e-01  4.0455e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5463e-01 -4.4522e-01 -1.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5463e-01 -4.4522e-01 -1.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5463e-01 -4.4522e-01 -1.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5463e-01 -4.4522e-01 -1.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5463e-01 -4.4522e-01 -1.4006e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.3667e+00  8.1307e-01 -1.1016e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2295e+00 -1.7976e+00 -2.6331e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2438e+00 -1.8094e+00 -2.6387e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
 -1.0229e-01 -7.0854e-01 -1.6377e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3761e-01 -4.7243e-01 -1.4176e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.1040e-01 -3.0075e-01 -1.2548e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.2255e+00  7.2183e-01 -1.5440e-01  ...  -1.6650e+00 -1.8258e+00 -1.0000e+02
 -1.2378e+00 -1.7456e+00 -2.5394e+00  ...  -3.5987e+00 -3.7198e+00 -1.0000e+02
 -1.2462e+00 -1.7518e+00 -2.5399e+00  ...  -3.5967e+00 -3.7169e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -1.7732e-01 -7.1718e-01 -1.5912e+00  ...  -2.8764e+00 -3.0161e+00 -1.0000e+02
  2.7570e-02 -5.1554e-01 -1.4023e+00  ...  -2.7302e+00 -2.8735e+00 -1.0000e+02
  1.5641e-01 -3.8781e-01 -1.2804e+00  ...  -2.6408e+00 -2.7864e+00 -1.0000e+02
...

(12,.,.) = 
  1.2736e+00  7.5004e-01 -2.2741e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2228e+00 -1.7536e+00 -2.6326e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1518e+00 -1.6844e+00 -2.5672e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.3662e-01 -3.3297e-01 -1.3308e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3662e-01 -3.3297e-01 -1.3308e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3662e-01 -3.3297e-01 -1.3308e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.4697e+00  9.2445e-01 -7.1443e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5418e-01 -4.5733e-01 -1.4864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5418e-01 -4.5733e-01 -1.4864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5418e-01 -4.5733e-01 -1.4864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5418e-01 -4.5733e-01 -1.4864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5418e-01 -4.5733e-01 -1.4864e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.1817e+00  5.8745e-01 -4.1052e-01  ...  -1.4198e+00 -1.6532e+00 -2.0015e+00
 -1.2748e+00 -1.8679e+00 -2.7450e+00  ...  -3.4236e+00 -3.5877e+00 -3.8432e+00
 -1.2380e+00 -1.8315e+00 -2.7088e+00  ...  -3.3899e+00 -3.5548e+00 -3.8110e+00
                 ...                   ⋱                   ...                
  1.6344e-01 -4.7655e-01 -1.4823e+00  ...  -2.3856e+00 -2.5922e+00 -2.9037e+00
  1.6344e-01 -4.7655e-01 -1.4823e+00  ...  -2.3856e+00 -2.5922e+00 -2.9037e+00
  1.6344e-01 -4.7655e-01 -1.4823e+00  ...  -2.3856e+00 -2.5922e+00 -2.9037e+00
[torch.cuda.FloatTensor of size 15x8x63 (GPU 0)]

gt_where_seq [[7, 0, 22, 0, 55, 1], [7, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 0, 32, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  1.5045e+00  1.0067e+00  5.0038e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4908e+00 -1.9970e+00 -2.8416e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3603e+00 -1.8717e+00 -2.7278e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.7115e-01 -2.8781e-01 -1.2857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7115e-01 -2.8781e-01 -1.2857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.7115e-01 -2.8781e-01 -1.2857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.3883e+00  9.3330e-01  2.7996e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5457e-01 -2.4950e-01 -1.1922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5457e-01 -2.4950e-01 -1.1922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.5457e-01 -2.4950e-01 -1.1922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5457e-01 -2.4950e-01 -1.1922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.5457e-01 -2.4950e-01 -1.1922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.5277e+00  9.3403e-01 -1.1560e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1787e-01 -4.5348e-01 -1.5378e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1787e-01 -4.5348e-01 -1.5378e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1787e-01 -4.5348e-01 -1.5378e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1787e-01 -4.5348e-01 -1.5378e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.1787e-01 -4.5348e-01 -1.5378e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  1.5698e+00  1.1089e+00  3.0706e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2397e+00 -1.7202e+00 -2.4677e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2570e+00 -1.7344e+00 -2.4753e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1522e-01 -2.9986e-01 -1.1392e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3065e-01 -1.8477e-01 -1.0283e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.3065e-01 -1.8477e-01 -1.0283e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.2317e+00  7.6681e-01 -2.1191e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4698e+00 -1.9303e+00 -2.7896e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3407e+00 -1.8050e+00 -2.6747e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1190e-01 -3.9230e-01 -1.3869e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3110e-01 -2.7378e-01 -1.2745e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.3110e-01 -2.7378e-01 -1.2745e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  1.1649e+00  6.3866e-01 -4.0225e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4174e+00 -1.9362e+00 -2.8381e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2262e+00 -1.7527e+00 -2.6734e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4989e-02 -4.9006e-01 -1.5342e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6603e-01 -3.9945e-01 -1.4482e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6603e-01 -3.9945e-01 -1.4482e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    1.5988    1.0755    0.0802  ...  -100.0000 -100.0000 -100.0000
   -1.4942   -2.0282   -2.9010  ...  -100.0000 -100.0000 -100.0000
   -1.3109   -1.8525   -2.7427  ...  -100.0000 -100.0000 -100.0000
   -0.8192   -1.3823   -2.3248  ...  -100.0000 -100.0000 -100.0000
   -0.2835   -0.8641   -1.8573  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    1.6905    1.2558    0.3664  ...    -2.2390   -2.5265   -1.9955
    0.3599   -0.1424   -1.0927  ...    -3.3853   -3.6117   -3.1842
    0.3599   -0.1424   -1.0927  ...    -3.3853   -3.6117   -3.1842
    0.3599   -0.1424   -1.0927  ...    -3.3853   -3.6117   -3.1842
    0.3599   -0.1424   -1.0927  ...    -3.3853   -3.6117   -3.1842

(2 ,.,.) = 
    2.0548    1.6982    0.8442  ...    -1.5576 -100.0000 -100.0000
    0.3415   -0.0932   -1.0493  ...    -3.1734 -100.0000 -100.0000
    0.3415   -0.0932   -1.0493  ...    -3.1734 -100.0000 -100.0000
    0.3415   -0.0932   -1.0493  ...    -3.1734 -100.0000 -100.0000
    0.3415   -0.0932   -1.0493  ...    -3.1734 -100.0000 -100.0000

(3 ,.,.) = 
    1.6830    1.2173    0.2588  ...    -1.7367 -100.0000 -100.0000
   -1.4160   -1.9029   -2.7685  ...    -4.0620 -100.0000 -100.0000
   -1.1904   -1.6857   -2.5728  ...    -3.9233 -100.0000 -100.0000
   -0.7388   -1.2503   -2.1810  ...    -3.6516 -100.0000 -100.0000
   -0.2043   -0.7301   -1.7064  ...    -3.3188 -100.0000 -100.0000

(4 ,.,.) = 
    1.7616    1.3254    0.4562  ...  -100.0000 -100.0000 -100.0000
    0.2662   -0.2403   -1.1726  ...  -100.0000 -100.0000 -100.0000
    0.2662   -0.2403   -1.1726  ...  -100.0000 -100.0000 -100.0000
    0.2662   -0.2403   -1.1726  ...  -100.0000 -100.0000 -100.0000
    0.2662   -0.2403   -1.1726  ...  -100.0000 -100.0000 -100.0000

(5 ,.,.) = 
    2.0028    1.6353    0.8705  ...  -100.0000 -100.0000 -100.0000
    0.2716   -0.1703   -1.0229  ...  -100.0000 -100.0000 -100.0000
    0.2716   -0.1703   -1.0229  ...  -100.0000 -100.0000 -100.0000
    0.2716   -0.1703   -1.0229  ...  -100.0000 -100.0000 -100.0000
    0.2716   -0.1703   -1.0229  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x5x61 (GPU 0)]

 Loss = 4.7285286679
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    1.9528    1.5291    0.6246  ...    -1.3803   -1.6431 -100.0000
   -1.7493   -2.1937   -2.9992  ...    -4.1876   -4.3524 -100.0000
   -1.4030   -1.8621   -2.7037  ...    -3.9838   -4.1592 -100.0000
              ...                ⋱                ...             
    0.2903   -0.2123   -1.1937  ...    -2.9287   -3.1542 -100.0000
    0.2903   -0.2123   -1.1937  ...    -2.9287   -3.1542 -100.0000
    0.2903   -0.2123   -1.1937  ...    -2.9287   -3.1542 -100.0000

( 1 ,.,.) = 
    1.9855    1.5642    0.6636  ...  -100.0000 -100.0000 -100.0000
   -1.7521   -2.1962   -3.0012  ...  -100.0000 -100.0000 -100.0000
   -1.4222   -1.8803   -2.7194  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    2.1045    1.6926    0.8079  ...  -100.0000 -100.0000 -100.0000
   -1.8122   -2.2532   -3.0509  ...  -100.0000 -100.0000 -100.0000
   -1.4905   -1.9455   -2.7772  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2903   -0.2124   -1.1938  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2124   -1.1938  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2124   -1.1938  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    2.1941    1.7894    0.9170  ...  -100.0000 -100.0000 -100.0000
   -1.8314   -2.2713   -3.0666  ...  -100.0000 -100.0000 -100.0000
   -1.5381   -1.9908   -2.8170  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    2.1968    1.7929    0.9223  ...  -100.0000 -100.0000 -100.0000
   -1.8527   -2.2913   -3.0835  ...  -100.0000 -100.0000 -100.0000
   -1.5423   -1.9946   -2.8200  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    2.0327    1.6159    0.7231  ...  -100.0000 -100.0000 -100.0000
   -1.8031   -2.2443   -3.0427  ...  -100.0000 -100.0000 -100.0000
   -1.4569   -1.9133   -2.7485  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2905   -0.2119   -1.1930  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1930  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1930  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    2.0736    1.6595    0.7711  ...  -100.0000 -100.0000 -100.0000
   -1.8060   -2.2473   -3.0457  ...  -100.0000 -100.0000 -100.0000
   -1.4715   -1.9274   -2.7611  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    1.9296    1.5046    0.5983  ...  -100.0000 -100.0000 -100.0000
   -1.7508   -2.1949   -2.9998  ...  -100.0000 -100.0000 -100.0000
   -1.4006   -1.8596   -2.7011  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2119   -1.1929  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.9940    1.5737    0.6748  ...  -100.0000 -100.0000 -100.0000
   -1.7725   -2.2155   -3.0180  ...  -100.0000 -100.0000 -100.0000
   -1.4297   -1.8875   -2.7259  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2904   -0.2121   -1.1934  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2121   -1.1934  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2121   -1.1934  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    2.0939    1.6812    0.7951  ...  -100.0000 -100.0000 -100.0000
   -1.8086   -2.2498   -3.0479  ...  -100.0000 -100.0000 -100.0000
   -1.4834   -1.9387   -2.7712  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2903   -0.2123   -1.1937  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2123   -1.1937  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2123   -1.1937  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.6272    1.1804    0.2404  ...    -1.4329   -1.7830 -100.0000
   -1.5735   -2.0270   -2.8538  ...    -3.9022   -4.1335 -100.0000
   -1.2161   -1.6834   -2.5453  ...    -3.6729   -3.9188 -100.0000
              ...                ⋱                ...             
    0.2904   -0.2121   -1.1934  ...    -2.6620   -2.9681 -100.0000
    0.2904   -0.2121   -1.1934  ...    -2.6620   -2.9681 -100.0000
    0.2904   -0.2121   -1.1934  ...    -2.6620   -2.9681 -100.0000

(14 ,.,.) = 
    2.0190    1.5997    0.7023  ...  -100.0000 -100.0000 -100.0000
   -1.7537   -2.1980   -3.0031  ...  -100.0000 -100.0000 -100.0000
   -1.4369   -1.8945   -2.7324  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2903   -0.2123   -1.1936  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2123   -1.1936  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2123   -1.1936  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.9537    1.5301    0.6259  ...  -100.0000 -100.0000 -100.0000
   -1.7433   -2.1878   -2.9937  ...  -100.0000 -100.0000 -100.0000
   -1.4064   -1.8651   -2.7059  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2906   -0.2117   -1.1927  ...  -100.0000 -100.0000 -100.0000
    0.2906   -0.2117   -1.1927  ...  -100.0000 -100.0000 -100.0000
    0.2906   -0.2117   -1.1927  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    2.1081    1.6965    0.8124  ...  -100.0000 -100.0000 -100.0000
   -1.8139   -2.2548   -3.0523  ...  -100.0000 -100.0000 -100.0000
   -1.4937   -1.9486   -2.7799  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2903   -0.2123   -1.1938  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2123   -1.1938  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2123   -1.1938  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    2.0120    1.5928    0.6959  ...  -100.0000 -100.0000 -100.0000
   -1.7746   -2.2176   -3.0198  ...  -100.0000 -100.0000 -100.0000
   -1.4375   -1.8950   -2.7326  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2903   -0.2122   -1.1936  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2122   -1.1936  ...  -100.0000 -100.0000 -100.0000
    0.2903   -0.2122   -1.1936  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    1.8712    1.4419    0.5286  ...  -100.0000 -100.0000 -100.0000
   -1.7212   -2.1668   -2.9753  ...  -100.0000 -100.0000 -100.0000
   -1.3597   -1.8205   -2.6665  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2906   -0.2118   -1.1928  ...  -100.0000 -100.0000 -100.0000
    0.2906   -0.2118   -1.1928  ...  -100.0000 -100.0000 -100.0000
    0.2906   -0.2118   -1.1928  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    1.8988    1.4714    0.5611  ...  -100.0000 -100.0000 -100.0000
   -1.7312   -2.1764   -2.9837  ...  -100.0000 -100.0000 -100.0000
   -1.3781   -1.8380   -2.6820  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2905   -0.2118   -1.1928  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2118   -1.1928  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2118   -1.1928  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    2.0883    1.6749    0.7876  ...  -100.0000 -100.0000 -100.0000
   -1.7932   -2.2353   -3.0355  ...  -100.0000 -100.0000 -100.0000
   -1.4744   -1.9302   -2.7638  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2122   -1.1935  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    1.9930    1.5725    0.6732  ...    -1.2292   -1.4170   -1.6495
   -1.7705   -2.2138   -3.0166  ...    -4.1475   -4.2469   -4.3921
   -1.4259   -1.8840   -2.7229  ...    -3.9421   -4.0484   -4.2028
              ...                ⋱                ...             
    0.2903   -0.2123   -1.1937  ...    -2.8512   -2.9988   -3.1978
    0.2903   -0.2123   -1.1937  ...    -2.8512   -2.9988   -3.1978
    0.2903   -0.2123   -1.1937  ...    -2.8512   -2.9988   -3.1978

( 1 ,.,.) = 
    1.9808    1.5594    0.6589  ...  -100.0000 -100.0000 -100.0000
   -1.7668   -2.2102   -3.0133  ...  -100.0000 -100.0000 -100.0000
   -1.4239   -1.8819   -2.7210  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2904   -0.2121   -1.1933  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2121   -1.1933  ...  -100.0000 -100.0000 -100.0000
    0.2904   -0.2121   -1.1933  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    1.9625    1.5400    0.6377  ...  -100.0000 -100.0000 -100.0000
   -1.7658   -2.2091   -3.0122  ...  -100.0000 -100.0000 -100.0000
   -1.4115   -1.8700   -2.7103  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2905   -0.2120   -1.1931  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2120   -1.1931  ...  -100.0000 -100.0000 -100.0000
    0.2905   -0.2120   -1.1931  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    2.0663    1.6512    0.7610  ...    -2.0884   -2.2903   -1.6794
   -1.7917   -2.2339   -3.0343  ...    -4.6686   -4.7601   -4.4654
   -1.4695   -1.9256   -2.7597  ...    -4.5139   -4.6128   -4.2935
              ...                ⋱                ...             
    0.2902   -0.2124   -1.1939  ...    -3.6049   -3.7496   -3.2919
    0.2902   -0.2124   -1.1939  ...    -3.6049   -3.7496   -3.2919
    0.2902   -0.2124   -1.1939  ...    -3.6049   -3.7496   -3.2919

( 4 ,.,.) = 
    1.7589    1.3207    0.3932  ...    -1.6680 -100.0000 -100.0000
   -1.6400   -2.0901   -2.9089  ...    -4.1844 -100.0000 -100.0000
   -1.2960   -1.7598   -2.6132  ...    -3.9805 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2904   -0.2122   -1.1934  ...    -2.9914 -100.0000 -100.0000
    0.2904   -0.2122   -1.1934  ...    -2.9914 -100.0000 -100.0000
    0.2904   -0.2122   -1.1934  ...    -2.9914 -100.0000 -100.0000

( 5 ,.,.) = 
    1.6794    1.2360    0.3010  ...    -1.7448 -100.0000 -100.0000
   -1.6038   -2.0557   -2.8788  ...    -4.1602 -100.0000 -100.0000
   -1.2480   -1.7138   -2.5723  ...    -3.9480 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2905   -0.2120   -1.1931  ...    -2.9831 -100.0000 -100.0000
    0.2905   -0.2120   -1.1931  ...    -2.9831 -100.0000 -100.0000
    0.2905   -0.2120   -1.1931  ...    -2.9831 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    2.0803    1.6218    0.6589  ...  -100.0000 -100.0000 -100.0000
   -1.8600   -2.3438   -3.1862  ...  -100.0000 -100.0000 -100.0000
   -1.5345   -2.0345   -2.9151  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2350   -0.3208   -1.3720  ...  -100.0000 -100.0000 -100.0000
    0.2350   -0.3208   -1.3720  ...  -100.0000 -100.0000 -100.0000
    0.2350   -0.3208   -1.3720  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    2.0565    1.5947    0.6259  ...  -100.0000 -100.0000 -100.0000
   -1.8080   -2.2950   -3.1449  ...  -100.0000 -100.0000 -100.0000
   -1.5139   -2.0150   -2.8984  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2352   -0.3205   -1.3715  ...  -100.0000 -100.0000 -100.0000
    0.2352   -0.3205   -1.3715  ...  -100.0000 -100.0000 -100.0000
    0.2352   -0.3205   -1.3715  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    2.1300    1.6752    0.7184  ...  -100.0000 -100.0000 -100.0000
   -1.8757   -2.3589   -3.1998  ...  -100.0000 -100.0000 -100.0000
   -1.5599   -2.0590   -2.9370  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2344   -0.3220   -1.3740  ...  -100.0000 -100.0000 -100.0000
    0.2344   -0.3220   -1.3740  ...  -100.0000 -100.0000 -100.0000
    0.2344   -0.3220   -1.3740  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    2.0213    1.5577    0.5866  ...  -100.0000 -100.0000 -100.0000
   -1.8405   -2.3254   -3.1704  ...  -100.0000 -100.0000 -100.0000
   -1.5049   -2.0064   -2.8907  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2351   -0.3207   -1.3718  ...  -100.0000 -100.0000 -100.0000
    0.2351   -0.3207   -1.3718  ...  -100.0000 -100.0000 -100.0000
    0.2351   -0.3207   -1.3718  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    2.1407    1.6875    0.7335  ...  -100.0000 -100.0000 -100.0000
   -1.8903   -2.3724   -3.2109  ...  -100.0000 -100.0000 -100.0000
   -1.5680   -2.0664   -2.9430  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2347   -0.3215   -1.3732  ...  -100.0000 -100.0000 -100.0000
    0.2347   -0.3215   -1.3732  ...  -100.0000 -100.0000 -100.0000
    0.2347   -0.3215   -1.3732  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    2.0803    1.6218    0.6589  ...  -100.0000 -100.0000 -100.0000
   -1.8600   -2.3438   -3.1862  ...  -100.0000 -100.0000 -100.0000
   -1.5345   -2.0345   -2.9151  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2350   -0.3208   -1.3720  ...  -100.0000 -100.0000 -100.0000
    0.2350   -0.3208   -1.3720  ...  -100.0000 -100.0000 -100.0000
    0.2350   -0.3208   -1.3720  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    2.0744    1.6155    0.6521  ...  -100.0000 -100.0000 -100.0000
   -1.8564   -2.3402   -3.1828  ...  -100.0000 -100.0000 -100.0000
   -1.5306   -2.0305   -2.9114  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2353   -0.3203   -1.3711  ...  -100.0000 -100.0000 -100.0000
    0.2353   -0.3203   -1.3711  ...  -100.0000 -100.0000 -100.0000
    0.2353   -0.3203   -1.3711  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    2.0744    1.6155    0.6521  ...  -100.0000 -100.0000 -100.0000
   -1.8564   -2.3402   -3.1828  ...  -100.0000 -100.0000 -100.0000
   -1.5306   -2.0305   -2.9114  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2353   -0.3203   -1.3711  ...  -100.0000 -100.0000 -100.0000
    0.2353   -0.3203   -1.3711  ...  -100.0000 -100.0000 -100.0000
    0.2353   -0.3203   -1.3711  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    2.0584    1.5975    0.6308  ...  -100.0000 -100.0000 -100.0000
   -1.8518   -2.3365   -3.1806  ...  -100.0000 -100.0000 -100.0000
   -1.5217   -2.0229   -2.9057  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2345   -0.3219   -1.3738  ...  -100.0000 -100.0000 -100.0000
    0.2345   -0.3219   -1.3738  ...  -100.0000 -100.0000 -100.0000
    0.2345   -0.3219   -1.3738  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    1.9807    1.5128    0.5348  ...    -1.5123   -1.3706   -1.6063
   -1.8149   -2.3022   -3.1517  ...    -4.3296   -4.2397   -4.3862
   -1.4815   -1.9851   -2.8733  ...    -4.1437   -4.0465   -4.2016
              ...                ⋱                ...             
    0.2342   -0.3224   -1.3747  ...    -3.1191   -2.9934   -3.1938
    0.2342   -0.3224   -1.3747  ...    -3.1191   -2.9934   -3.1938
    0.2342   -0.3224   -1.3747  ...    -3.1191   -2.9934   -3.1938

( 4 ,.,.) = 
    1.9519    1.4824    0.5021  ...    -1.3885   -1.6420 -100.0000
   -1.8196   -2.3060   -3.1542  ...    -4.2321   -4.3895 -100.0000
   -1.4691   -1.9728   -2.8619  ...    -4.0284   -4.1963 -100.0000
              ...                ⋱                ...             
    0.2347   -0.3215   -1.3731  ...    -2.9792   -3.1958 -100.0000
    0.2347   -0.3215   -1.3731  ...    -2.9792   -3.1958 -100.0000
    0.2347   -0.3215   -1.3731  ...    -2.9792   -3.1958 -100.0000

( 5 ,.,.) = 
    2.0361    1.5740    0.6055  ...  -100.0000 -100.0000 -100.0000
   -1.8576   -2.3416   -3.1844  ...  -100.0000 -100.0000 -100.0000
   -1.5144   -2.0156   -2.8990  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.2348   -0.3213   -1.3728  ...  -100.0000 -100.0000 -100.0000
    0.2348   -0.3213   -1.3728  ...  -100.0000 -100.0000 -100.0000
    0.2348   -0.3213   -1.3728  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 13 @ 2018-04-12 20:36:19.079901
training
gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 0, 22, 0, 54, 1], [7, 0, 22, 0, 53, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.2096e+00  1.8175e+00  1.0270e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9808e-01 -8.4827e-02 -9.7425e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9808e-01 -8.4827e-02 -9.7425e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.9808e-01 -8.4827e-02 -9.7425e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9808e-01 -8.4827e-02 -9.7425e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9808e-01 -8.4827e-02 -9.7425e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.8909e+00  1.4827e+00  6.0644e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0173e-01 -8.1982e-02 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0173e-01 -8.1982e-02 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0173e-01 -8.1982e-02 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0173e-01 -8.1982e-02 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0173e-01 -8.1982e-02 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.6458e+00  1.1728e+00  3.7194e-01  ...  -1.7392e+00 -2.0110e+00 -1.0000e+02
  4.3332e-01 -1.0401e-01 -9.5736e-01  ...  -2.8588e+00 -3.0952e+00 -1.0000e+02
  4.3332e-01 -1.0401e-01 -9.5736e-01  ...  -2.8588e+00 -3.0952e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3332e-01 -1.0401e-01 -9.5736e-01  ...  -2.8588e+00 -3.0952e+00 -1.0000e+02
  4.3332e-01 -1.0401e-01 -9.5736e-01  ...  -2.8588e+00 -3.0952e+00 -1.0000e+02
  4.3332e-01 -1.0401e-01 -9.5736e-01  ...  -2.8588e+00 -3.0952e+00 -1.0000e+02
...

(12,.,.) = 
  1.9235e+00  1.5764e+00  7.0538e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7952e-01 -3.6245e-02 -9.9821e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7952e-01 -3.6245e-02 -9.9821e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.7952e-01 -3.6245e-02 -9.9821e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7952e-01 -3.6245e-02 -9.9821e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7952e-01 -3.6245e-02 -9.9821e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  1.8372e+00  1.3442e+00  4.8853e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9398e-01 -1.7645e-01 -1.0922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9398e-01 -1.7645e-01 -1.0922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.9398e-01 -1.7645e-01 -1.0922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9398e-01 -1.7645e-01 -1.0922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.9398e-01 -1.7645e-01 -1.0922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.1545e+00  1.7963e+00  8.6313e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0834e-01 -3.5939e-02 -1.0874e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0834e-01 -3.5939e-02 -1.0874e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0834e-01 -3.5939e-02 -1.0874e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0834e-01 -3.5939e-02 -1.0874e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0834e-01 -3.5939e-02 -1.0874e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 55, 1], [7, 0, 14, 0, 54, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.2859e+00  1.8804e+00  9.7815e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6802e-01 -4.1412e-02 -1.0656e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6802e-01 -4.1412e-02 -1.0656e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6802e-01 -4.1412e-02 -1.0656e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6802e-01 -4.1412e-02 -1.0656e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6802e-01 -4.1412e-02 -1.0656e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  1.9985e+00  1.5819e+00  8.1394e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6887e+00 -2.1228e+00 -2.8163e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1846e+00 -1.6387e+00 -2.3751e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  2.1597e-02 -4.6273e-01 -1.2808e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6098e-01 -2.5557e-02 -8.6184e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5336e-01  6.7062e-02 -7.7239e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.8638e+00  1.4623e+00  6.0700e-01  ...  -1.3603e+00 -1.5649e+00 -1.0000e+02
 -1.9749e+00 -2.3808e+00 -3.1178e+00  ...  -4.2554e+00 -4.3782e+00 -1.0000e+02
 -1.3425e+00 -1.7766e+00 -2.5812e+00  ...  -3.8877e+00 -4.0259e+00 -1.0000e+02
                 ...                   ⋱                   ...                
 -1.2884e-01 -5.9647e-01 -1.5001e+00  ...  -3.1184e+00 -3.2845e+00 -1.0000e+02
  2.7242e-01 -1.9872e-01 -1.1238e+00  ...  -2.8424e+00 -3.0178e+00 -1.0000e+02
  3.8658e-01 -8.4861e-02 -1.0153e+00  ...  -2.7643e+00 -2.9426e+00 -1.0000e+02
...

(12,.,.) = 
  2.3764e+00  1.8992e+00  1.0538e+00  ...  -1.3641e+00 -1.4521e+00 -1.0000e+02
  3.9525e-01 -2.0655e-01 -1.1667e+00  ...  -3.2394e+00 -3.3164e+00 -1.0000e+02
  3.9525e-01 -2.0655e-01 -1.1667e+00  ...  -3.2394e+00 -3.3164e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  3.9525e-01 -2.0655e-01 -1.1667e+00  ...  -3.2394e+00 -3.3164e+00 -1.0000e+02
  3.9525e-01 -2.0655e-01 -1.1667e+00  ...  -3.2394e+00 -3.3164e+00 -1.0000e+02
  3.9525e-01 -2.0655e-01 -1.1667e+00  ...  -3.2394e+00 -3.3164e+00 -1.0000e+02

(13,.,.) = 
  2.1677e+00  1.8067e+00  9.4682e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5732e-01 -8.7703e-02 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5732e-01 -8.7703e-02 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.5732e-01 -8.7703e-02 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5732e-01 -8.7703e-02 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.5732e-01 -8.7703e-02 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.0453e+00  1.6449e+00  8.2400e-01  ...  -1.6523e+00 -1.0000e+02 -1.0000e+02
  3.5951e-01 -1.1664e-01 -1.0148e+00  ...  -3.1728e+00 -1.0000e+02 -1.0000e+02
  3.5951e-01 -1.1664e-01 -1.0148e+00  ...  -3.1728e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.5951e-01 -1.1664e-01 -1.0148e+00  ...  -3.1728e+00 -1.0000e+02 -1.0000e+02
  3.5951e-01 -1.1664e-01 -1.0148e+00  ...  -3.1728e+00 -1.0000e+02 -1.0000e+02
  3.5951e-01 -1.1664e-01 -1.0148e+00  ...  -3.1728e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 1], [7, 0, 8, 0, 55, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.3165e+00  1.9679e+00  1.0969e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.2521e-01  8.4207e-02 -9.1707e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.2521e-01  8.4207e-02 -9.1707e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.2521e-01  8.4207e-02 -9.1707e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.2521e-01  8.4207e-02 -9.1707e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.2521e-01  8.4207e-02 -9.1707e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  2.1606e+00  1.7195e+00  7.4831e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.8768e-01 -3.7971e-02 -1.0940e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.8768e-01 -3.7971e-02 -1.0940e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.8768e-01 -3.7971e-02 -1.0940e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.8768e-01 -3.7971e-02 -1.0940e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.8768e-01 -3.7971e-02 -1.0940e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.4393e+00  1.9675e+00  1.1334e+00  ...  -1.5176e+00 -1.0000e+02 -1.0000e+02
  5.2127e-01 -7.5884e-02 -1.0295e+00  ...  -3.3223e+00 -1.0000e+02 -1.0000e+02
  5.2127e-01 -7.5884e-02 -1.0295e+00  ...  -3.3223e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.2127e-01 -7.5884e-02 -1.0295e+00  ...  -3.3223e+00 -1.0000e+02 -1.0000e+02
  5.2127e-01 -7.5884e-02 -1.0295e+00  ...  -3.3223e+00 -1.0000e+02 -1.0000e+02
  5.2127e-01 -7.5884e-02 -1.0295e+00  ...  -3.3223e+00 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  2.4616e+00  2.0757e+00  1.2268e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.4757e-01 -5.0256e-02 -1.0351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.4757e-01 -5.0256e-02 -1.0351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.4757e-01 -5.0256e-02 -1.0351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.4757e-01 -5.0256e-02 -1.0351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.4757e-01 -5.0256e-02 -1.0351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  2.7358e+00  2.4223e+00  1.6784e+00  ...  -1.1647e+00 -1.0000e+02 -1.0000e+02
  5.4738e-01  1.1954e-01 -7.9687e-01  ...  -3.3116e+00 -1.0000e+02 -1.0000e+02
  5.4738e-01  1.1954e-01 -7.9687e-01  ...  -3.3116e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.4738e-01  1.1954e-01 -7.9687e-01  ...  -3.3116e+00 -1.0000e+02 -1.0000e+02
  5.4738e-01  1.1954e-01 -7.9687e-01  ...  -3.3116e+00 -1.0000e+02 -1.0000e+02
  5.4738e-01  1.1954e-01 -7.9687e-01  ...  -3.3116e+00 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.1574e+00  1.7466e+00  8.9928e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.1228e+00 -2.5423e+00 -3.2641e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3649e+00 -1.8224e+00 -2.6295e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3578e-01 -6.2449e-02 -9.9991e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3578e-01 -6.2449e-02 -9.9991e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3578e-01 -6.2449e-02 -9.9991e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x61 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    2.4868    2.0808    1.1582  ...  -100.0000 -100.0000 -100.0000
    0.4752   -0.0423   -1.1055  ...  -100.0000 -100.0000 -100.0000
    0.4752   -0.0423   -1.1055  ...  -100.0000 -100.0000 -100.0000
    0.4752   -0.0423   -1.1055  ...  -100.0000 -100.0000 -100.0000
    0.4752   -0.0423   -1.1055  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    2.5166    2.1558    1.2367  ...  -100.0000 -100.0000 -100.0000
    0.4477   -0.0184   -1.0763  ...  -100.0000 -100.0000 -100.0000
    0.4477   -0.0184   -1.0763  ...  -100.0000 -100.0000 -100.0000
    0.4477   -0.0184   -1.0763  ...  -100.0000 -100.0000 -100.0000
    0.4477   -0.0184   -1.0763  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    2.7680    2.3842    1.5408  ...  -100.0000 -100.0000 -100.0000
    0.4262   -0.0938   -1.1099  ...  -100.0000 -100.0000 -100.0000
    0.4262   -0.0938   -1.1099  ...  -100.0000 -100.0000 -100.0000
    0.4262   -0.0938   -1.1099  ...  -100.0000 -100.0000 -100.0000
    0.4262   -0.0938   -1.1099  ...  -100.0000 -100.0000 -100.0000

(3 ,.,.) = 
    2.4528    2.0908    1.3655  ...    -0.5529   -1.2439   -1.3277
   -2.2811   -2.6574   -3.2887  ...    -4.3344   -4.6591   -4.7191
   -1.4404   -1.8566   -2.5728  ...    -3.8315   -4.2254   -4.2959
   -0.6259   -1.0681   -1.8485  ...    -3.3021   -3.7622   -3.8410
    0.0955   -0.3591   -1.1816  ...    -2.8063   -3.3245   -3.4083

(4 ,.,.) = 
    2.6686    2.3704    1.5950  ...  -100.0000 -100.0000 -100.0000
    0.4385    0.0306   -0.9161  ...  -100.0000 -100.0000 -100.0000
    0.4385    0.0306   -0.9161  ...  -100.0000 -100.0000 -100.0000
    0.4385    0.0306   -0.9161  ...  -100.0000 -100.0000 -100.0000
    0.4385    0.0306   -0.9161  ...  -100.0000 -100.0000 -100.0000

(5 ,.,.) = 
    2.1745    1.7910    0.9311  ...  -100.0000 -100.0000 -100.0000
    0.4898    0.0227   -0.9305  ...  -100.0000 -100.0000 -100.0000
    0.4898    0.0227   -0.9305  ...  -100.0000 -100.0000 -100.0000
    0.4898    0.0227   -0.9305  ...  -100.0000 -100.0000 -100.0000
    0.4898    0.0227   -0.9305  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x5x63 (GPU 0)]

 Loss = 4.65863889806
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  2.7384e+00  2.3538e+00  1.4141e+00  ...  -9.0462e-01 -1.1686e+00 -1.0000e+02
 -2.5530e+00 -2.9564e+00 -3.7306e+00  ...  -4.7985e+00 -4.9262e+00 -1.0000e+02
 -1.4956e+00 -1.9604e+00 -2.8861e+00  ...  -4.2662e+00 -4.4274e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5795e-01 -5.6103e-02 -1.1618e+00  ...  -3.1213e+00 -3.3385e+00 -1.0000e+02
  4.5795e-01 -5.6103e-02 -1.1618e+00  ...  -3.1213e+00 -3.3385e+00 -1.0000e+02
  4.5795e-01 -5.6103e-02 -1.1618e+00  ...  -3.1213e+00 -3.3385e+00 -1.0000e+02

( 1 ,.,.) = 
  2.7585e+00  2.3757e+00  1.4397e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5554e+00 -2.9584e+00 -3.7320e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5159e+00 -1.9795e+00 -2.9022e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5820e-01 -5.5541e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5820e-01 -5.5541e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5820e-01 -5.5541e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.9078e+00  2.5386e+00  1.6301e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6194e+00 -3.0182e+00 -3.7817e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5975e+00 -2.0574e+00 -2.9701e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5792e-01 -5.6175e-02 -1.1620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5792e-01 -5.6175e-02 -1.1620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5792e-01 -5.6175e-02 -1.1620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.0002e+00  2.6397e+00  1.7491e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6344e+00 -3.0322e+00 -3.7934e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6586e+00 -2.1154e+00 -3.0200e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5803e-01 -5.5937e-02 -1.1615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5803e-01 -5.5937e-02 -1.1615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5803e-01 -5.5937e-02 -1.1615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.0023e+00  2.6426e+00  1.7537e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6565e+00 -3.0523e+00 -3.8095e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6553e+00 -2.1120e+00 -3.0167e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5821e-01 -5.5513e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5821e-01 -5.5513e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5821e-01 -5.5513e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  2.8359e+00  2.4608e+00  1.5405e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6118e+00 -3.0107e+00 -3.7750e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5553e+00 -2.0169e+00 -2.9346e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5818e-01 -5.5577e-02 -1.1609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5818e-01 -5.5577e-02 -1.1609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5818e-01 -5.5577e-02 -1.1609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.8594e+00  2.4860e+00  1.5688e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6095e+00 -3.0088e+00 -3.7738e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5656e+00 -2.0270e+00 -2.9437e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5802e-01 -5.5955e-02 -1.1616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5802e-01 -5.5955e-02 -1.1616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5802e-01 -5.5955e-02 -1.1616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.7049e+00  2.3178e+00  1.3734e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5525e+00 -2.9556e+00 -3.7295e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4891e+00 -1.9539e+00 -2.8799e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5820e-01 -5.5528e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5820e-01 -5.5528e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5820e-01 -5.5528e-02 -1.1608e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.7800e+00  2.3993e+00  1.4675e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5762e+00 -2.9778e+00 -3.7482e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5220e+00 -1.9855e+00 -2.9076e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5804e-01 -5.5900e-02 -1.1615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5804e-01 -5.5900e-02 -1.1615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5804e-01 -5.5900e-02 -1.1615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.8956e+00  2.5253e+00  1.6146e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6160e+00 -3.0149e+00 -3.7790e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5886e+00 -2.0489e+00 -2.9627e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5794e-01 -5.6137e-02 -1.1619e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5794e-01 -5.6137e-02 -1.1619e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5794e-01 -5.6137e-02 -1.1619e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.3307e+00  1.9118e+00  9.0741e-01  ...  -1.0359e+00 -1.4153e+00 -1.0000e+02
 -2.3351e+00 -2.7535e+00 -3.5626e+00  ...  -4.5213e+00 -4.7175e+00 -1.0000e+02
 -1.2936e+00 -1.7675e+00 -2.7181e+00  ...  -3.9348e+00 -4.1782e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5805e-01 -5.5882e-02 -1.1614e+00  ...  -2.8150e+00 -3.1316e+00 -1.0000e+02
  4.5805e-01 -5.5882e-02 -1.1614e+00  ...  -2.8150e+00 -3.1316e+00 -1.0000e+02
  4.5805e-01 -5.5882e-02 -1.1614e+00  ...  -2.8150e+00 -3.1316e+00 -1.0000e+02

(14 ,.,.) = 
  2.7761e+00  2.3943e+00  1.4599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5442e+00 -2.9484e+00 -3.7244e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5266e+00 -1.9900e+00 -2.9118e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5797e-01 -5.6056e-02 -1.1618e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5797e-01 -5.6056e-02 -1.1618e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5797e-01 -5.6056e-02 -1.1618e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.7320e+00  2.3472e+00  1.4069e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5486e+00 -2.9519e+00 -3.7265e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5002e+00 -1.9644e+00 -2.8890e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5829e-01 -5.5335e-02 -1.1604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5829e-01 -5.5335e-02 -1.1604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5829e-01 -5.5335e-02 -1.1604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.9120e+00  2.5432e+00  1.6356e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6209e+00 -3.0196e+00 -3.7829e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6020e+00 -2.0617e+00 -2.9738e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5792e-01 -5.6172e-02 -1.1620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5792e-01 -5.6172e-02 -1.1620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5792e-01 -5.6172e-02 -1.1620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.8115e+00  2.4336e+00  1.5072e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5838e+00 -2.9849e+00 -3.7541e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5377e+00 -2.0004e+00 -2.9207e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5799e-01 -5.6026e-02 -1.1617e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5799e-01 -5.6026e-02 -1.1617e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5799e-01 -5.6026e-02 -1.1617e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.6205e+00  2.2262e+00  1.2676e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5092e+00 -2.9152e+00 -3.6960e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4345e+00 -1.9017e+00 -2.8345e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5826e-01 -5.5401e-02 -1.1606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5826e-01 -5.5401e-02 -1.1606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5826e-01 -5.5401e-02 -1.1606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.6705e+00  2.2803e+00  1.3297e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5304e+00 -2.9350e+00 -3.7125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4650e+00 -1.9309e+00 -2.8599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5824e-01 -5.5442e-02 -1.1606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5824e-01 -5.5442e-02 -1.1606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5824e-01 -5.5442e-02 -1.1606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  2.8599e+00  2.4862e+00  1.5682e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5875e+00 -2.9886e+00 -3.7574e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5677e+00 -2.0291e+00 -2.9456e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5802e-01 -5.5951e-02 -1.1616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5802e-01 -5.5951e-02 -1.1616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5802e-01 -5.5951e-02 -1.1616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.7879e+00  2.4078e+00  1.4770e+00  ...  -6.8705e-01 -9.4658e-01 -1.1706e+00
 -2.5769e+00 -2.9785e+00 -3.7489e+00  ...  -4.7562e+00 -4.8545e+00 -4.9630e+00
 -1.5212e+00 -1.9848e+00 -2.9072e+00  ...  -4.2106e+00 -4.3382e+00 -4.4751e+00
                 ...                   ⋱                   ...                
  4.5793e-01 -5.6149e-02 -1.1619e+00  ...  -3.0169e+00 -3.2052e+00 -3.3899e+00
  4.5793e-01 -5.6149e-02 -1.1619e+00  ...  -3.0169e+00 -3.2052e+00 -3.3899e+00
  4.5793e-01 -5.6149e-02 -1.1619e+00  ...  -3.0169e+00 -3.2052e+00 -3.3899e+00

( 1 ,.,.) = 
  2.7708e+00  2.3893e+00  1.4559e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5730e+00 -2.9747e+00 -3.7455e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5194e+00 -1.9828e+00 -2.9052e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5807e-01 -5.5828e-02 -1.1613e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5807e-01 -5.5828e-02 -1.1613e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5807e-01 -5.5828e-02 -1.1613e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.7543e+00  2.3716e+00  1.4358e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5718e+00 -2.9735e+00 -3.7443e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5024e+00 -1.9666e+00 -2.8910e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5815e-01 -5.5647e-02 -1.1610e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5815e-01 -5.5647e-02 -1.1610e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5815e-01 -5.5647e-02 -1.1610e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  2.8458e+00  2.4707e+00  1.5500e+00  ...  -1.6996e+00 -1.9227e+00 -1.1989e+00
 -2.5884e+00 -2.9895e+00 -3.7582e+00  ...  -5.1834e+00 -5.2512e+00 -5.0097e+00
 -1.5663e+00 -2.0278e+00 -2.9447e+00  ...  -4.7818e+00 -4.8715e+00 -4.5514e+00
                 ...                   ⋱                   ...                
  4.5789e-01 -5.6240e-02 -1.1621e+00  ...  -3.8181e+00 -3.9586e+00 -3.4694e+00
  4.5789e-01 -5.6240e-02 -1.1621e+00  ...  -3.8181e+00 -3.9586e+00 -3.4694e+00
  4.5789e-01 -5.6240e-02 -1.1621e+00  ...  -3.8181e+00 -3.9586e+00 -3.4694e+00

( 4 ,.,.) = 
  2.4980e+00  2.0924e+00  1.1120e+00  ...  -1.2391e+00 -1.0000e+02 -1.0000e+02
 -2.4251e+00 -2.8374e+00 -3.6322e+00  ...  -4.7701e+00 -1.0000e+02 -1.0000e+02
 -1.3810e+00 -1.8511e+00 -2.7909e+00  ...  -4.2394e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5804e-01 -5.5907e-02 -1.1615e+00  ...  -3.1535e+00 -1.0000e+02 -1.0000e+02
  4.5804e-01 -5.5907e-02 -1.1615e+00  ...  -3.1535e+00 -1.0000e+02 -1.0000e+02
  4.5804e-01 -5.5907e-02 -1.1615e+00  ...  -3.1535e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  2.3949e+00  1.9811e+00  9.8579e-01  ...  -1.3532e+00 -1.0000e+02 -1.0000e+02
 -2.3720e+00 -2.7878e+00 -3.5910e+00  ...  -4.7411e+00 -1.0000e+02 -1.0000e+02
 -1.3248e+00 -1.7972e+00 -2.7439e+00  ...  -4.2033e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5813e-01 -5.5698e-02 -1.1611e+00  ...  -3.1435e+00 -1.0000e+02 -1.0000e+02
  4.5813e-01 -5.5698e-02 -1.1611e+00  ...  -3.1435e+00 -1.0000e+02 -1.0000e+02
  4.5813e-01 -5.5698e-02 -1.1611e+00  ...  -3.1435e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  2.8846e+00  2.4652e+00  1.4609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6638e+00 -3.1064e+00 -3.9121e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6367e+00 -2.1499e+00 -3.1213e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0128e-01 -1.7668e-01 -1.3702e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0128e-01 -1.7668e-01 -1.3702e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0128e-01 -1.7668e-01 -1.3702e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.8192e+00  2.3922e+00  1.3725e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5968e+00 -3.0451e+00 -3.8631e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6080e+00 -2.1229e+00 -3.0985e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0145e-01 -1.7630e-01 -1.3695e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0145e-01 -1.7630e-01 -1.3695e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0145e-01 -1.7630e-01 -1.3695e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.9405e+00  2.5262e+00  1.5319e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6777e+00 -3.1199e+00 -3.9239e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6688e+00 -2.1810e+00 -3.1485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0055e-01 -1.7829e-01 -1.3730e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0055e-01 -1.7829e-01 -1.3730e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0055e-01 -1.7829e-01 -1.3730e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.8186e+00  2.3925e+00  1.3751e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6431e+00 -3.0873e+00 -3.8966e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6016e+00 -2.1168e+00 -3.0931e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0134e-01 -1.7655e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0134e-01 -1.7655e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0134e-01 -1.7655e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.9506e+00  2.5380e+00  1.5471e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6907e+00 -3.1315e+00 -3.9327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6732e+00 -2.1848e+00 -3.1513e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0086e-01 -1.7761e-01 -1.3718e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0086e-01 -1.7761e-01 -1.3718e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0086e-01 -1.7761e-01 -1.3718e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  2.8846e+00  2.4652e+00  1.4609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6638e+00 -3.1064e+00 -3.9121e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6367e+00 -2.1499e+00 -3.1213e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0128e-01 -1.7668e-01 -1.3702e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0128e-01 -1.7668e-01 -1.3702e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0128e-01 -1.7668e-01 -1.3702e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  2.8725e+00  2.4521e+00  1.4459e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6586e+00 -3.1014e+00 -3.9077e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6297e+00 -2.1430e+00 -3.1150e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0161e-01 -1.7598e-01 -1.3690e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0161e-01 -1.7598e-01 -1.3690e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0161e-01 -1.7598e-01 -1.3690e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.8725e+00  2.4521e+00  1.4459e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6586e+00 -3.1014e+00 -3.9077e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6297e+00 -2.1430e+00 -3.1150e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0161e-01 -1.7598e-01 -1.3690e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0161e-01 -1.7598e-01 -1.3690e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0161e-01 -1.7598e-01 -1.3690e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.8609e+00  2.4384e+00  1.4281e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6544e+00 -3.0984e+00 -3.9063e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6213e+00 -2.1361e+00 -3.1104e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0066e-01 -1.7807e-01 -1.3726e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0066e-01 -1.7807e-01 -1.3726e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0066e-01 -1.7807e-01 -1.3726e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  2.7746e+00  2.3428e+00  1.3145e+00  ...  -1.0002e+00 -8.8789e-01 -1.1204e+00
 -2.6150e+00 -3.0626e+00 -3.8781e+00  ...  -4.9016e+00 -4.8426e+00 -4.9544e+00
 -1.5771e+00 -2.0949e+00 -3.0761e+00  ...  -4.4051e+00 -4.3293e+00 -4.4698e+00
                 ...                   ⋱                   ...                
  4.0027e-01 -1.7889e-01 -1.3740e+00  ...  -3.2906e+00 -3.1900e+00 -3.3803e+00
  4.0027e-01 -1.7889e-01 -1.3740e+00  ...  -3.2906e+00 -3.1900e+00 -3.3803e+00
  4.0027e-01 -1.7889e-01 -1.3740e+00  ...  -3.2906e+00 -3.1900e+00 -3.3803e+00

( 4 ,.,.) = 
  2.7535e+00  2.3205e+00  1.2901e+00  ...  -9.1446e-01 -1.1617e+00 -1.0000e+02
 -2.6232e+00 -3.0694e+00 -3.8826e+00  ...  -4.8443e+00 -4.9627e+00 -1.0000e+02
 -1.5634e+00 -2.0812e+00 -3.0635e+00  ...  -4.3196e+00 -4.4697e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0083e-01 -1.7767e-01 -1.3719e+00  ...  -3.1876e+00 -3.3904e+00 -1.0000e+02
  4.0083e-01 -1.7767e-01 -1.3719e+00  ...  -3.1876e+00 -3.3904e+00 -1.0000e+02
  4.0083e-01 -1.7767e-01 -1.3719e+00  ...  -3.1876e+00 -3.3904e+00 -1.0000e+02

( 5 ,.,.) = 
  2.8455e+00  2.4221e+00  1.4103e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6615e+00 -3.1044e+00 -3.9106e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.6119e+00 -2.1268e+00 -3.1020e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.0102e-01 -1.7728e-01 -1.3713e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0102e-01 -1.7728e-01 -1.3713e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.0102e-01 -1.7728e-01 -1.3713e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 14 @ 2018-04-12 20:36:21.359375
training
gt_where_seq [[7, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 8, 0, 55, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 0, 22, 0, 54, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.8512e+00  2.4544e+00  1.5430e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4077e-01 -1.7385e-03 -1.0866e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4077e-01 -1.7385e-03 -1.0866e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.4077e-01 -1.7385e-03 -1.0866e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4077e-01 -1.7385e-03 -1.0866e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.4077e-01 -1.7385e-03 -1.0866e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  2.7072e+00  2.4152e+00  1.5917e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.1138e-01  1.1695e-01 -8.7765e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.1138e-01  1.1695e-01 -8.7765e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.1138e-01  1.1695e-01 -8.7765e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.1138e-01  1.1695e-01 -8.7765e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.1138e-01  1.1695e-01 -8.7765e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.4456e+00  2.0059e+00  1.0751e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.4814e+00 -2.9203e+00 -3.6635e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3518e+00 -1.8584e+00 -2.7510e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.4461e-01  9.3185e-02 -9.5947e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9072e-01 -6.1673e-02 -1.1084e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9072e-01 -6.1673e-02 -1.1084e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  2.7049e+00  2.2762e+00  1.3789e+00  ...  -1.3021e+00 -1.0000e+02 -1.0000e+02
  5.0189e-01 -6.8680e-02 -1.1178e+00  ...  -3.3834e+00 -1.0000e+02 -1.0000e+02
  5.0189e-01 -6.8680e-02 -1.1178e+00  ...  -3.3834e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.0189e-01 -6.8680e-02 -1.1178e+00  ...  -3.3834e+00 -1.0000e+02 -1.0000e+02
  5.0189e-01 -6.8680e-02 -1.1178e+00  ...  -3.3834e+00 -1.0000e+02 -1.0000e+02
  5.0189e-01 -6.8680e-02 -1.1178e+00  ...  -3.3834e+00 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  2.2764e+00  1.9476e+00  1.1026e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.2089e+00 -2.5439e+00 -3.2684e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1788e+00 -1.5539e+00 -2.3897e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.5811e-01  3.5938e-01 -5.9023e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1873e-01  3.1957e-01 -6.3042e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3443e-01  1.3377e-01 -8.1314e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.4034e+00  1.9661e+00  9.1438e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.6278e+00 -3.0471e+00 -3.8377e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4832e+00 -1.9751e+00 -2.9425e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3620e-01  9.2721e-02 -1.0794e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3520e-01 -9.1224e-03 -1.1764e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3520e-01 -9.1224e-03 -1.1764e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.8634e+00  2.5305e+00  1.5640e+00  ...  -1.0549e+00 -1.0000e+02 -1.0000e+02
  5.6314e-01  1.0874e-01 -1.0540e+00  ...  -3.3002e+00 -1.0000e+02 -1.0000e+02
  5.6314e-01  1.0874e-01 -1.0540e+00  ...  -3.3002e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.6314e-01  1.0874e-01 -1.0540e+00  ...  -3.3002e+00 -1.0000e+02 -1.0000e+02
  5.6314e-01  1.0874e-01 -1.0540e+00  ...  -3.3002e+00 -1.0000e+02 -1.0000e+02
  5.6314e-01  1.0874e-01 -1.0540e+00  ...  -3.3002e+00 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  2.8883e+00  2.5153e+00  1.5113e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.5872e+00 -2.9816e+00 -3.7997e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3146e+00 -1.7797e+00 -2.7920e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3253e-01  2.8522e-02 -1.1578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3253e-01  2.8522e-02 -1.1578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3253e-01  2.8522e-02 -1.1578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  3.0351e+00  2.7658e+00  1.8611e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0421e-01  2.1687e-01 -9.2229e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0421e-01  2.1687e-01 -9.2229e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.0421e-01  2.1687e-01 -9.2229e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0421e-01  2.1687e-01 -9.2229e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.0421e-01  2.1687e-01 -9.2229e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.0440e+00  2.7258e+00  1.7902e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7325e-01  1.1828e-01 -1.0481e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7325e-01  1.1828e-01 -1.0481e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.7325e-01  1.1828e-01 -1.0481e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7325e-01  1.1828e-01 -1.0481e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.7325e-01  1.1828e-01 -1.0481e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.0653e+00  2.6630e+00  1.8615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.7045e+00 -3.1371e+00 -3.8063e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4443e+00 -1.9617e+00 -2.7955e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1550e-01  1.4548e-01 -8.5478e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5625e-01 -1.5173e-02 -1.0104e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.5625e-01 -1.5173e-02 -1.0104e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.9562e+00  2.5507e+00  1.3970e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9128e-01 -6.9684e-02 -1.4211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9128e-01 -6.9684e-02 -1.4211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.9128e-01 -6.9684e-02 -1.4211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9128e-01 -6.9684e-02 -1.4211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9128e-01 -6.9684e-02 -1.4211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 1], [7, 0, 22, 0, 55, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.2702e+00  2.8273e+00  1.8071e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9565e-01 -1.6025e-01 -1.4327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9565e-01 -1.6025e-01 -1.4327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.9565e-01 -1.6025e-01 -1.4327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9565e-01 -1.6025e-01 -1.4327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.9565e-01 -1.6025e-01 -1.4327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  2.7825e+00  2.3647e+00  1.1729e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3408e-01 -1.1787e-01 -1.4645e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3408e-01 -1.1787e-01 -1.4645e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.3408e-01 -1.1787e-01 -1.4645e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3408e-01 -1.1787e-01 -1.4645e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3408e-01 -1.1787e-01 -1.4645e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.5099e+00  1.9818e+00  1.0646e+00  ...  -3.9626e-01 -1.0364e+00 -1.4390e+00
 -3.0142e+00 -3.4824e+00 -4.1144e+00  ...  -4.6914e+00 -4.9328e+00 -5.1123e+00
 -1.4636e+00 -2.0594e+00 -2.9085e+00  ...  -3.7766e+00 -4.1318e+00 -4.3893e+00
                 ...                   ⋱                   ...                
  2.8723e-01 -3.7155e-01 -1.3776e+00  ...  -2.5716e+00 -3.0557e+00 -3.3897e+00
  6.4739e-01 -1.1957e-02 -1.0363e+00  ...  -2.3000e+00 -2.8119e+00 -3.1600e+00
  7.0100e-01  4.1879e-02 -9.8558e-01  ...  -2.2631e+00 -2.7802e+00 -3.1307e+00
...

(12,.,.) = 
  3.3209e+00  2.9008e+00  1.8277e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3746e-01 -1.0113e-01 -1.4515e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3746e-01 -1.0113e-01 -1.4515e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3746e-01 -1.0113e-01 -1.4515e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3746e-01 -1.0113e-01 -1.4515e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3746e-01 -1.0113e-01 -1.4515e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.4748e+00  3.0871e+00  2.1185e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2860e-01  2.0353e-02 -1.2579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2860e-01  2.0353e-02 -1.2579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2860e-01  2.0353e-02 -1.2579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2860e-01  2.0353e-02 -1.2579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2860e-01  2.0353e-02 -1.2579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.8648e+00  2.3571e+00  1.1852e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.0455e+00 -3.5233e+00 -4.3197e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5343e+00 -2.1419e+00 -3.2214e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3873e-01 -5.3607e-01 -1.8358e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3166e-01 -2.4644e-01 -1.5746e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.3166e-01 -2.4644e-01 -1.5746e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    3.3498    2.9882    2.0125  ...  -100.0000 -100.0000 -100.0000
    0.6358    0.0960   -1.1533  ...  -100.0000 -100.0000 -100.0000
    0.6358    0.0960   -1.1533  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.6358    0.0960   -1.1533  ...  -100.0000 -100.0000 -100.0000
    0.6358    0.0960   -1.1533  ...  -100.0000 -100.0000 -100.0000
    0.6358    0.0960   -1.1533  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    3.0655    2.7028    1.7098  ...    -1.6849   -1.1930   -1.2467
    0.4446   -0.0684   -1.2775  ...    -3.9553   -3.6148   -3.6729
    0.4446   -0.0684   -1.2775  ...    -3.9553   -3.6148   -3.6729
              ...                ⋱                ...             
    0.4446   -0.0684   -1.2775  ...    -3.9553   -3.6148   -3.6729
    0.4446   -0.0684   -1.2775  ...    -3.9553   -3.6148   -3.6729
    0.4446   -0.0684   -1.2775  ...    -3.9553   -3.6148   -3.6729

(2 ,.,.) = 
    2.9217    2.3881    1.3239  ...  -100.0000 -100.0000 -100.0000
    0.3757   -0.3346   -1.5387  ...  -100.0000 -100.0000 -100.0000
    0.3757   -0.3346   -1.5387  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.3757   -0.3346   -1.5387  ...  -100.0000 -100.0000 -100.0000
    0.3757   -0.3346   -1.5387  ...  -100.0000 -100.0000 -100.0000
    0.3757   -0.3346   -1.5387  ...  -100.0000 -100.0000 -100.0000

(3 ,.,.) = 
    3.3542    2.9103    1.8275  ...  -100.0000 -100.0000 -100.0000
    0.5602   -0.1017   -1.4430  ...  -100.0000 -100.0000 -100.0000
    0.5602   -0.1017   -1.4430  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5602   -0.1017   -1.4430  ...  -100.0000 -100.0000 -100.0000
    0.5602   -0.1017   -1.4430  ...  -100.0000 -100.0000 -100.0000
    0.5602   -0.1017   -1.4430  ...  -100.0000 -100.0000 -100.0000

(4 ,.,.) = 
    2.7188    2.1696    0.8318  ...    -0.4043   -0.5569   -1.0508
   -3.1266   -3.6118   -4.4508  ...    -4.8702   -4.9243   -5.1160
   -1.3647   -2.0043   -3.1982  ...    -3.8775   -3.9599   -4.2538
              ...                ⋱                ...             
    0.6320   -0.0701   -1.5256  ...    -2.5229   -2.6390   -3.0413
    0.6653   -0.0371   -1.4981  ...    -2.5061   -2.6234   -3.0281
    0.4171   -0.2867   -1.7288  ...    -2.6998   -2.8131   -3.2051

(5 ,.,.) = 
    3.2303    2.7555    1.6679  ...  -100.0000 -100.0000 -100.0000
    0.5242   -0.1555   -1.4605  ...  -100.0000 -100.0000 -100.0000
    0.5242   -0.1555   -1.4605  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5242   -0.1555   -1.4605  ...  -100.0000 -100.0000 -100.0000
    0.5242   -0.1555   -1.4605  ...  -100.0000 -100.0000 -100.0000
    0.5242   -0.1555   -1.4605  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x8x62 (GPU 0)]

 Loss = 4.58463522967
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  3.3842e+00  2.9480e+00  1.7916e+00  ...  -4.4714e-01 -7.1506e-01 -1.0000e+02
 -3.5043e+00 -3.9149e+00 -4.6623e+00  ...  -5.3441e+00 -5.4377e+00 -1.0000e+02
 -1.3972e+00 -1.9883e+00 -3.1598e+00  ...  -4.3929e+00 -4.5528e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3199e-01 -1.1775e-01 -1.5330e+00  ...  -3.3089e+00 -3.5225e+00 -1.0000e+02
  5.3199e-01 -1.1775e-01 -1.5330e+00  ...  -3.3089e+00 -3.5225e+00 -1.0000e+02
  5.3199e-01 -1.1775e-01 -1.5330e+00  ...  -3.3089e+00 -3.5225e+00 -1.0000e+02

( 1 ,.,.) = 
  3.3955e+00  2.9610e+00  1.8082e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5091e+00 -3.9188e+00 -4.6647e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4150e+00 -2.0045e+00 -3.1725e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3242e-01 -1.1668e-01 -1.5311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3242e-01 -1.1668e-01 -1.5311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3242e-01 -1.1668e-01 -1.5311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.5643e+00  3.1508e+00  2.0433e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5763e+00 -3.9789e+00 -4.7096e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4980e+00 -2.0835e+00 -3.2386e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3196e-01 -1.1782e-01 -1.5331e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3196e-01 -1.1782e-01 -1.5331e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3196e-01 -1.1782e-01 -1.5331e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.6568e+00  3.2554e+00  2.1745e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5906e+00 -3.9917e+00 -4.7191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5692e+00 -2.1502e+00 -3.2934e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3214e-01 -1.1737e-01 -1.5323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3214e-01 -1.1737e-01 -1.5323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3214e-01 -1.1737e-01 -1.5323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.6550e+00  3.2540e+00  2.1742e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6099e+00 -4.0084e+00 -4.7309e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5565e+00 -2.1378e+00 -3.2827e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3244e-01 -1.1664e-01 -1.5310e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3244e-01 -1.1664e-01 -1.5310e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3244e-01 -1.1664e-01 -1.5310e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  3.4936e+00  3.0720e+00  1.9469e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5646e+00 -3.9680e+00 -4.7010e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4530e+00 -2.0404e+00 -3.2023e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3238e-01 -1.1678e-01 -1.5313e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3238e-01 -1.1678e-01 -1.5313e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3238e-01 -1.1678e-01 -1.5313e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.4976e+00  3.0759e+00  1.9504e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5607e+00 -3.9649e+00 -4.6990e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4562e+00 -2.0439e+00 -3.2056e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3211e-01 -1.1746e-01 -1.5325e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3211e-01 -1.1746e-01 -1.5325e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3211e-01 -1.1746e-01 -1.5325e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.3402e+00  2.8994e+00  1.7334e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4992e+00 -3.9100e+00 -4.6582e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3885e+00 -1.9794e+00 -3.1516e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3243e-01 -1.1667e-01 -1.5311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3243e-01 -1.1667e-01 -1.5311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3243e-01 -1.1667e-01 -1.5311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.4227e+00  2.9916e+00  1.8460e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5266e+00 -3.9345e+00 -4.6766e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4184e+00 -2.0081e+00 -3.1760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3216e-01 -1.1735e-01 -1.5323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3216e-01 -1.1735e-01 -1.5323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3215e-01 -1.1735e-01 -1.5323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.5514e+00  3.1363e+00  2.0252e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5727e+00 -3.9757e+00 -4.7071e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4884e+00 -2.0743e+00 -3.2310e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3199e-01 -1.1776e-01 -1.5330e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3199e-01 -1.1776e-01 -1.5330e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3199e-01 -1.1776e-01 -1.5330e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.9324e+00  2.4437e+00  1.1820e+00  ...  -5.9919e-01 -1.0203e+00 -1.0000e+02
 -3.2498e+00 -3.6884e+00 -4.4945e+00  ...  -5.0847e+00 -5.2458e+00 -1.0000e+02
 -1.2297e+00 -1.8297e+00 -3.0275e+00  ...  -4.0397e+00 -4.2998e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3217e-01 -1.1732e-01 -1.5322e+00  ...  -2.9449e+00 -3.2827e+00 -1.0000e+02
  5.3217e-01 -1.1732e-01 -1.5322e+00  ...  -2.9449e+00 -3.2827e+00 -1.0000e+02
  5.3217e-01 -1.1732e-01 -1.5322e+00  ...  -2.9449e+00 -3.2827e+00 -1.0000e+02

(14 ,.,.) = 
  3.3962e+00  2.9610e+00  1.8062e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4918e+00 -3.9039e+00 -4.6543e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4227e+00 -2.0124e+00 -3.1798e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3205e-01 -1.1759e-01 -1.5327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3205e-01 -1.1759e-01 -1.5327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3205e-01 -1.1759e-01 -1.5327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
    3.3751    2.9385    1.7810  ...  -100.0000 -100.0000 -100.0000
   -3.5031   -3.9133   -4.6605  ...  -100.0000 -100.0000 -100.0000
   -1.4017   -1.9918   -3.1617  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5326   -0.1163   -1.5304  ...  -100.0000 -100.0000 -100.0000
    0.5326   -0.1163   -1.5304  ...  -100.0000 -100.0000 -100.0000
    0.5326   -0.1163   -1.5304  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    3.5691    3.1562    2.0501  ...  -100.0000 -100.0000 -100.0000
   -3.5780   -3.9804   -4.7107  ...  -100.0000 -100.0000 -100.0000
   -1.5035   -2.0886   -3.2429  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5320   -0.1178   -1.5331  ...  -100.0000 -100.0000 -100.0000
    0.5320   -0.1178   -1.5331  ...  -100.0000 -100.0000 -100.0000
    0.5320   -0.1178   -1.5331  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    3.4696    3.0442    1.9108  ...  -100.0000 -100.0000 -100.0000
   -3.5409   -3.9473   -4.6861  ...  -100.0000 -100.0000 -100.0000
   -1.4389   -2.0275   -3.1921  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5321   -0.1176   -1.5326  ...  -100.0000 -100.0000 -100.0000
    0.5321   -0.1176   -1.5326  ...  -100.0000 -100.0000 -100.0000
    0.5321   -0.1176   -1.5326  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    3.2396    2.7869    1.5963  ...  -100.0000 -100.0000 -100.0000
   -3.4413   -3.8583   -4.6199  ...  -100.0000 -100.0000 -100.0000
   -1.3343   -1.9281   -3.1088  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5325   -0.1164   -1.5306  ...  -100.0000 -100.0000 -100.0000
    0.5325   -0.1164   -1.5306  ...  -100.0000 -100.0000 -100.0000
    0.5325   -0.1164   -1.5306  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    3.3057    2.8606    1.6856  ...  -100.0000 -100.0000 -100.0000
   -3.4756   -3.8890   -4.6426  ...  -100.0000 -100.0000 -100.0000
   -1.3680   -1.9600   -3.1354  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5325   -0.1165   -1.5308  ...  -100.0000 -100.0000 -100.0000
    0.5325   -0.1165   -1.5308  ...  -100.0000 -100.0000 -100.0000
    0.5325   -0.1165   -1.5308  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    3.4902    3.0672    1.9387  ...  -100.0000 -100.0000 -100.0000
   -3.5373   -3.9443   -4.6841  ...  -100.0000 -100.0000 -100.0000
   -1.4610   -2.0485   -3.2097  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.5321   -0.1174   -1.5324  ...  -100.0000 -100.0000 -100.0000
    0.5321   -0.1174   -1.5324  ...  -100.0000 -100.0000 -100.0000
    0.5321   -0.1174   -1.5324  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.4396e+00  3.0103e+00  1.8685e+00  ...  -1.6519e-01 -5.0439e-01 -7.1955e-01
 -3.5294e+00 -3.9372e+00 -4.6787e+00  ...  -5.3080e+00 -5.3937e+00 -5.4697e+00
 -1.4204e+00 -2.0102e+00 -3.1779e+00  ...  -4.3210e+00 -4.4763e+00 -4.6062e+00
                 ...                   ⋱                   ...                
  5.3197e-01 -1.1781e-01 -1.5331e+00  ...  -3.1828e+00 -3.4108e+00 -3.5841e+00
  5.3197e-01 -1.1781e-01 -1.5331e+00  ...  -3.1828e+00 -3.4108e+00 -3.5841e+00
  5.3197e-01 -1.1781e-01 -1.5331e+00  ...  -3.1828e+00 -3.4108e+00 -3.5841e+00

( 1 ,.,.) = 
  3.4221e+00  2.9909e+00  1.8453e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5261e+00 -3.9341e+00 -4.6761e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4202e+00 -2.0097e+00 -3.1771e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3222e-01 -1.1720e-01 -1.5320e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3222e-01 -1.1720e-01 -1.5320e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3222e-01 -1.1720e-01 -1.5320e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.4054e+00  2.9726e+00  1.8233e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5214e+00 -3.9296e+00 -4.6726e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4009e+00 -1.9913e+00 -3.1615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3235e-01 -1.1687e-01 -1.5315e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3235e-01 -1.1687e-01 -1.5315e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.3235e-01 -1.1687e-01 -1.5315e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  3.4840e+00  3.0600e+00  1.9295e+00  ...  -1.3889e+00 -1.6155e+00 -7.5385e-01
 -3.5391e+00 -3.9460e+00 -4.6855e+00  ...  -5.6421e+00 -5.6843e+00 -5.5001e+00
 -1.4633e+00 -2.0509e+00 -3.2119e+00  ...  -4.9443e+00 -5.0239e+00 -4.6756e+00
                 ...                   ⋱                   ...                
  5.3190e-01 -1.1798e-01 -1.5334e+00  ...  -4.0594e+00 -4.1840e+00 -3.6553e+00
  5.3190e-01 -1.1798e-01 -1.5334e+00  ...  -4.0594e+00 -4.1840e+00 -3.6553e+00
  5.3190e-01 -1.1798e-01 -1.5334e+00  ...  -4.0594e+00 -4.1840e+00 -3.6553e+00

( 4 ,.,.) = 
  3.1176e+00  2.6493e+00  1.4271e+00  ...  -8.0534e-01 -1.0000e+02 -1.0000e+02
 -3.3623e+00 -3.7886e+00 -4.5688e+00  ...  -5.3006e+00 -1.0000e+02 -1.0000e+02
 -1.3012e+00 -1.8973e+00 -3.0839e+00  ...  -4.3553e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3216e-01 -1.1734e-01 -1.5323e+00  ...  -3.3097e+00 -1.0000e+02 -1.0000e+02
  5.3216e-01 -1.1734e-01 -1.5323e+00  ...  -3.3097e+00 -1.0000e+02 -1.0000e+02
  5.3216e-01 -1.1734e-01 -1.5323e+00  ...  -3.3097e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  2.9983e+00  2.5169e+00  1.2691e+00  ...  -9.4595e-01 -1.0000e+02 -1.0000e+02
 -3.2908e+00 -3.7247e+00 -4.5213e+00  ...  -5.2663e+00 -1.0000e+02 -1.0000e+02
 -1.2520e+00 -1.8506e+00 -3.0447e+00  ...  -4.3185e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.3230e-01 -1.1698e-01 -1.5316e+00  ...  -3.2927e+00 -1.0000e+02 -1.0000e+02
  5.3230e-01 -1.1698e-01 -1.5316e+00  ...  -3.2927e+00 -1.0000e+02 -1.0000e+02
  5.3230e-01 -1.1698e-01 -1.5316e+00  ...  -3.2927e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  3.5360e+00  3.0589e+00  1.8280e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6207e+00 -4.0678e+00 -4.8231e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5461e+00 -2.2036e+00 -3.4190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6080e-01 -2.7571e-01 -1.7893e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6080e-01 -2.7571e-01 -1.7893e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6080e-01 -2.7571e-01 -1.7893e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.4419e+00  2.9505e+00  1.6898e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5509e+00 -4.0071e+00 -4.7799e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5154e+00 -2.1748e+00 -3.3959e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6110e-01 -2.7501e-01 -1.7882e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6110e-01 -2.7501e-01 -1.7882e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6110e-01 -2.7501e-01 -1.7882e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.5932e+00  3.1232e+00  1.9071e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6337e+00 -4.0802e+00 -4.8329e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5820e+00 -2.2384e+00 -3.4484e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5960e-01 -2.7849e-01 -1.7937e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5960e-01 -2.7849e-01 -1.7937e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5960e-01 -2.7849e-01 -1.7937e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.4670e+00  2.9801e+00  1.7292e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5977e+00 -4.0477e+00 -4.8086e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5111e+00 -2.1709e+00 -3.3926e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6089e-01 -2.7550e-01 -1.7889e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6089e-01 -2.7550e-01 -1.7889e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6089e-01 -2.7550e-01 -1.7889e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.6023e+00  3.1344e+00  1.9228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6431e+00 -4.0879e+00 -4.8379e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5819e+00 -2.2376e+00 -3.4472e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6013e-01 -2.7726e-01 -1.7917e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6013e-01 -2.7726e-01 -1.7917e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6013e-01 -2.7726e-01 -1.7917e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  3.5360e+00  3.0589e+00  1.8280e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6207e+00 -4.0678e+00 -4.8231e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5461e+00 -2.2036e+00 -3.4190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6080e-01 -2.7571e-01 -1.7893e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6080e-01 -2.7571e-01 -1.7893e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6080e-01 -2.7571e-01 -1.7893e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.5193e+00  3.0403e+00  1.8055e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6136e+00 -4.0613e+00 -4.8180e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5368e+00 -2.1943e+00 -3.4109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6139e-01 -2.7436e-01 -1.7871e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6139e-01 -2.7436e-01 -1.7871e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6139e-01 -2.7436e-01 -1.7871e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.5193e+00  3.0403e+00  1.8055e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6136e+00 -4.0613e+00 -4.8180e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5368e+00 -2.1943e+00 -3.4109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6139e-01 -2.7436e-01 -1.7871e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6139e-01 -2.7436e-01 -1.7871e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6139e-01 -2.7436e-01 -1.7871e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.5106e+00  3.0289e+00  1.7887e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6093e+00 -4.0586e+00 -4.8172e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5305e+00 -2.1902e+00 -3.4094e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5982e-01 -2.7797e-01 -1.7929e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5982e-01 -2.7797e-01 -1.7929e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.5982e-01 -2.7797e-01 -1.7929e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  3.4198e+00  2.9242e+00  1.6558e+00  ...  -5.0467e-01 -4.2543e-01 -6.5557e-01
 -3.5698e+00 -4.0249e+00 -4.7937e+00  ...  -5.4161e+00 -5.3804e+00 -5.4608e+00
 -1.4902e+00 -2.1536e+00 -3.3810e+00  ...  -4.5210e+00 -4.4592e+00 -4.5961e+00
                 ...                   ⋱                   ...                
  4.5904e-01 -2.7977e-01 -1.7958e+00  ...  -3.4631e+00 -3.3847e+00 -3.5682e+00
  4.5904e-01 -2.7977e-01 -1.7958e+00  ...  -3.4631e+00 -3.3847e+00 -3.5682e+00
  4.5904e-01 -2.7977e-01 -1.7958e+00  ...  -3.4631e+00 -3.3847e+00 -3.5682e+00

( 4 ,.,.) = 
  3.4083e+00  2.9124e+00  1.6437e+00  ...  -4.6220e-01 -7.0214e-01 -1.0000e+02
 -3.5764e+00 -4.0297e+00 -4.7964e+00  ...  -5.3871e+00 -5.4705e+00 -1.0000e+02
 -1.4772e+00 -2.1401e+00 -3.3688e+00  ...  -4.4603e+00 -4.6034e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  4.5998e-01 -2.7760e-01 -1.7923e+00  ...  -3.3967e+00 -3.5882e+00 -1.0000e+02
  4.5998e-01 -2.7760e-01 -1.7923e+00  ...  -3.3967e+00 -3.5882e+00 -1.0000e+02
  4.5998e-01 -2.7760e-01 -1.7923e+00  ...  -3.3967e+00 -3.5882e+00 -1.0000e+02

( 5 ,.,.) = 
  3.5014e+00  3.0192e+00  1.7781e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6147e+00 -4.0628e+00 -4.8197e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.5210e+00 -2.1806e+00 -3.4011e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.6041e-01 -2.7666e-01 -1.7909e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6041e-01 -2.7666e-01 -1.7909e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.6041e-01 -2.7666e-01 -1.7909e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 15 @ 2018-04-12 20:36:23.834617
training
gt_where_seq [[7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.6847e+00  3.3621e+00  2.3125e+00  ...  -4.8920e-01 -1.0000e+02 -1.0000e+02
  5.9025e-01  4.8411e-02 -1.3714e+00  ...  -3.6699e+00 -1.0000e+02 -1.0000e+02
  5.9025e-01  4.8411e-02 -1.3714e+00  ...  -3.6699e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.9025e-01  4.8411e-02 -1.3714e+00  ...  -3.6699e+00 -1.0000e+02 -1.0000e+02
  5.9025e-01  4.8411e-02 -1.3714e+00  ...  -3.6699e+00 -1.0000e+02 -1.0000e+02
  5.9025e-01  4.8411e-02 -1.3714e+00  ...  -3.6699e+00 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.3962e+00  3.1054e+00  2.2407e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4465e+00 -3.7348e+00 -4.3793e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1764e+00 -1.5923e+00 -2.5854e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  4.9423e-01  4.9130e-02 -1.0775e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5586e-01  2.1056e-01 -9.2522e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5586e-01  2.1056e-01 -9.2522e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.9495e+00  2.4760e+00  1.4721e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4068e+00 -3.8210e+00 -4.4652e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.3645e+00 -1.9455e+00 -2.9230e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.8235e-01 -2.5104e-01 -1.4029e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1854e-01  1.8720e-01 -9.8804e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.3455e-01  2.0300e-01 -9.7475e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.5202e+00  3.0995e+00  2.0323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5087e+00 -3.9186e+00 -4.6377e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.2987e+00 -1.8943e+00 -3.0336e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  3.9547e-01 -2.5153e-01 -1.5886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1468e-01 -3.3755e-02 -1.3903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.1468e-01 -3.3755e-02 -1.3903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.7418e+00  3.2833e+00  2.1216e+00  ...  -1.9082e-01 -1.0000e+02 -1.0000e+02
  5.1816e-01 -2.2893e-01 -1.7258e+00  ...  -3.5586e+00 -1.0000e+02 -1.0000e+02
  5.1816e-01 -2.2893e-01 -1.7258e+00  ...  -3.5586e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.1816e-01 -2.2893e-01 -1.7258e+00  ...  -3.5586e+00 -1.0000e+02 -1.0000e+02
  5.1816e-01 -2.2893e-01 -1.7258e+00  ...  -3.5586e+00 -1.0000e+02 -1.0000e+02
  5.1816e-01 -2.2893e-01 -1.7258e+00  ...  -3.5586e+00 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  3.4873e+00  3.0080e+00  1.9863e+00  ...  -7.5156e-01 -1.0000e+02 -1.0000e+02
  6.2199e-01 -1.0481e-01 -1.3875e+00  ...  -3.5975e+00 -1.0000e+02 -1.0000e+02
  6.2199e-01 -1.0481e-01 -1.3875e+00  ...  -3.5975e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2199e-01 -1.0481e-01 -1.3875e+00  ...  -3.5975e+00 -1.0000e+02 -1.0000e+02
  6.2199e-01 -1.0481e-01 -1.3875e+00  ...  -3.5975e+00 -1.0000e+02 -1.0000e+02
  6.2199e-01 -1.0481e-01 -1.3875e+00  ...  -3.5975e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x61 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 24, 0, 60, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.4164e+00  3.0610e+00  2.0760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8131e-01  4.9212e-02 -1.1952e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8131e-01  4.9212e-02 -1.1952e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.8131e-01  4.9212e-02 -1.1952e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8131e-01  4.9212e-02 -1.1952e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  5.8131e-01  4.9212e-02 -1.1952e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.8691e+00  3.5672e+00  2.6632e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5272e+00 -3.8563e+00 -4.5530e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1746e+00 -1.6575e+00 -2.7664e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.0274e+00  5.1504e-01 -7.7584e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.9926e-01  4.8621e-01 -8.0593e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4299e-01  2.2615e-01 -1.0582e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  3.8688e+00  3.5370e+00  2.6611e+00  ...  -2.7218e-01 -1.0000e+02 -1.0000e+02
  7.7095e-01  2.0298e-01 -1.0425e+00  ...  -3.5639e+00 -1.0000e+02 -1.0000e+02
  7.7095e-01  2.0298e-01 -1.0425e+00  ...  -3.5639e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7095e-01  2.0298e-01 -1.0425e+00  ...  -3.5639e+00 -1.0000e+02 -1.0000e+02
  7.7095e-01  2.0298e-01 -1.0425e+00  ...  -3.5639e+00 -1.0000e+02 -1.0000e+02
  7.7095e-01  2.0298e-01 -1.0425e+00  ...  -3.5639e+00 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.4565e+00  3.0765e+00  2.0629e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4706e-01  7.2067e-02 -1.2147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4706e-01  7.2067e-02 -1.2147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.4706e-01  7.2067e-02 -1.2147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4706e-01  7.2067e-02 -1.2147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.4706e-01  7.2067e-02 -1.2147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.8374e+00  3.5679e+00  2.6272e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8223e-01  3.1372e-01 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8223e-01  3.1372e-01 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8223e-01  3.1372e-01 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8223e-01  3.1372e-01 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8223e-01  3.1372e-01 -1.0359e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  3.3334e+00  2.9519e+00  1.8187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.3788e+00 -3.7482e+00 -4.5218e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1635e+00 -1.6852e+00 -2.8725e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.3308e-01  3.7834e-01 -1.0144e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.9383e-01  3.3808e-01 -1.0557e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.2812e-01  6.9100e-02 -1.3114e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x8x63 (GPU 0)]

gt_where_seq [[7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 22, 0, 55, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.4435e+00  3.0086e+00  1.8694e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.6103e+00 -4.0070e+00 -4.7196e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.0223e+00 -1.6252e+00 -2.8271e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.1512e-01  2.7970e-01 -1.1191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9173e-01  5.3052e-02 -1.3341e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.9173e-01  5.3052e-02 -1.3341e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.5454e+00  3.2384e+00  2.2777e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4824e+00 -3.7878e+00 -4.4852e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.0379e+00 -1.4821e+00 -2.5842e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.5738e-01  4.9119e-01 -7.6358e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5470e-01  2.8580e-01 -9.6395e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5470e-01  2.8580e-01 -9.6395e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  3.7197e+00  3.4475e+00  2.4698e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.5934e+00 -3.8772e+00 -4.5915e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.0649e+00 -1.4908e+00 -2.6548e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.6202e-01  5.1438e-01 -8.1839e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.7564e-01  4.2663e-01 -9.0505e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8655e-01  2.3531e-01 -1.0908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.5144e+00  3.2187e+00  2.2778e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.4762e+00 -3.7736e+00 -4.4620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.0883e+00 -1.5189e+00 -2.5966e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.0040e+00  5.5329e-01 -6.8032e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2708e-01  3.7353e-01 -8.5734e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3709e-01  2.8235e-01 -9.4657e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.1226e+00  2.7410e+00  1.7046e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.7994e+00 -4.1109e+00 -4.7289e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.1635e+00 -1.6567e+00 -2.7265e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.5427e-01  1.2758e-01 -1.1032e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5427e-01  1.2758e-01 -1.1032e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.5427e-01  1.2758e-01 -1.1032e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  3.7332e+00  3.4516e+00  2.6075e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2291e-01  3.6370e-01 -8.1663e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2291e-01  3.6370e-01 -8.1663e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.2291e-01  3.6370e-01 -8.1663e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2291e-01  3.6370e-01 -8.1663e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2291e-01  3.6370e-01 -8.1663e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.1452e+00  3.9056e+00  2.9797e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6129e-01  3.0312e-01 -1.1154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6129e-01  3.0312e-01 -1.1154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.6129e-01  3.0312e-01 -1.1154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6129e-01  3.0312e-01 -1.1154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6129e-01  3.0312e-01 -1.1154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.8424e+00  3.4770e+00  2.5581e+00  ...   5.7240e-02 -5.2426e-01 -7.2740e-01
 -4.0739e+00 -4.4003e+00 -4.9629e+00  ...  -5.6217e+00 -5.7360e+00 -5.7862e+00
 -1.0040e+00 -1.5795e+00 -2.6767e+00  ...  -4.2673e+00 -4.5460e+00 -4.6607e+00
                 ...                   ⋱                   ...                
  5.8289e-01 -2.6407e-02 -1.2654e+00  ...  -3.3303e+00 -3.7029e+00 -3.8488e+00
  1.0202e+00  4.1474e-01 -8.4401e-01  ...  -3.0459e+00 -3.4466e+00 -3.6013e+00
  9.3563e-01  3.2830e-01 -9.3029e-01  ...  -3.1162e+00 -3.5123e+00 -3.6654e+00

(2 ,.,.) = 
  4.1513e+00  3.9648e+00  3.0053e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.0906e+00 -4.2887e+00 -4.9617e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6689e-01 -1.3161e+00 -2.6256e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.2157e-01  1.5548e-01 -1.2994e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.7884e-01  5.1458e-01 -9.5833e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0083e+00  6.4544e-01 -8.3404e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(3 ,.,.) = 
  3.4807e+00  3.0315e+00  1.7251e+00  ...   2.1106e-01 -1.9766e-01 -6.1916e-01
 -3.7945e+00 -4.1856e+00 -4.9301e+00  ...  -5.3380e+00 -5.4355e+00 -5.5629e+00
 -8.2057e-01 -1.4572e+00 -2.8319e+00  ...  -3.7604e+00 -3.9794e+00 -4.2489e+00
                 ...                   ⋱                   ...                
  7.1804e-01  5.2993e-02 -1.5038e+00  ...  -2.7170e+00 -3.0043e+00 -3.3396e+00
  1.0154e+00  3.5400e-01 -1.2235e+00  ...  -2.4967e+00 -2.7986e+00 -3.1460e+00
  9.4003e-01  2.7668e-01 -1.2998e+00  ...  -2.5661e+00 -2.8656e+00 -3.2102e+00

(4 ,.,.) = 
  3.8939e+00  3.6279e+00  2.6635e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9828e-01  3.3213e-01 -1.0314e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9828e-01  3.3213e-01 -1.0314e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.9828e-01  3.3213e-01 -1.0314e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9828e-01  3.3213e-01 -1.0314e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9828e-01  3.3213e-01 -1.0314e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(5 ,.,.) = 
  4.0475e+00  3.6036e+00  2.3890e+00  ...   8.8939e-02 -1.2617e-01 -5.5729e-01
  7.1287e-01 -5.0739e-02 -1.6775e+00  ...  -3.5114e+00 -3.6371e+00 -3.9255e+00
  7.1287e-01 -5.0739e-02 -1.6775e+00  ...  -3.5114e+00 -3.6371e+00 -3.9255e+00
                 ...                   ⋱                   ...                
  7.1287e-01 -5.0739e-02 -1.6775e+00  ...  -3.5114e+00 -3.6371e+00 -3.9255e+00
  7.1287e-01 -5.0739e-02 -1.6775e+00  ...  -3.5114e+00 -3.6371e+00 -3.9255e+00
  7.1287e-01 -5.0739e-02 -1.6775e+00  ...  -3.5114e+00 -3.6371e+00 -3.9255e+00
[torch.cuda.FloatTensor of size 6x7x59 (GPU 0)]

 Loss = 4.54216003418
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  3.9244e+00  3.5059e+00  2.2319e+00  ...  -1.0034e-01 -3.8381e-01 -1.0000e+02
 -4.2104e+00 -4.5669e+00 -5.2327e+00  ...  -5.7270e+00 -5.7984e+00 -1.0000e+02
 -8.4675e-01 -1.5129e+00 -2.9564e+00  ...  -4.3023e+00 -4.4809e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1341e-01  1.4478e-02 -1.6374e+00  ...  -3.4347e+00 -3.6569e+00 -1.0000e+02
  7.1341e-01  1.4478e-02 -1.6374e+00  ...  -3.4347e+00 -3.6569e+00 -1.0000e+02
  7.1341e-01  1.4478e-02 -1.6374e+00  ...  -3.4347e+00 -3.6569e+00 -1.0000e+02

( 1 ,.,.) = 
  3.9292e+00  3.5118e+00  2.2408e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2150e+00 -4.5703e+00 -5.2345e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.5681e-01 -1.5216e+00 -2.9625e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1400e-01  1.6186e-02 -1.6344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1400e-01  1.6186e-02 -1.6344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1400e-01  1.6186e-02 -1.6344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.1147e+00  3.7240e+00  2.5191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2847e+00 -4.6311e+00 -5.2760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.1523e-01 -1.5787e+00 -3.0113e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1340e-01  1.4448e-02 -1.6375e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1340e-01  1.4448e-02 -1.6375e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1340e-01  1.4448e-02 -1.6375e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.2042e+00  3.8272e+00  2.6571e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2963e+00 -4.6411e+00 -5.2827e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.7789e-01 -1.6382e+00 -3.0603e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1364e-01  1.5161e-02 -1.6362e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1364e-01  1.5161e-02 -1.6362e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1364e-01  1.5161e-02 -1.6362e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.1970e+00  3.8196e+00  2.6485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3138e+00 -4.6558e+00 -5.2922e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.5838e-01 -1.6189e+00 -3.0435e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1402e-01  1.6223e-02 -1.6343e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1402e-01  1.6223e-02 -1.6343e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1402e-01  1.6223e-02 -1.6343e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.0423e+00  3.6418e+00  2.4124e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2707e+00 -4.6185e+00 -5.2670e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.8107e-01 -1.5450e+00 -2.9822e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1393e-01  1.5965e-02 -1.6348e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1393e-01  1.5965e-02 -1.6348e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1393e-01  1.5965e-02 -1.6348e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.0276e+00  3.6244e+00  2.3880e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2634e+00 -4.6125e+00 -5.2633e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7770e-01 -1.5424e+00 -2.9807e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1359e-01  1.4987e-02 -1.6365e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1359e-01  1.4987e-02 -1.6365e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1359e-01  1.4987e-02 -1.6365e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.8654e+00  3.4393e+00  2.1474e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.1979e+00 -4.5555e+00 -5.2246e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.4148e-01 -1.5068e+00 -2.9500e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1401e-01  1.6191e-02 -1.6344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1401e-01  1.6191e-02 -1.6344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1401e-01  1.6191e-02 -1.6344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.9581e+00  3.5448e+00  2.2835e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2302e+00 -4.5838e+00 -5.2439e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.5748e-01 -1.5228e+00 -2.9642e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1365e-01  1.5145e-02 -1.6362e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1365e-01  1.5145e-02 -1.6362e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1365e-01  1.5145e-02 -1.6362e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.1015e+00  3.7090e+00  2.4992e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2814e+00 -4.6282e+00 -5.2740e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.0747e-01 -1.5712e+00 -3.0050e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1342e-01  1.4527e-02 -1.6373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1342e-01  1.4527e-02 -1.6373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1342e-01  1.4527e-02 -1.6373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.4365e+00  2.9515e+00  1.5265e+00  ...  -2.3409e-01 -7.2104e-01 -1.0000e+02
 -3.9237e+00 -4.3184e+00 -5.0641e+00  ...  -5.4783e+00 -5.6187e+00 -1.0000e+02
 -7.7342e-01 -1.4421e+00 -2.8967e+00  ...  -3.9110e+00 -4.2221e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1365e-01  1.5179e-02 -1.6362e+00  ...  -2.9821e+00 -3.3653e+00 -1.0000e+02
  7.1365e-01  1.5179e-02 -1.6362e+00  ...  -2.9821e+00 -3.3653e+00 -1.0000e+02
  7.1365e-01  1.5179e-02 -1.6362e+00  ...  -2.9821e+00 -3.3653e+00 -1.0000e+02

(14 ,.,.) = 
  3.9185e+00  3.4986e+00  2.2211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.1957e+00 -4.5542e+00 -5.2240e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.6128e-01 -1.5268e+00 -2.9679e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1352e-01  1.4815e-02 -1.6368e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1352e-01  1.4815e-02 -1.6368e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1352e-01  1.4815e-02 -1.6368e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.9154e+00  3.4965e+00  2.2215e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2108e+00 -4.5665e+00 -5.2318e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.4925e-01 -1.5139e+00 -2.9557e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1422e-01  1.6797e-02 -1.6333e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1422e-01  1.6797e-02 -1.6333e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1422e-01  1.6797e-02 -1.6333e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.1198e+00  3.7299e+00  2.5270e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2864e+00 -4.6326e+00 -5.2770e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.1995e-01 -1.5832e+00 -3.0151e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1338e-01  1.4416e-02 -1.6375e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1338e-01  1.4416e-02 -1.6375e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1338e-01  1.4416e-02 -1.6375e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.0230e+00  3.6190e+00  2.3806e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2517e+00 -4.6024e+00 -5.2565e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.7345e-01 -1.5383e+00 -2.9774e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1353e-01  1.4840e-02 -1.6368e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1353e-01  1.4840e-02 -1.6368e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1353e-01  1.4840e-02 -1.6368e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.7502e+00  3.3083e+00  1.9791e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.1262e+00 -4.4934e+00 -5.1825e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.1081e-01 -1.4771e+00 -2.9248e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1416e-01  1.6641e-02 -1.6336e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1416e-01  1.6641e-02 -1.6336e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1416e-01  1.6641e-02 -1.6336e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.8325e+00  3.4018e+00  2.0986e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.1744e+00 -4.5352e+00 -5.2108e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.3086e-01 -1.4965e+00 -2.9412e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1410e-01  1.6445e-02 -1.6340e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1410e-01  1.6445e-02 -1.6340e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1410e-01  1.6445e-02 -1.6340e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.0209e+00  3.6164e+00  2.3766e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2432e+00 -4.5951e+00 -5.2516e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.8351e-01 -1.5480e+00 -2.9855e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1361e-01  1.5064e-02 -1.6364e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1361e-01  1.5064e-02 -1.6364e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1361e-01  1.5064e-02 -1.6364e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.9851e+00  3.5753e+00  2.3228e+00  ...   2.3695e-01 -1.8545e-01 -3.9763e-01
 -4.2365e+00 -4.5895e+00 -5.2479e+00  ...  -5.6998e+00 -5.7722e+00 -5.8270e+00
 -8.5973e-01 -1.5254e+00 -2.9669e+00  ...  -4.2082e+00 -4.4077e+00 -4.5452e+00
                 ...                   ⋱                   ...                
  7.1338e-01  1.4423e-02 -1.6375e+00  ...  -3.2949e+00 -3.5640e+00 -3.7340e+00
  7.1338e-01  1.4423e-02 -1.6375e+00  ...  -3.2949e+00 -3.5640e+00 -3.7340e+00
  7.1338e-01  1.4423e-02 -1.6375e+00  ...  -3.2949e+00 -3.5640e+00 -3.7340e+00

( 1 ,.,.) = 
  3.9690e+00  3.5573e+00  2.3001e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2336e+00 -4.5866e+00 -5.2457e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.6189e-01 -1.5269e+00 -2.9673e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1374e-01  1.5409e-02 -1.6358e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1374e-01  1.5409e-02 -1.6358e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1374e-01  1.5409e-02 -1.6358e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.9477e+00  3.5333e+00  2.2695e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2248e+00 -4.5789e+00 -5.2403e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.4731e-01 -1.5126e+00 -2.9550e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1391e-01  1.5903e-02 -1.6349e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1391e-01  1.5903e-02 -1.6349e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.1391e-01  1.5903e-02 -1.6349e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  4.0216e+00  3.6169e+00  2.3766e+00  ...  -1.1962e+00 -1.4265e+00 -4.3674e-01
 -4.2457e+00 -4.5976e+00 -5.2535e+00  ...  -5.9587e+00 -5.9855e+00 -5.8479e+00
 -8.8854e-01 -1.5533e+00 -2.9904e+00  ...  -4.9401e+00 -5.0196e+00 -4.6106e+00
                 ...                   ⋱                   ...                
  7.1330e-01  1.4165e-02 -1.6380e+00  ...  -4.2538e+00 -4.3674e+00 -3.8021e+00
  7.1330e-01  1.4165e-02 -1.6380e+00  ...  -4.2538e+00 -4.3674e+00 -3.8021e+00
  7.1330e-01  1.4165e-02 -1.6380e+00  ...  -4.2538e+00 -4.3674e+00 -3.8021e+00

( 4 ,.,.) = 
  3.6391e+00  3.1806e+00  1.8132e+00  ...  -4.7593e-01 -1.0000e+02 -1.0000e+02
 -4.0569e+00 -4.4339e+00 -5.1426e+00  ...  -5.6767e+00 -1.0000e+02 -1.0000e+02
 -8.0288e-01 -1.4703e+00 -2.9202e+00  ...  -4.2678e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1365e-01  1.5179e-02 -1.6362e+00  ...  -3.4057e+00 -1.0000e+02 -1.0000e+02
  7.1365e-01  1.5179e-02 -1.6362e+00  ...  -3.4057e+00 -1.0000e+02 -1.0000e+02
  7.1365e-01  1.5179e-02 -1.6362e+00  ...  -3.4057e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  3.5006e+00  3.0241e+00  1.6172e+00  ...  -6.4035e-01 -1.0000e+02 -1.0000e+02
 -3.9669e+00 -4.3557e+00 -5.0894e+00  ...  -5.6367e+00 -1.0000e+02 -1.0000e+02
 -7.8067e-01 -1.4487e+00 -2.9018e+00  ...  -4.2330e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.1383e-01  1.5707e-02 -1.6352e+00  ...  -3.3745e+00 -1.0000e+02 -1.0000e+02
  7.1383e-01  1.5707e-02 -1.6352e+00  ...  -3.3745e+00 -1.0000e+02 -1.0000e+02
  7.1383e-01  1.5707e-02 -1.6352e+00  ...  -3.3745e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.0846e+00  3.6218e+00  2.2651e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3222e+00 -4.7118e+00 -5.3708e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.7137e-01 -1.7308e+00 -3.2386e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3697e-01 -1.7026e-01 -1.9356e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3697e-01 -1.7026e-01 -1.9356e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3697e-01 -1.7026e-01 -1.9356e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.9750e+00  3.4930e+00  2.0914e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2531e+00 -4.6534e+00 -5.3329e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.4869e-01 -1.7089e+00 -3.2207e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3736e-01 -1.6920e-01 -1.9339e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3736e-01 -1.6920e-01 -1.9339e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3736e-01 -1.6920e-01 -1.9339e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.1428e+00  3.6884e+00  2.3519e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3343e+00 -4.7231e+00 -5.3791e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.0020e+00 -1.7622e+00 -3.2660e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3538e-01 -1.7438e-01 -1.9420e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3538e-01 -1.7438e-01 -1.9420e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3538e-01 -1.7438e-01 -1.9420e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.0171e+00  3.5429e+00  2.1598e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.2991e+00 -4.6922e+00 -5.3581e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.4825e-01 -1.7087e+00 -3.2206e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3709e-01 -1.6996e-01 -1.9351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3709e-01 -1.6996e-01 -1.9351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3709e-01 -1.6996e-01 -1.9351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.1513e+00  3.6993e+00  2.3684e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3411e+00 -4.7284e+00 -5.3821e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.9857e-01 -1.7579e+00 -3.2615e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3611e-01 -1.7247e-01 -1.9390e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3611e-01 -1.7247e-01 -1.9390e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3611e-01 -1.7247e-01 -1.9390e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.0846e+00  3.6218e+00  2.2651e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3222e+00 -4.7118e+00 -5.3708e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.7137e-01 -1.7308e+00 -3.2386e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3697e-01 -1.7026e-01 -1.9356e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3697e-01 -1.7026e-01 -1.9356e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3697e-01 -1.7026e-01 -1.9356e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.0653e+00  3.6000e+00  2.2373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3137e+00 -4.7040e+00 -5.3654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6410e-01 -1.7227e+00 -3.2309e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3780e-01 -1.6808e-01 -1.9322e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3780e-01 -1.6808e-01 -1.9322e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3780e-01 -1.6808e-01 -1.9322e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.0653e+00  3.6000e+00  2.2373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3137e+00 -4.7040e+00 -5.3654e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6410e-01 -1.7227e+00 -3.2309e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3780e-01 -1.6808e-01 -1.9322e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3780e-01 -1.6808e-01 -1.9322e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3780e-01 -1.6808e-01 -1.9322e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.0588e+00  3.5903e+00  2.2208e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3095e+00 -4.7020e+00 -5.3652e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.6176e-01 -1.7235e+00 -3.2343e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3575e-01 -1.7339e-01 -1.9405e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3575e-01 -1.7339e-01 -1.9405e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3575e-01 -1.7339e-01 -1.9405e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  3.9645e+00  3.4785e+00  2.0693e+00  ...  -1.2393e-01 -8.2244e-02 -3.1762e-01
 -4.2709e+00 -4.6703e+00 -5.3453e+00  ...  -5.7789e+00 -5.7580e+00 -5.8176e+00
 -9.3737e-01 -1.7021e+00 -3.2187e+00  ...  -4.4290e+00 -4.3777e+00 -4.5269e+00
                 ...                   ⋱                   ...                
  6.3454e-01 -1.7655e-01 -1.9453e+00  ...  -3.5810e+00 -3.5235e+00 -3.7091e+00
  6.3454e-01 -1.7655e-01 -1.9453e+00  ...  -3.5810e+00 -3.5235e+00 -3.7091e+00
  6.3454e-01 -1.7655e-01 -1.9453e+00  ...  -3.5810e+00 -3.5235e+00 -3.7091e+00

( 4 ,.,.) = 
  3.9627e+00  3.4781e+00  2.0721e+00  ...  -1.3406e-01 -3.7260e-01 -1.0000e+02
 -4.2771e+00 -4.6747e+00 -5.3474e+00  ...  -5.7682e+00 -5.8284e+00 -1.0000e+02
 -9.2929e-01 -1.6925e+00 -3.2090e+00  ...  -4.3955e+00 -4.5475e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3581e-01 -1.7326e-01 -1.9402e+00  ...  -3.5533e+00 -3.7420e+00 -1.0000e+02
  6.3581e-01 -1.7326e-01 -1.9402e+00  ...  -3.5533e+00 -3.7420e+00 -1.0000e+02
  6.3581e-01 -1.7326e-01 -1.9402e+00  ...  -3.5533e+00 -3.7420e+00 -1.0000e+02

( 5 ,.,.) = 
  4.0525e+00  3.5840e+00  2.2141e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.3142e+00 -4.7053e+00 -5.3669e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -9.5460e-01 -1.7156e+00 -3.2270e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3650e-01 -1.7153e-01 -1.9376e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3650e-01 -1.7153e-01 -1.9376e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.3650e-01 -1.7153e-01 -1.9376e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 16 @ 2018-04-12 20:36:26.176162
training
gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 22, 0, 53, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.9629e+00  3.5569e+00  2.4694e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5639e-01  6.5825e-02 -1.4016e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5639e-01  6.5825e-02 -1.4016e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.5639e-01  6.5825e-02 -1.4016e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5639e-01  6.5825e-02 -1.4016e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5639e-01  6.5825e-02 -1.4016e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  4.1408e+00  3.8630e+00  2.7531e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2209e-01  1.9581e-01 -1.4097e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2209e-01  1.9581e-01 -1.4097e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2209e-01  1.9581e-01 -1.4097e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2209e-01  1.9581e-01 -1.4097e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2209e-01  1.9581e-01 -1.4097e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  3.9854e+00  3.6571e+00  2.5803e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8210e-01  1.0865e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8210e-01  1.0865e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.8210e-01  1.0865e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8210e-01  1.0865e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.8210e-01  1.0865e-01 -1.3700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.7228e+00  3.2479e+00  1.9004e+00  ...  -5.1385e-01 -1.0000e+02 -1.0000e+02
  6.2714e-01 -1.1187e-01 -1.7565e+00  ...  -3.5897e+00 -1.0000e+02 -1.0000e+02
  6.2714e-01 -1.1187e-01 -1.7565e+00  ...  -3.5897e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.2714e-01 -1.1187e-01 -1.7565e+00  ...  -3.5897e+00 -1.0000e+02 -1.0000e+02
  6.2714e-01 -1.1187e-01 -1.7565e+00  ...  -3.5897e+00 -1.0000e+02 -1.0000e+02
  6.2714e-01 -1.1187e-01 -1.7565e+00  ...  -3.5897e+00 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  4.0687e+00  3.6897e+00  2.4847e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0753e-01  3.8378e-02 -1.6039e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0753e-01  3.8378e-02 -1.6039e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.0753e-01  3.8378e-02 -1.6039e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0753e-01  3.8378e-02 -1.6039e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.0753e-01  3.8378e-02 -1.6039e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  3.7885e+00  3.3687e+00  2.1041e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4044e-01  6.8058e-02 -1.5384e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4044e-01  6.8058e-02 -1.5384e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4044e-01  6.8058e-02 -1.5384e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4044e-01  6.8058e-02 -1.5384e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4044e-01  6.8058e-02 -1.5384e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 0, 14, 0, 54, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.9759e+00  3.6061e+00  2.3936e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8236e-01  1.5365e-01 -1.4609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8236e-01  1.5365e-01 -1.4609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.8236e-01  1.5365e-01 -1.4609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8236e-01  1.5365e-01 -1.4609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.8236e-01  1.5365e-01 -1.4609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  4.0105e+00  3.5232e+00  2.2323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3450e-01 -8.3630e-02 -1.7355e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3450e-01 -8.3630e-02 -1.7355e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.3450e-01 -8.3630e-02 -1.7355e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3450e-01 -8.3630e-02 -1.7355e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.3450e-01 -8.3630e-02 -1.7355e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  4.2112e+00  3.9470e+00  2.7301e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5436e-01  2.4701e-01 -1.5076e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5436e-01  2.4701e-01 -1.5076e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.5436e-01  2.4701e-01 -1.5076e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5436e-01  2.4701e-01 -1.5076e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5436e-01  2.4701e-01 -1.5076e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.7552e+00  3.3514e+00  2.1095e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.4002e+00 -4.7051e+00 -5.3003e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -8.1757e-01 -1.4301e+00 -2.8143e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  5.6316e-01 -7.5825e-02 -1.6210e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0460e+00  4.1140e-01 -1.1683e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0060e+00  3.6992e-01 -1.2113e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  4.2796e+00  3.9474e+00  2.8603e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7429e-01  1.4638e-01 -1.4479e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7429e-01  1.4638e-01 -1.4479e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7429e-01  1.4638e-01 -1.4479e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7429e-01  1.4638e-01 -1.4479e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7429e-01  1.4638e-01 -1.4479e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  4.3994e+00  4.0696e+00  2.8914e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.5785e-01  2.0459e-01 -1.5589e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.5785e-01  2.0459e-01 -1.5589e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.5785e-01  2.0459e-01 -1.5589e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.5785e-01  2.0459e-01 -1.5589e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.5785e-01  2.0459e-01 -1.5589e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    3.4718    2.8127    1.2049  ...  -100.0000 -100.0000 -100.0000
   -4.1746   -4.6433   -5.3327  ...  -100.0000 -100.0000 -100.0000
   -0.4222   -1.3082   -2.8866  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.0552    0.1471   -1.6356  ...  -100.0000 -100.0000 -100.0000
    0.7580   -0.1551   -1.9085  ...  -100.0000 -100.0000 -100.0000
    0.7580   -0.1551   -1.9085  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    3.5957    3.0347    1.3275  ...  -100.0000 -100.0000 -100.0000
   -4.3871   -4.7788   -5.4749  ...  -100.0000 -100.0000 -100.0000
   -0.5778   -1.3741   -3.0873  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7622   -0.0627   -1.9948  ...  -100.0000 -100.0000 -100.0000
    0.7622   -0.0627   -1.9948  ...  -100.0000 -100.0000 -100.0000
    0.7622   -0.0627   -1.9948  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    4.4240    3.9800    2.7293  ...  -100.0000 -100.0000 -100.0000
    0.7421   -0.1137   -1.8754  ...  -100.0000 -100.0000 -100.0000
    0.7421   -0.1137   -1.8754  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7421   -0.1137   -1.8754  ...  -100.0000 -100.0000 -100.0000
    0.7421   -0.1137   -1.8754  ...  -100.0000 -100.0000 -100.0000
    0.7421   -0.1137   -1.8754  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    4.1133    3.6345    2.0459  ...  -100.0000 -100.0000 -100.0000
    0.6623   -0.1536   -2.1339  ...  -100.0000 -100.0000 -100.0000
    0.6623   -0.1536   -2.1339  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.6623   -0.1536   -2.1339  ...  -100.0000 -100.0000 -100.0000
    0.6623   -0.1536   -2.1339  ...  -100.0000 -100.0000 -100.0000
    0.6623   -0.1536   -2.1339  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    3.7835    3.4286    1.9928  ...  -100.0000 -100.0000 -100.0000
   -4.3614   -4.6399   -5.3333  ...  -100.0000 -100.0000 -100.0000
   -0.5927   -1.1409   -2.7494  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.9640    0.4030   -1.3956  ...  -100.0000 -100.0000 -100.0000
    0.6678    0.1028   -1.6739  ...  -100.0000 -100.0000 -100.0000
    0.6678    0.1028   -1.6739  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    4.2307    3.9219    2.6550  ...  -100.0000 -100.0000 -100.0000
    0.7963    0.2203   -1.5691  ...  -100.0000 -100.0000 -100.0000
    0.7963    0.2203   -1.5691  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7963    0.2203   -1.5691  ...  -100.0000 -100.0000 -100.0000
    0.7963    0.2203   -1.5691  ...  -100.0000 -100.0000 -100.0000
    0.7963    0.2203   -1.5691  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 22, 0, 54, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    4.0057    3.5789    2.3397  ...  -100.0000 -100.0000 -100.0000
   -4.3529   -4.7001   -5.3178  ...  -100.0000 -100.0000 -100.0000
   -0.2534   -0.9517   -2.4323  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1680    0.4650   -1.1538  ...  -100.0000 -100.0000 -100.0000
    1.1379    0.4340   -1.1860  ...  -100.0000 -100.0000 -100.0000
    0.9085    0.1996   -1.4087  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    4.0097    3.4595    1.6299  ...  -100.0000 -100.0000 -100.0000
   -4.5275   -4.9292   -5.6306  ...  -100.0000 -100.0000 -100.0000
   -0.2272   -1.0984   -3.0467  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.8233   -0.0645   -2.2053  ...  -100.0000 -100.0000 -100.0000
    0.8233   -0.0645   -2.2053  ...  -100.0000 -100.0000 -100.0000
    0.8233   -0.0645   -2.2053  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    3.7824    3.3276    1.6825  ...  -100.0000 -100.0000 -100.0000
   -4.5162   -4.8443   -5.5243  ...  -100.0000 -100.0000 -100.0000
   -0.3328   -1.0284   -2.8188  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.8071    0.0988   -1.8608  ...  -100.0000 -100.0000 -100.0000
    0.8071    0.0988   -1.8608  ...  -100.0000 -100.0000 -100.0000
    0.8071    0.0988   -1.8608  ...  -100.0000 -100.0000 -100.0000

(3 ,.,.) = 
    4.2031    3.8285    2.5146  ...    -0.4589   -0.4710 -100.0000
    0.8208    0.1474   -1.6306  ...    -3.8485   -3.8790 -100.0000
    0.8208    0.1474   -1.6306  ...    -3.8485   -3.8790 -100.0000
              ...                ⋱                ...             
    0.8208    0.1474   -1.6306  ...    -3.8485   -3.8790 -100.0000
    0.8208    0.1474   -1.6306  ...    -3.8485   -3.8790 -100.0000
    0.8208    0.1474   -1.6306  ...    -3.8485   -3.8790 -100.0000

(4 ,.,.) = 
    4.0210    3.5040    2.0154  ...  -100.0000 -100.0000 -100.0000
    0.7689   -0.0780   -1.8992  ...  -100.0000 -100.0000 -100.0000
    0.7689   -0.0780   -1.8992  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7689   -0.0780   -1.8992  ...  -100.0000 -100.0000 -100.0000
    0.7689   -0.0780   -1.8992  ...  -100.0000 -100.0000 -100.0000
    0.7689   -0.0780   -1.8992  ...  -100.0000 -100.0000 -100.0000

(5 ,.,.) = 
    3.8532    3.3395    1.7658  ...     1.2024    0.2061   -0.2586
   -4.3173   -4.7123   -5.4136  ...    -5.4448   -5.6742   -5.8009
   -0.3238   -1.1029   -2.7973  ...    -3.0306   -3.6818   -4.0178
              ...                ⋱                ...             
    1.0446    0.2540   -1.6258  ...    -1.9966   -2.7908   -3.1831
    0.7306   -0.0653   -1.9142  ...    -2.2671   -3.0313   -3.4102
    0.7306   -0.0653   -1.9142  ...    -2.2671   -3.0313   -3.4102
[torch.cuda.FloatTensor of size 6x9x62 (GPU 0)]

 Loss = 4.49195424248
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.2045e+00  3.6635e+00  1.9655e+00  ...   3.1137e-01 -8.0192e-02 -1.0000e+02
 -4.7975e+00 -5.1644e+00 -5.7541e+00  ...  -5.9518e+00 -6.0248e+00 -1.0000e+02
 -1.9477e-01 -1.1066e+00 -2.9989e+00  ...  -3.9011e+00 -4.1719e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7293e-01 -1.5710e-01 -2.2238e+00  ...  -3.3404e+00 -3.6465e+00 -1.0000e+02
  7.7293e-01 -1.5710e-01 -2.2238e+00  ...  -3.3404e+00 -3.6465e+00 -1.0000e+02
  7.7293e-01 -1.5710e-01 -2.2238e+00  ...  -3.3404e+00 -3.6465e+00 -1.0000e+02

( 1 ,.,.) = 
  4.2105e+00  3.6720e+00  1.9787e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8017e+00 -5.1670e+00 -5.7550e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9606e-01 -1.1058e+00 -2.9967e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7406e-01 -1.5373e-01 -2.2191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7406e-01 -1.5373e-01 -2.2191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7406e-01 -1.5373e-01 -2.2191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.4270e+00  3.9316e+00  2.3410e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8736e+00 -5.2256e+00 -5.7891e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0214e-01 -1.1140e+00 -3.0059e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7294e-01 -1.5705e-01 -2.2238e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7294e-01 -1.5705e-01 -2.2238e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7294e-01 -1.5705e-01 -2.2238e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.5200e+00  4.0447e+00  2.5036e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8835e+00 -5.2333e+00 -5.7935e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.3019e-01 -1.1405e+00 -3.0272e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7342e-01 -1.5564e-01 -2.2218e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7342e-01 -1.5564e-01 -2.2218e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7342e-01 -1.5564e-01 -2.2218e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.5066e+00  4.0294e+00  2.4836e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8983e+00 -5.2447e+00 -5.7998e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.1538e-01 -1.1249e+00 -3.0134e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7408e-01 -1.5371e-01 -2.2190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7408e-01 -1.5371e-01 -2.2190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7408e-01 -1.5371e-01 -2.2190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.3430e+00  3.8317e+00  2.2023e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8576e+00 -5.2121e+00 -5.7811e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9362e-01 -1.1039e+00 -2.9958e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7389e-01 -1.5426e-01 -2.2198e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7389e-01 -1.5426e-01 -2.2198e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7389e-01 -1.5426e-01 -2.2198e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.2997e+00  3.7785e+00  2.1258e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8430e+00 -5.2007e+00 -5.7748e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9290e-01 -1.1042e+00 -2.9968e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7331e-01 -1.5602e-01 -2.2224e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7331e-01 -1.5602e-01 -2.2224e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7331e-01 -1.5602e-01 -2.2224e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.1201e+00  3.5643e+00  1.8322e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7764e+00 -5.1466e+00 -5.7435e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0189e-01 -1.1113e+00 -3.0008e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7408e-01 -1.5371e-01 -2.2191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7408e-01 -1.5371e-01 -2.2191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7408e-01 -1.5371e-01 -2.2191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.2301e+00  3.6950e+00  2.0099e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8123e+00 -5.1760e+00 -5.7606e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9534e-01 -1.1063e+00 -2.9981e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7340e-01 -1.5572e-01 -2.2219e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7340e-01 -1.5572e-01 -2.2219e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7340e-01 -1.5572e-01 -2.2219e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.4129e+00  3.9145e+00  2.3168e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8706e+00 -5.2231e+00 -5.7877e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9916e-01 -1.1110e+00 -3.0033e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7299e-01 -1.5692e-01 -2.2236e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7299e-01 -1.5692e-01 -2.2236e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7299e-01 -1.5692e-01 -2.2236e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.6597e+00  3.0176e+00  1.1093e+00  ...   1.6995e-01 -4.5670e-01 -1.0000e+02
 -4.4977e+00 -4.9216e+00 -5.6133e+00  ...  -5.7063e+00 -5.8531e+00 -1.0000e+02
 -2.4360e-01 -1.1528e+00 -3.0346e+00  ...  -3.4679e+00 -3.9078e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7340e-01 -1.5569e-01 -2.2219e+00  ...  -2.7997e+00 -3.2997e+00 -1.0000e+02
  7.7340e-01 -1.5569e-01 -2.2219e+00  ...  -2.7997e+00 -3.2997e+00 -1.0000e+02
  7.7340e-01 -1.5569e-01 -2.2219e+00  ...  -2.7997e+00 -3.2997e+00 -1.0000e+02

(14 ,.,.) = 
  4.1947e+00  3.6513e+00  1.9472e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7831e+00 -5.1526e+00 -5.7470e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9705e-01 -1.1084e+00 -3.0003e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7319e-01 -1.5631e-01 -2.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7319e-01 -1.5631e-01 -2.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7319e-01 -1.5631e-01 -2.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.2017e+00  3.6621e+00  1.9662e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8002e+00 -5.1654e+00 -5.7540e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9418e-01 -1.1032e+00 -2.9940e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7447e-01 -1.5253e-01 -2.2174e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7447e-01 -1.5253e-01 -2.2174e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7447e-01 -1.5253e-01 -2.2174e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.4320e+00  3.9376e+00  2.3496e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8751e+00 -5.2268e+00 -5.7898e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0394e-01 -1.1158e+00 -3.0074e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7291e-01 -1.5713e-01 -2.2239e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7291e-01 -1.5713e-01 -2.2239e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7291e-01 -1.5713e-01 -2.2239e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.3319e+00  3.8171e+00  2.1797e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8441e+00 -5.2016e+00 -5.7753e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9289e-01 -1.1044e+00 -2.9972e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7319e-01 -1.5631e-01 -2.2227e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7319e-01 -1.5631e-01 -2.2227e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7319e-01 -1.5631e-01 -2.2227e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.9917e+00  3.4118e+00  1.6272e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.6995e+00 -5.0844e+00 -5.7075e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0950e-01 -1.1180e+00 -3.0055e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7437e-01 -1.5281e-01 -2.2178e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7437e-01 -1.5281e-01 -2.2178e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7437e-01 -1.5281e-01 -2.2178e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.0891e+00  3.5274e+00  1.7820e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7553e+00 -5.1295e+00 -5.7336e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.0256e-01 -1.1116e+00 -3.0008e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7423e-01 -1.5324e-01 -2.2184e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7423e-01 -1.5324e-01 -2.2184e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7423e-01 -1.5324e-01 -2.2184e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.3114e+00  3.7923e+00  2.1445e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8319e+00 -5.1918e+00 -5.7696e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.9192e-01 -1.1033e+00 -2.9964e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7333e-01 -1.5587e-01 -2.2221e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7333e-01 -1.5587e-01 -2.2221e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7333e-01 -1.5587e-01 -2.2221e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    4.2784    3.7523    2.0884  ...     0.7010    0.1895   -0.1063
   -4.8252   -5.1867   -5.7668  ...    -5.9325   -5.9982   -6.0531
   -0.1918   -1.1039   -2.9969  ...    -3.7743   -4.0509   -4.2585
              ...                ⋱                ...             
    0.7729   -0.1572   -2.2239  ...    -3.1881   -3.5166   -3.7503
    0.7729   -0.1572   -2.2239  ...    -3.1881   -3.5166   -3.7503
    0.7729   -0.1572   -2.2239  ...    -3.1881   -3.5166   -3.7503

( 1 ,.,.) = 
    4.2664    3.7388    2.0709  ...  -100.0000 -100.0000 -100.0000
   -4.8238   -5.1851   -5.7657  ...  -100.0000 -100.0000 -100.0000
   -0.1953   -1.1059   -2.9976  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7736   -0.1552   -2.2212  ...  -100.0000 -100.0000 -100.0000
    0.7736   -0.1552   -2.2212  ...  -100.0000 -100.0000 -100.0000
    0.7736   -0.1552   -2.2212  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    4.2332    3.6996    2.0176  ...  -100.0000 -100.0000 -100.0000
   -4.8109   -5.1745   -5.7595  ...  -100.0000 -100.0000 -100.0000
   -0.1937   -1.1038   -2.9952  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7739   -0.1542   -2.2199  ...  -100.0000 -100.0000 -100.0000
    0.7739   -0.1542   -2.2199  ...  -100.0000 -100.0000 -100.0000
    0.7739   -0.1542   -2.2199  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    4.3166    3.7978    2.1510  ...    -0.9242   -1.1917   -0.1473
   -4.8344   -5.1942   -5.7712  ...    -6.1505   -6.1723   -6.0702
   -0.1967   -1.1090   -3.0017  ...    -4.7073   -4.8115   -4.3252
              ...                ⋱                ...             
    0.7727   -0.1577   -2.2247  ...    -4.2807   -4.4089   -3.8250
    0.7727   -0.1577   -2.2247  ...    -4.2807   -4.4089   -3.8250
    0.7727   -0.1577   -2.2247  ...    -4.2807   -4.4089   -3.8250

( 4 ,.,.) = 
    3.8939    3.2934    1.4663  ...    -0.1802 -100.0000 -100.0000
   -4.6437   -5.0400   -5.6821  ...    -5.9155 -100.0000 -100.0000
   -0.2191   -1.1290   -3.0156  ...    -3.9422 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7734   -0.1556   -2.2218  ...    -3.3592 -100.0000 -100.0000
    0.7734   -0.1556   -2.2218  ...    -3.3592 -100.0000 -100.0000
    0.7734   -0.1556   -2.2218  ...    -3.3592 -100.0000 -100.0000

( 5 ,.,.) = 
    3.7236    3.0931    1.2065  ...    -0.3712 -100.0000 -100.0000
   -4.5395   -4.9553   -5.6328  ...    -5.8691 -100.0000 -100.0000
   -0.2359   -1.1447   -3.0275  ...    -3.9092 -100.0000 -100.0000
              ...                ⋱                ...             
    0.7737   -0.1546   -2.2204  ...    -3.3070 -100.0000 -100.0000
    0.7737   -0.1546   -2.2204  ...    -3.3070 -100.0000 -100.0000
    0.7737   -0.1546   -2.2204  ...    -3.3070 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.3878e+00  3.7942e+00  2.0147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9117e+00 -5.3030e+00 -5.8586e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.9238e-01 -1.3379e+00 -3.2875e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7442e-01 -4.0014e-01 -2.5544e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7442e-01 -4.0014e-01 -2.5544e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7442e-01 -4.0014e-01 -2.5544e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.2639e+00  3.6403e+00  1.7959e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8462e+00 -5.2518e+00 -5.8303e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8779e-01 -1.3325e+00 -3.2829e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7507e-01 -3.9837e-01 -2.5523e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7507e-01 -3.9837e-01 -2.5523e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7507e-01 -3.9837e-01 -2.5523e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.4511e+00  3.8699e+00  2.1193e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9229e+00 -5.3131e+00 -5.8649e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.0609e-01 -1.3554e+00 -3.3040e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7163e-01 -4.0747e-01 -2.5635e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7163e-01 -4.0747e-01 -2.5635e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7163e-01 -4.0747e-01 -2.5635e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.3174e+00  3.7070e+00  1.8915e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8897e+00 -5.2859e+00 -5.8493e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.8909e-01 -1.3344e+00 -3.2844e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7461e-01 -3.9967e-01 -2.5539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7461e-01 -3.9967e-01 -2.5539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7461e-01 -3.9967e-01 -2.5539e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.4615e+00  3.8844e+00  2.1422e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9281e+00 -5.3165e+00 -5.8665e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -3.0181e-01 -1.3493e+00 -3.2981e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7297e-01 -4.0393e-01 -2.5592e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7297e-01 -4.0393e-01 -2.5592e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7297e-01 -4.0393e-01 -2.5592e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.3878e+00  3.7942e+00  2.0147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9117e+00 -5.3030e+00 -5.8586e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.9238e-01 -1.3379e+00 -3.2875e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7442e-01 -4.0014e-01 -2.5544e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7442e-01 -4.0014e-01 -2.5544e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7442e-01 -4.0014e-01 -2.5544e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.3650e+00  3.7675e+00  1.9786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9023e+00 -5.2949e+00 -5.8540e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.9142e-01 -1.3345e+00 -3.2835e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7600e-01 -3.9599e-01 -2.5495e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7600e-01 -3.9599e-01 -2.5495e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7600e-01 -3.9599e-01 -2.5495e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.3650e+00  3.7675e+00  1.9786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9023e+00 -5.2949e+00 -5.8540e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.9142e-01 -1.3345e+00 -3.2835e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7600e-01 -3.9599e-01 -2.5495e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7600e-01 -3.9599e-01 -2.5495e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7600e-01 -3.9599e-01 -2.5495e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.3572e+00  3.7540e+00  1.9549e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8984e+00 -5.2937e+00 -5.8541e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.9431e-01 -1.3427e+00 -3.2930e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7245e-01 -4.0529e-01 -2.5611e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7245e-01 -4.0529e-01 -2.5611e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7245e-01 -4.0529e-01 -2.5611e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  4.2459e+00  3.6134e+00  1.7543e+00  ...   3.4020e-01  3.3180e-01  3.7133e-03
 -4.8594e+00 -5.2648e+00 -5.8387e+00  ...  -5.9930e+00 -5.9810e+00 -6.0415e+00
 -2.9635e-01 -1.3483e+00 -3.2989e+00  ...  -4.0304e+00 -3.9949e+00 -4.2220e+00
                 ...                   ⋱                   ...                
  6.7001e-01 -4.1172e-01 -2.5686e+00  ...  -3.4821e+00 -3.4496e+00 -3.7062e+00
  6.7001e-01 -4.1172e-01 -2.5686e+00  ...  -3.4821e+00 -3.4496e+00 -3.7062e+00
  6.7001e-01 -4.1172e-01 -2.5686e+00  ...  -3.4821e+00 -3.4496e+00 -3.7062e+00

( 4 ,.,.) = 
  4.2551e+00  3.6278e+00  1.7783e+00  ...   2.5369e-01 -7.2416e-02 -1.0000e+02
 -4.8675e+00 -5.2699e+00 -5.8411e+00  ...  -5.9956e+00 -6.0551e+00 -1.0000e+02
 -2.9343e-01 -1.3419e+00 -3.2917e+00  ...  -4.0430e+00 -4.2693e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7228e-01 -4.0575e-01 -2.5613e+00  ...  -3.5078e+00 -3.7631e+00 -1.0000e+02
  6.7228e-01 -4.0575e-01 -2.5613e+00  ...  -3.5078e+00 -3.7631e+00 -1.0000e+02
  6.7228e-01 -4.0575e-01 -2.5613e+00  ...  -3.5078e+00 -3.7631e+00 -1.0000e+02

( 5 ,.,.) = 
  4.3502e+00  3.7470e+00  1.9473e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9027e+00 -5.2965e+00 -5.8553e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -2.9070e-01 -1.3374e+00 -3.2877e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.7370e-01 -4.0213e-01 -2.5571e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7370e-01 -4.0213e-01 -2.5571e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7370e-01 -4.0213e-01 -2.5571e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 17 @ 2018-04-12 20:36:28.462803
training
gt_where_seq [[7, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.9994e+00  3.5243e+00  1.8888e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2119e-01 -5.7063e-02 -2.0311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2119e-01 -5.7063e-02 -2.0311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.2119e-01 -5.7063e-02 -2.0311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2119e-01 -5.7063e-02 -2.0311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2119e-01 -5.7063e-02 -2.0311e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  4.2934e+00  3.8960e+00  2.3257e+00  ...   6.3505e-01  1.2206e-01 -1.0000e+02
  7.9282e-01  7.0796e-02 -1.9813e+00  ...  -3.2022e+00 -3.6082e+00 -1.0000e+02
  7.9282e-01  7.0796e-02 -1.9813e+00  ...  -3.2022e+00 -3.6082e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  7.9282e-01  7.0796e-02 -1.9813e+00  ...  -3.2022e+00 -3.6082e+00 -1.0000e+02
  7.9282e-01  7.0796e-02 -1.9813e+00  ...  -3.2022e+00 -3.6082e+00 -1.0000e+02
  7.9282e-01  7.0796e-02 -1.9813e+00  ...  -3.2022e+00 -3.6082e+00 -1.0000e+02

(2 ,.,.) = 
  4.2621e+00  3.6908e+00  2.0537e+00  ...   2.6785e-01 -1.0000e+02 -1.0000e+02
 -4.7721e+00 -5.1664e+00 -5.7415e+00  ...  -5.9756e+00 -1.0000e+02 -1.0000e+02
 -2.0863e-01 -1.1785e+00 -3.0081e+00  ...  -4.0222e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.1819e-01 -3.7341e-01 -2.3533e+00  ...  -3.5745e+00 -1.0000e+02 -1.0000e+02
  6.1819e-01 -3.7341e-01 -2.3533e+00  ...  -3.5745e+00 -1.0000e+02 -1.0000e+02
  6.1819e-01 -3.7341e-01 -2.3533e+00  ...  -3.5745e+00 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  4.3073e+00  3.8198e+00  2.3935e+00  ...   1.1022e-01 -8.6602e-02 -1.4963e-01
  7.3569e-01 -1.3916e-01 -2.0048e+00  ...  -3.6764e+00 -3.8096e+00 -3.8496e+00
  7.3569e-01 -1.3916e-01 -2.0048e+00  ...  -3.6764e+00 -3.8096e+00 -3.8496e+00
                 ...                   ⋱                   ...                
  7.3569e-01 -1.3916e-01 -2.0048e+00  ...  -3.6764e+00 -3.8096e+00 -3.8496e+00
  7.3569e-01 -1.3916e-01 -2.0048e+00  ...  -3.6764e+00 -3.8096e+00 -3.8496e+00
  7.3569e-01 -1.3916e-01 -2.0048e+00  ...  -3.6764e+00 -3.8096e+00 -3.8496e+00

(13,.,.) = 
  4.2853e+00  3.8564e+00  2.2681e+00  ...   3.0837e-01 -1.0107e-01 -4.9671e-01
  8.5310e-01  6.8776e-02 -1.9916e+00  ...  -3.4286e+00 -3.7039e+00 -3.9641e+00
  8.5310e-01  6.8776e-02 -1.9916e+00  ...  -3.4286e+00 -3.7039e+00 -3.9641e+00
                 ...                   ⋱                   ...                
  8.5310e-01  6.8776e-02 -1.9916e+00  ...  -3.4286e+00 -3.7039e+00 -3.9641e+00
  8.5310e-01  6.8776e-02 -1.9916e+00  ...  -3.4286e+00 -3.7039e+00 -3.9641e+00
  8.5310e-01  6.8776e-02 -1.9916e+00  ...  -3.4286e+00 -3.7039e+00 -3.9641e+00

(14,.,.) = 
  4.4330e+00  3.9315e+00  2.4251e+00  ...   1.2217e+00  6.9696e-01  2.4604e-01
 -4.7829e+00 -5.1557e+00 -5.7261e+00  ...  -5.8761e+00 -5.9495e+00 -6.0353e+00
 -1.4577e-01 -1.0669e+00 -2.8883e+00  ...  -3.5819e+00 -3.8812e+00 -4.2034e+00
                 ...                   ⋱                   ...                
  1.0773e+00  1.4697e-01 -1.8640e+00  ...  -2.7641e+00 -3.1330e+00 -3.5086e+00
  7.8771e-01 -1.4872e-01 -2.1261e+00  ...  -2.9946e+00 -3.3485e+00 -3.7091e+00
  7.8771e-01 -1.4872e-01 -2.1261e+00  ...  -2.9946e+00 -3.3485e+00 -3.7091e+00
[torch.cuda.FloatTensor of size 15x9x59 (GPU 0)]

gt_where_seq [[7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.2988e+00  3.6970e+00  1.9918e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.6895e+00 -5.1214e+00 -5.7373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  6.7287e-02 -9.5721e-01 -2.8781e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2767e+00  2.4986e-01 -1.8550e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2574e+00  2.2823e-01 -1.8798e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.7501e-01 -1.6398e-01 -2.2263e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.7046e+00  3.0937e+00  1.3885e+00  ...   5.5033e-02 -6.1203e-01 -1.0000e+02
 -4.4554e+00 -4.8765e+00 -5.5436e+00  ...  -5.7409e+00 -5.8869e+00 -1.0000e+02
  1.3867e-01 -7.4821e-01 -2.5520e+00  ...  -3.3414e+00 -3.8111e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3450e+00  4.6595e-01 -1.4845e+00  ...  -2.4827e+00 -3.0277e+00 -1.0000e+02
  1.3572e+00  4.7752e-01 -1.4783e+00  ...  -2.4866e+00 -3.0335e+00 -1.0000e+02
  1.1384e+00  2.5091e-01 -1.6900e+00  ...  -2.6664e+00 -3.2005e+00 -1.0000e+02

(2 ,.,.) = 
  4.5959e+00  4.2098e+00  2.8211e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7209e-01 -1.1107e-02 -1.9969e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7209e-01 -1.1107e-02 -1.9969e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.7209e-01 -1.1107e-02 -1.9969e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7209e-01 -1.1107e-02 -1.9969e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.7209e-01 -1.1107e-02 -1.9969e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  4.4278e+00  3.9736e+00  2.2262e+00  ...   6.5222e-01 -1.0000e+02 -1.0000e+02
  6.3310e-01 -2.2637e-01 -2.4349e+00  ...  -3.5172e+00 -1.0000e+02 -1.0000e+02
  6.3310e-01 -2.2637e-01 -2.4349e+00  ...  -3.5172e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  6.3310e-01 -2.2637e-01 -2.4349e+00  ...  -3.5172e+00 -1.0000e+02 -1.0000e+02
  6.3310e-01 -2.2637e-01 -2.4349e+00  ...  -3.5172e+00 -1.0000e+02 -1.0000e+02
  6.3310e-01 -2.2637e-01 -2.4349e+00  ...  -3.5172e+00 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  4.0153e+00  3.4983e+00  1.7360e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.5898e+00 -4.9615e+00 -5.6385e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -1.4999e-02 -8.3404e-01 -2.7714e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  7.4884e-01 -7.9007e-02 -2.1444e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4884e-01 -7.9007e-02 -2.1444e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.4884e-01 -7.9007e-02 -2.1444e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  4.3539e+00  3.9485e+00  2.3958e+00  ...  -1.7580e-01 -1.0000e+02 -1.0000e+02
  8.7591e-01  1.1655e-01 -1.9482e+00  ...  -3.8104e+00 -1.0000e+02 -1.0000e+02
  8.7591e-01  1.1655e-01 -1.9482e+00  ...  -3.8104e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.7591e-01  1.1655e-01 -1.9482e+00  ...  -3.8104e+00 -1.0000e+02 -1.0000e+02
  8.7591e-01  1.1655e-01 -1.9482e+00  ...  -3.8104e+00 -1.0000e+02 -1.0000e+02
  8.7591e-01  1.1655e-01 -1.9482e+00  ...  -3.8104e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x8x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 22, 0, 55, 1], [7, 0, 0, 0, 60, 1], [7, 0, 8, 0, 55, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.4269e+00  4.0711e+00  2.6883e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0493e-01  1.2108e-01 -1.7896e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0493e-01  1.2108e-01 -1.7896e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  8.0493e-01  1.2108e-01 -1.7896e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0493e-01  1.2108e-01 -1.7896e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0493e-01  1.2108e-01 -1.7896e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  4.2425e+00  3.8609e+00  2.5245e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0124e+00  3.2990e-01 -1.4685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0124e+00  3.2990e-01 -1.4685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.0124e+00  3.2990e-01 -1.4685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0124e+00  3.2990e-01 -1.4685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0124e+00  3.2990e-01 -1.4685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  4.7921e+00  4.5072e+00  3.3886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.4377e-01  2.8904e-01 -1.5419e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.4377e-01  2.8904e-01 -1.5419e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.4377e-01  2.8904e-01 -1.5419e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.4377e-01  2.8904e-01 -1.5419e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.4377e-01  2.8904e-01 -1.5419e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  4.3848e+00  4.0399e+00  2.5330e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9687e+00 -5.2132e+00 -5.7831e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  4.2983e-01 -2.2608e-01 -2.2135e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.8233e-01  3.2546e-01 -1.7373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.8233e-01  3.2546e-01 -1.7373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.8233e-01  3.2546e-01 -1.7373e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  4.0627e+00  3.6458e+00  1.9522e+00  ...   3.7294e-01 -2.8146e-01 -1.7800e-01
 -4.8585e+00 -5.1354e+00 -5.7411e+00  ...  -5.9570e+00 -6.0513e+00 -6.0404e+00
  2.5292e-01 -4.3835e-01 -2.4232e+00  ...  -3.4531e+00 -3.8743e+00 -3.8178e+00
                 ...                   ⋱                   ...                
  9.2872e-01  2.3653e-01 -1.8447e+00  ...  -3.0318e+00 -3.4983e+00 -3.4350e+00
  9.2872e-01  2.3653e-01 -1.8447e+00  ...  -3.0318e+00 -3.4983e+00 -3.4350e+00
  9.2872e-01  2.3653e-01 -1.8447e+00  ...  -3.0318e+00 -3.4983e+00 -3.4350e+00

(14,.,.) = 
  4.4024e+00  4.1703e+00  2.9048e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8426e+00 -5.0346e+00 -5.6243e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  3.7504e-01 -8.3032e-02 -1.8816e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  9.7096e-01  5.1437e-01 -1.3418e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.7096e-01  5.1437e-01 -1.3418e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  9.7096e-01  5.1437e-01 -1.3418e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    4.1353    3.7494    2.2555  ...    -0.0875 -100.0000 -100.0000
   -4.9941   -5.2424   -5.7712  ...    -6.0874 -100.0000 -100.0000
    0.5758   -0.0874   -1.9542  ...    -3.6076 -100.0000 -100.0000
    0.4552   -0.2072   -2.0576  ...    -3.6744 -100.0000 -100.0000
    1.0329    0.3743   -1.5321  ...    -3.3006 -100.0000 -100.0000

(1 ,.,.) = 
    4.4451    4.1682    3.0508  ...  -100.0000 -100.0000 -100.0000
    1.1245    0.5781   -1.1004  ...  -100.0000 -100.0000 -100.0000
    1.1245    0.5781   -1.1004  ...  -100.0000 -100.0000 -100.0000
    1.1245    0.5781   -1.1004  ...  -100.0000 -100.0000 -100.0000
    1.1245    0.5781   -1.1004  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    4.8560    4.7260    3.9617  ...     0.9772    0.5721    0.4796
    1.1419    0.7990   -0.6594  ...    -3.4925   -3.7649   -3.8526
    1.1419    0.7990   -0.6594  ...    -3.4925   -3.7649   -3.8526
    1.1419    0.7990   -0.6594  ...    -3.4925   -3.7649   -3.8526
    1.1419    0.7990   -0.6594  ...    -3.4925   -3.7649   -3.8526

(3 ,.,.) = 
    4.5584    4.3631    3.4014  ...     0.7794    0.0640 -100.0000
    1.1838    0.7727   -0.7913  ...    -3.1161   -3.6720 -100.0000
    1.1838    0.7727   -0.7913  ...    -3.1161   -3.6720 -100.0000
    1.1838    0.7727   -0.7913  ...    -3.1161   -3.6720 -100.0000
    1.1838    0.7727   -0.7913  ...    -3.1161   -3.6720 -100.0000

(4 ,.,.) = 
    4.4205    4.1046    2.7829  ...    -0.0236 -100.0000 -100.0000
    1.0794    0.4672   -1.4208  ...    -3.6292 -100.0000 -100.0000
    1.0794    0.4672   -1.4208  ...    -3.6292 -100.0000 -100.0000
    1.0794    0.4672   -1.4208  ...    -3.6292 -100.0000 -100.0000
    1.0794    0.4672   -1.4208  ...    -3.6292 -100.0000 -100.0000

(5 ,.,.) = 
    4.5899    4.2090    2.8569  ...     0.2887    0.5183 -100.0000
    1.0319    0.2744   -1.6745  ...    -3.6377   -3.5048 -100.0000
    1.0319    0.2744   -1.6745  ...    -3.6377   -3.5048 -100.0000
    1.0319    0.2744   -1.6745  ...    -3.6377   -3.5048 -100.0000
    1.0319    0.2744   -1.6745  ...    -3.6377   -3.5048 -100.0000
[torch.cuda.FloatTensor of size 6x5x59 (GPU 0)]

 Loss = 4.39042139053
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.5683e+00  4.3413e+00  3.1914e+00  ...   9.2874e-01  3.4950e-01 -1.0000e+02
 -5.0323e+00 -5.2129e+00 -5.7272e+00  ...  -6.0525e+00 -6.1445e+00 -1.0000e+02
  7.8862e-01  3.0912e-01 -1.4487e+00  ...  -3.2231e+00 -3.6759e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2090e+00  7.3269e-01 -1.0577e+00  ...  -2.9754e+00 -3.4509e+00 -1.0000e+02
  1.2090e+00  7.3269e-01 -1.0577e+00  ...  -2.9754e+00 -3.4509e+00 -1.0000e+02
  1.2090e+00  7.3269e-01 -1.0577e+00  ...  -2.9754e+00 -3.4509e+00 -1.0000e+02

( 1 ,.,.) = 
  4.5795e+00  4.3543e+00  3.2113e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0350e+00 -5.2147e+00 -5.7276e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9238e-01  3.1453e-01 -1.4405e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2095e+00  7.3479e-01 -1.0525e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2095e+00  7.3479e-01 -1.0525e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2095e+00  7.3479e-01 -1.0525e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.8374e+00  4.6402e+00  3.6151e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1101e+00 -5.2823e+00 -5.7710e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.3651e-01  3.5757e-01 -1.4034e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2090e+00  7.3265e-01 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2090e+00  7.3265e-01 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2090e+00  7.3265e-01 -1.0578e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.9286e+00  4.7419e+00  3.7627e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1106e+00 -5.2827e+00 -5.7711e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.3831e-01  3.6011e-01 -1.4002e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2092e+00  7.3351e-01 -1.0557e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3351e-01 -1.0557e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3351e-01 -1.0557e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.9111e+00  4.7231e+00  3.7374e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1290e+00 -5.2986e+00 -5.7807e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.4480e-01  3.6766e-01 -1.3910e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2095e+00  7.3485e-01 -1.0524e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2095e+00  7.3485e-01 -1.0524e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2095e+00  7.3485e-01 -1.0524e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.7382e+00  4.5307e+00  3.4613e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0969e+00 -5.2700e+00 -5.7627e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2063e-01  3.4288e-01 -1.4143e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2094e+00  7.3450e-01 -1.0532e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2094e+00  7.3450e-01 -1.0532e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2094e+00  7.3450e-01 -1.0532e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.6523e+00  4.4348e+00  3.3237e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0713e+00 -5.2475e+00 -5.7489e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0727e-01  3.2852e-01 -1.4294e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2092e+00  7.3341e-01 -1.0560e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3341e-01 -1.0560e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3341e-01 -1.0560e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.4439e+00  4.2046e+00  3.0044e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9979e+00 -5.1816e+00 -5.7067e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.6483e-01  2.8674e-01 -1.4666e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2095e+00  7.3485e-01 -1.0524e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2095e+00  7.3485e-01 -1.0524e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2095e+00  7.3485e-01 -1.0524e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.5820e+00  4.3569e+00  3.2144e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0423e+00 -5.2216e+00 -5.7324e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9074e-01  3.1194e-01 -1.4448e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2092e+00  7.3359e-01 -1.0556e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3359e-01 -1.0556e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3359e-01 -1.0556e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.8222e+00  4.6233e+00  3.5909e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1083e+00 -5.2806e+00 -5.7699e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.3528e-01  3.5638e-01 -1.4043e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2090e+00  7.3272e-01 -1.0576e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2090e+00  7.3272e-01 -1.0576e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2090e+00  7.3272e-01 -1.0576e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.9489e+00  3.6583e+00  2.2666e+00  ...   6.4832e-01 -1.6418e-01 -1.0000e+02
 -4.6925e+00 -4.9087e+00 -5.5326e+00  ...  -5.7887e+00 -5.9660e+00 -1.0000e+02
  6.4869e-01  1.6862e-01 -1.5793e+00  ...  -2.7504e+00 -3.3923e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2092e+00  7.3356e-01 -1.0556e+00  ...  -2.3572e+00 -3.0414e+00 -1.0000e+02
  1.2092e+00  7.3356e-01 -1.0556e+00  ...  -2.3572e+00 -3.0414e+00 -1.0000e+02
  1.2092e+00  7.3356e-01 -1.0556e+00  ...  -2.3572e+00 -3.0414e+00 -1.0000e+02

(14 ,.,.) = 
  4.5627e+00  4.3347e+00  3.1810e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0142e+00 -5.1966e+00 -5.7166e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9406e-01  3.1496e-01 -1.4426e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2091e+00  7.3310e-01 -1.0567e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2091e+00  7.3310e-01 -1.0567e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2091e+00  7.3310e-01 -1.0567e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.5762e+00  4.3511e+00  3.2083e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0375e+00 -5.2167e+00 -5.7286e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9217e-01  3.1488e-01 -1.4391e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2097e+00  7.3552e-01 -1.0507e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2097e+00  7.3552e-01 -1.0507e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2097e+00  7.3552e-01 -1.0507e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.8418e+00  4.6451e+00  3.6221e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1109e+00 -5.2831e+00 -5.7715e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.3679e-01  3.5783e-01 -1.4033e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2090e+00  7.3260e-01 -1.0579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2090e+00  7.3260e-01 -1.0579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2090e+00  7.3260e-01 -1.0579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.7396e+00  4.5316e+00  3.4604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0873e+00 -5.2618e+00 -5.7579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.1971e-01  3.4091e-01 -1.4182e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2091e+00  7.3312e-01 -1.0566e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2091e+00  7.3312e-01 -1.0566e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2091e+00  7.3312e-01 -1.0566e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.3019e+00  4.0480e+00  2.7908e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9109e+00 -5.1038e+00 -5.6571e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.2700e-01  2.4898e-01 -1.5012e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2096e+00  7.3540e-01 -1.0510e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2096e+00  7.3540e-01 -1.0510e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2096e+00  7.3540e-01 -1.0510e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.4129e+00  4.1704e+00  2.9575e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9770e+00 -5.1629e+00 -5.6948e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.5687e-01  2.7892e-01 -1.4735e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2096e+00  7.3513e-01 -1.0517e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2096e+00  7.3513e-01 -1.0517e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2096e+00  7.3513e-01 -1.0517e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.6928e+00  4.4797e+00  3.3866e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0679e+00 -5.2444e+00 -5.7468e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.2102e-01  3.4247e-01 -1.4163e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2092e+00  7.3343e-01 -1.0558e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3343e-01 -1.0558e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3343e-01 -1.0558e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.6632e+00  4.4466e+00  3.3394e+00  ...   1.3480e+00  7.7177e-01  3.1470e-01
 -5.0640e+00 -5.2412e+00 -5.7451e+00  ...  -6.0443e+00 -6.1088e+00 -6.1772e+00
  8.0657e-01  3.2721e-01 -1.4318e+00  ...  -3.0835e+00 -3.4541e+00 -3.8090e+00
                 ...                   ⋱                   ...                
  1.2090e+00  7.3258e-01 -1.0579e+00  ...  -2.8361e+00 -3.2340e+00 -3.6051e+00
  1.2090e+00  7.3258e-01 -1.0579e+00  ...  -2.8361e+00 -3.2340e+00 -3.6051e+00
  1.2090e+00  7.3258e-01 -1.0579e+00  ...  -2.8361e+00 -3.2340e+00 -3.6051e+00

( 1 ,.,.) = 
  4.6560e+00  4.4391e+00  3.3301e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0646e+00 -5.2414e+00 -5.7448e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.0317e-01  3.2472e-01 -1.4323e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2093e+00  7.3384e-01 -1.0549e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2093e+00  7.3384e-01 -1.0549e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2093e+00  7.3384e-01 -1.0549e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.6036e+00  4.3814e+00  3.2502e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0479e+00 -5.2263e+00 -5.7351e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9037e-01  3.1225e-01 -1.4431e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2094e+00  7.3448e-01 -1.0533e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2094e+00  7.3448e-01 -1.0533e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2094e+00  7.3448e-01 -1.0533e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  4.7046e+00  4.4923e+00  3.4029e+00  ...  -3.2560e-01 -7.1095e-01  2.7654e-01
 -5.0702e+00 -5.2468e+00 -5.7487e+00  ...  -6.2430e+00 -6.2696e+00 -6.1924e+00
  8.1893e-01  3.3948e-01 -1.4208e+00  ...  -4.2333e+00 -4.4177e+00 -3.8849e+00
                 ...                   ⋱                   ...                
  1.2089e+00  7.3228e-01 -1.0587e+00  ...  -4.0648e+00 -4.2640e+00 -3.6936e+00
  1.2089e+00  7.3228e-01 -1.0587e+00  ...  -4.0648e+00 -4.2640e+00 -3.6936e+00
  1.2089e+00  7.3228e-01 -1.0587e+00  ...  -4.0648e+00 -4.2640e+00 -3.6936e+00

( 4 ,.,.) = 
  4.2234e+00  3.9599e+00  2.6673e+00  ...   1.7316e-01 -1.0000e+02 -1.0000e+02
 -4.8643e+00 -5.0626e+00 -5.6313e+00  ...  -6.0376e+00 -1.0000e+02 -1.0000e+02
  7.1470e-01  2.3517e-01 -1.5168e+00  ...  -3.4227e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2092e+00  7.3352e-01 -1.0556e+00  ...  -3.1252e+00 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3352e-01 -1.0556e+00  ...  -3.1252e+00 -1.0000e+02 -1.0000e+02
  1.2092e+00  7.3352e-01 -1.0556e+00  ...  -3.1252e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  4.0136e+00  3.7296e+00  2.3611e+00  ...  -6.7461e-02 -1.0000e+02 -1.0000e+02
 -4.7368e+00 -4.9482e+00 -5.5577e+00  ...  -5.9815e+00 -1.0000e+02 -1.0000e+02
  6.6512e-01  1.8567e-01 -1.5624e+00  ...  -3.3849e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2093e+00  7.3419e-01 -1.0540e+00  ...  -3.0459e+00 -1.0000e+02 -1.0000e+02
  1.2093e+00  7.3419e-01 -1.0540e+00  ...  -3.0459e+00 -1.0000e+02 -1.0000e+02
  1.2093e+00  7.3419e-01 -1.0540e+00  ...  -3.0459e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
    4.8087    4.5489    3.3254  ...  -100.0000 -100.0000 -100.0000
   -5.1306   -5.3410   -5.8495  ...  -100.0000 -100.0000 -100.0000
    0.7767    0.1761   -1.7706  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1532    0.5545   -1.4345  ...  -100.0000 -100.0000 -100.0000
    1.1532    0.5545   -1.4345  ...  -100.0000 -100.0000 -100.0000
    1.1532    0.5545   -1.4345  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    4.6672    4.3872    3.0871  ...  -100.0000 -100.0000 -100.0000
   -5.0603   -5.2799   -5.8128  ...  -100.0000 -100.0000 -100.0000
    0.7627    0.1626   -1.7818  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1534    0.5555   -1.4323  ...  -100.0000 -100.0000 -100.0000
    1.1534    0.5555   -1.4323  ...  -100.0000 -100.0000 -100.0000
    1.1534    0.5555   -1.4323  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    4.8791    4.6275    3.4369  ...  -100.0000 -100.0000 -100.0000
   -5.1363   -5.3473   -5.8546  ...  -100.0000 -100.0000 -100.0000
    0.7808    0.1764   -1.7767  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1517    0.5491   -1.4459  ...  -100.0000 -100.0000 -100.0000
    1.1517    0.5491   -1.4459  ...  -100.0000 -100.0000 -100.0000
    1.1517    0.5491   -1.4459  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    4.7380    4.4683    3.2069  ...  -100.0000 -100.0000 -100.0000
   -5.1106   -5.3236   -5.8392  ...  -100.0000 -100.0000 -100.0000
    0.7644    0.1638   -1.7813  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1533    0.5548   -1.4339  ...  -100.0000 -100.0000 -100.0000
    1.1533    0.5548   -1.4339  ...  -100.0000 -100.0000 -100.0000
    1.1533    0.5548   -1.4339  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    4.8928    4.6441    3.4643  ...  -100.0000 -100.0000 -100.0000
   -5.1425   -5.3520   -5.8568  ...  -100.0000 -100.0000 -100.0000
    0.7843    0.1817   -1.7690  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1524    0.5516   -1.4405  ...  -100.0000 -100.0000 -100.0000
    1.1524    0.5516   -1.4405  ...  -100.0000 -100.0000 -100.0000
    1.1524    0.5516   -1.4405  ...  -100.0000 -100.0000 -100.0000

(14 ,.,.) = 
    4.8087    4.5489    3.3254  ...  -100.0000 -100.0000 -100.0000
   -5.1306   -5.3410   -5.8495  ...  -100.0000 -100.0000 -100.0000
    0.7767    0.1761   -1.7706  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1532    0.5545   -1.4345  ...  -100.0000 -100.0000 -100.0000
    1.1532    0.5545   -1.4345  ...  -100.0000 -100.0000 -100.0000
    1.1532    0.5545   -1.4345  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    4.7815    4.5189    3.2836  ...  -100.0000 -100.0000 -100.0000
   -5.1213   -5.3324   -5.8438  ...  -100.0000 -100.0000 -100.0000
    0.7697    0.1709   -1.7721  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1539    0.5572   -1.4288  ...  -100.0000 -100.0000 -100.0000
    1.1539    0.5572   -1.4288  ...  -100.0000 -100.0000 -100.0000
    1.1539    0.5572   -1.4288  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    4.7815    4.5189    3.2836  ...  -100.0000 -100.0000 -100.0000
   -5.1213   -5.3324   -5.8438  ...  -100.0000 -100.0000 -100.0000
    0.7697    0.1709   -1.7721  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1539    0.5572   -1.4288  ...  -100.0000 -100.0000 -100.0000
    1.1539    0.5572   -1.4288  ...  -100.0000 -100.0000 -100.0000
    1.1539    0.5572   -1.4288  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    4.7725    4.5062    3.2584  ...  -100.0000 -100.0000 -100.0000
   -5.1163   -5.3296   -5.8437  ...  -100.0000 -100.0000 -100.0000
    0.7649    0.1613   -1.7884  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1521    0.5506   -1.4429  ...  -100.0000 -100.0000 -100.0000
    1.1521    0.5506   -1.4429  ...  -100.0000 -100.0000 -100.0000
    1.1521    0.5506   -1.4429  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    4.6375    4.3505    3.0261  ...     0.9899    0.9318    0.4361
   -5.0727   -5.2929   -5.8230  ...    -6.0931   -6.0851   -6.1610
    0.7407    0.1338   -1.8181  ...    -3.3661   -3.3542   -3.7395
              ...                ⋱                ...             
    1.1510    0.5464   -1.4517  ...    -3.1282   -3.1217   -3.5256
    1.1510    0.5464   -1.4517  ...    -3.1282   -3.1217   -3.5256
    1.1510    0.5464   -1.4517  ...    -3.1282   -3.1217   -3.5256

( 4 ,.,.) = 
    4.6618    4.3800    3.0742  ...     0.8368    0.3388 -100.0000
   -5.0871   -5.3044   -5.8289  ...    -6.1056   -6.1794 -100.0000
    0.7417    0.1379   -1.8095  ...    -3.4432   -3.8276 -100.0000
              ...                ⋱                ...             
    1.1522    0.5506   -1.4428  ...    -3.2177   -3.6203 -100.0000
    1.1522    0.5506   -1.4428  ...    -3.2177   -3.6203 -100.0000
    1.1522    0.5506   -1.4428  ...    -3.2177   -3.6203 -100.0000

( 5 ,.,.) = 
    4.7603    4.4934    3.2428  ...  -100.0000 -100.0000 -100.0000
   -5.1226   -5.3344   -5.8460  ...  -100.0000 -100.0000 -100.0000
    0.7653    0.1636   -1.7834  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1529    0.5532   -1.4374  ...  -100.0000 -100.0000 -100.0000
    1.1529    0.5532   -1.4374  ...  -100.0000 -100.0000 -100.0000
    1.1529    0.5532   -1.4374  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 18 @ 2018-04-12 20:36:30.930985
training
gt_where_seq [[7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    4.0965    3.8818    2.8424  ...  -100.0000 -100.0000 -100.0000
   -4.8696   -5.0294   -5.5242  ...  -100.0000 -100.0000 -100.0000
    0.7265    0.3475   -1.1061  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1765    0.8007   -0.6756  ...  -100.0000 -100.0000 -100.0000
    1.1765    0.8007   -0.6756  ...  -100.0000 -100.0000 -100.0000
    1.1765    0.8007   -0.6756  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    4.5169    4.2607    3.1105  ...  -100.0000 -100.0000 -100.0000
    1.0519    0.5207   -1.2293  ...  -100.0000 -100.0000 -100.0000
    1.0519    0.5207   -1.2293  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.0519    0.5207   -1.2293  ...  -100.0000 -100.0000 -100.0000
    1.0519    0.5207   -1.2293  ...  -100.0000 -100.0000 -100.0000
    1.0519    0.5207   -1.2293  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    4.8517    4.7054    3.6284  ...  -100.0000 -100.0000 -100.0000
    1.1542    0.7777   -1.1218  ...  -100.0000 -100.0000 -100.0000
    1.1542    0.7777   -1.1218  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1542    0.7777   -1.1218  ...  -100.0000 -100.0000 -100.0000
    1.1542    0.7777   -1.1218  ...  -100.0000 -100.0000 -100.0000
    1.1542    0.7777   -1.1218  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    4.6499    4.4981    3.5214  ...  -100.0000 -100.0000 -100.0000
    1.1613    0.8052   -0.8446  ...  -100.0000 -100.0000 -100.0000
    1.1613    0.8052   -0.8446  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1613    0.8052   -0.8446  ...  -100.0000 -100.0000 -100.0000
    1.1613    0.8052   -0.8446  ...  -100.0000 -100.0000 -100.0000
    1.1613    0.8052   -0.8446  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    4.4688    4.3688    3.3162  ...  -100.0000 -100.0000 -100.0000
    0.9429    0.7175   -0.9625  ...  -100.0000 -100.0000 -100.0000
    0.9429    0.7175   -0.9625  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    0.9429    0.7175   -0.9625  ...  -100.0000 -100.0000 -100.0000
    0.9429    0.7175   -0.9625  ...  -100.0000 -100.0000 -100.0000
    0.9429    0.7175   -0.9625  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    3.9426    3.7553    2.5204  ...  -100.0000 -100.0000 -100.0000
   -4.9491   -5.0764   -5.6053  ...  -100.0000 -100.0000 -100.0000
    0.7992    0.4767   -1.1546  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5383    1.2238   -0.4216  ...  -100.0000 -100.0000 -100.0000
    1.5923    1.2788   -0.3696  ...  -100.0000 -100.0000 -100.0000
    1.2364    0.9160   -0.7415  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x8x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.5387e+00  4.2812e+00  2.8102e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2107e+00  6.8981e-01 -1.4485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2107e+00  6.8981e-01 -1.4485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2107e+00  6.8981e-01 -1.4485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2107e+00  6.8981e-01 -1.4485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2107e+00  6.8981e-01 -1.4485e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  4.1112e+00  3.8908e+00  2.4732e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7714e+00 -4.9414e+00 -5.5851e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  8.9686e-01  5.0625e-01 -1.3600e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2430e+00  8.5627e-01 -1.0244e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5689e+00  1.1878e+00 -7.0187e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6451e+00  1.2656e+00 -6.2923e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  4.7346e+00  4.5715e+00  3.5826e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2629e+00  8.7455e-01 -8.3189e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2629e+00  8.7455e-01 -8.3189e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2629e+00  8.7455e-01 -8.3189e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2629e+00  8.7455e-01 -8.3189e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2629e+00  8.7455e-01 -8.3189e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.9550e+00  3.6430e+00  2.4365e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.7615e+00 -4.9849e+00 -5.5292e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  7.9185e-01  2.8286e-01 -1.2723e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1800e+00  6.7569e-01 -8.9563e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5619e+00  1.0659e+00 -5.1291e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5107e+00  1.0128e+00 -5.6988e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  4.5242e+00  4.3344e+00  3.2240e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1948e+00  7.9384e-01 -9.4755e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1948e+00  7.9384e-01 -9.4755e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1948e+00  7.9384e-01 -9.4755e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1948e+00  7.9384e-01 -9.4755e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1948e+00  7.9384e-01 -9.4755e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  4.4066e+00  4.0716e+00  2.8875e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1307e+00  4.9930e-01 -1.1946e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1307e+00  4.9930e-01 -1.1946e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1307e+00  4.9930e-01 -1.1946e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1307e+00  4.9930e-01 -1.1946e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1307e+00  4.9930e-01 -1.1946e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 0, 22, 0, 55, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 0, 22, 0, 53, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    4.0225    3.6935    2.2899  ...  -100.0000 -100.0000 -100.0000
    1.2828    0.7430   -1.0760  ...  -100.0000 -100.0000 -100.0000
    1.2828    0.7430   -1.0760  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2828    0.7430   -1.0760  ...  -100.0000 -100.0000 -100.0000
    1.2828    0.7430   -1.0760  ...  -100.0000 -100.0000 -100.0000
    1.2828    0.7430   -1.0760  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    4.4275    4.1715    3.0359  ...  -100.0000 -100.0000 -100.0000
    1.2371    0.7374   -0.9390  ...  -100.0000 -100.0000 -100.0000
    1.2371    0.7374   -0.9390  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2371    0.7374   -0.9390  ...  -100.0000 -100.0000 -100.0000
    1.2371    0.7374   -0.9390  ...  -100.0000 -100.0000 -100.0000
    1.2371    0.7374   -0.9390  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    3.7986    3.5610    2.1155  ...  -100.0000 -100.0000 -100.0000
   -4.7922   -4.9614   -5.5827  ...  -100.0000 -100.0000 -100.0000
    1.0329    0.6531   -1.1441  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5979    1.2264   -0.5892  ...  -100.0000 -100.0000 -100.0000
    1.3142    0.9363   -0.8844  ...  -100.0000 -100.0000 -100.0000
    1.3142    0.9363   -0.8844  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    3.7441    3.3778    1.5474  ...  -100.0000 -100.0000 -100.0000
   -5.0135   -5.2281   -5.8217  ...  -100.0000 -100.0000 -100.0000
    0.8210    0.2612   -1.8345  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5066    0.9581   -1.1956  ...  -100.0000 -100.0000 -100.0000
    1.0904    0.5308   -1.6042  ...  -100.0000 -100.0000 -100.0000
    1.0904    0.5308   -1.6042  ...  -100.0000 -100.0000 -100.0000

(13,.,.) = 
    4.4619    4.2853    3.1933  ...  -100.0000 -100.0000 -100.0000
    1.1224    0.7537   -0.9328  ...  -100.0000 -100.0000 -100.0000
    1.1224    0.7537   -0.9328  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1224    0.7537   -0.9328  ...  -100.0000 -100.0000 -100.0000
    1.1224    0.7537   -0.9328  ...  -100.0000 -100.0000 -100.0000
    1.1224    0.7537   -0.9328  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    3.7399    3.4893    2.1267  ...  -100.0000 -100.0000 -100.0000
    1.1936    0.7924   -0.9145  ...  -100.0000 -100.0000 -100.0000
    1.1936    0.7924   -0.9145  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1936    0.7924   -0.9145  ...  -100.0000 -100.0000 -100.0000
    1.1936    0.7924   -0.9145  ...  -100.0000 -100.0000 -100.0000
    1.1936    0.7924   -0.9145  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x9x63 (GPU 0)]

gt_where_seq [[7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.7578e+00  3.3537e+00  1.4426e+00  ...   5.1545e-01 -5.2893e-01 -1.0000e+02
 -4.7349e+00 -5.0036e+00 -5.7122e+00  ...  -5.7711e+00 -6.0008e+00 -1.0000e+02
  1.0015e+00  3.9817e-01 -1.7592e+00  ...  -2.2978e+00 -3.1450e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6045e+00  1.0129e+00 -1.1953e+00  ...  -1.8286e+00 -2.7301e+00 -1.0000e+02
  1.6030e+00  1.0109e+00 -1.2041e+00  ...  -1.8449e+00 -2.7501e+00 -1.0000e+02
  1.2819e+00  6.7967e-01 -1.5220e+00  ...  -2.1220e+00 -3.0025e+00 -1.0000e+02

(1 ,.,.) = 
  4.3526e+00  3.9176e+00  2.3208e+00  ...   3.3199e-01 -1.5157e-01 -1.0000e+02
  1.1148e+00  3.3002e-01 -1.7393e+00  ...  -3.1698e+00 -3.5734e+00 -1.0000e+02
  1.1148e+00  3.3002e-01 -1.7393e+00  ...  -3.1698e+00 -3.5734e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1148e+00  3.3002e-01 -1.7393e+00  ...  -3.1698e+00 -3.5734e+00 -1.0000e+02
  1.1148e+00  3.3002e-01 -1.7393e+00  ...  -3.1698e+00 -3.5734e+00 -1.0000e+02
  1.1148e+00  3.3002e-01 -1.7393e+00  ...  -3.1698e+00 -3.5734e+00 -1.0000e+02

(2 ,.,.) = 
  4.1222e+00  3.6828e+00  1.8833e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1755e+00  4.4435e-01 -1.7466e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1755e+00  4.4435e-01 -1.7466e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1755e+00  4.4435e-01 -1.7466e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1755e+00  4.4435e-01 -1.7466e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1755e+00  4.4435e-01 -1.7466e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(3 ,.,.) = 
  4.1640e+00  3.4979e+00  1.2474e+00  ...   8.3356e-01  4.7091e-01  1.6599e-01
  1.0054e+00 -7.4694e-02 -2.5454e+00  ...  -2.6709e+00 -2.9012e+00 -3.1965e+00
  1.0054e+00 -7.4694e-02 -2.5454e+00  ...  -2.6709e+00 -2.9012e+00 -3.1965e+00
                 ...                   ⋱                   ...                
  1.0054e+00 -7.4694e-02 -2.5454e+00  ...  -2.6709e+00 -2.9012e+00 -3.1965e+00
  1.0054e+00 -7.4694e-02 -2.5454e+00  ...  -2.6709e+00 -2.9012e+00 -3.1965e+00
  1.0054e+00 -7.4694e-02 -2.5454e+00  ...  -2.6709e+00 -2.9012e+00 -3.1965e+00

(4 ,.,.) = 
  4.3216e+00  4.0068e+00  2.4055e+00  ...  -3.5941e-01 -1.0000e+02 -1.0000e+02
  1.2052e+00  6.3071e-01 -1.5053e+00  ...  -3.6178e+00 -1.0000e+02 -1.0000e+02
  1.2052e+00  6.3071e-01 -1.5053e+00  ...  -3.6178e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2052e+00  6.3071e-01 -1.5053e+00  ...  -3.6178e+00 -1.0000e+02 -1.0000e+02
  1.2052e+00  6.3071e-01 -1.5053e+00  ...  -3.6178e+00 -1.0000e+02 -1.0000e+02
  1.2052e+00  6.3071e-01 -1.5053e+00  ...  -3.6178e+00 -1.0000e+02 -1.0000e+02

(5 ,.,.) = 
  3.9137e+00  3.4916e+00  1.5590e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2598e+00 -5.4756e+00 -5.9880e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0038e+00  3.4565e-01 -1.8715e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4803e+00  8.3103e-01 -1.4361e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0959e+00  4.3404e-01 -1.8125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0959e+00  4.3404e-01 -1.8125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x9x60 (GPU 0)]

 Loss = 4.31499209123
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.0201e+00  3.5982e+00  1.6097e+00  ...   4.0345e-01 -3.9140e-01 -1.0000e+02
 -5.2374e+00 -5.4676e+00 -6.0101e+00  ...  -6.0835e+00 -6.2048e+00 -1.0000e+02
  1.1568e+00  4.7684e-01 -1.8445e+00  ...  -2.5689e+00 -3.2253e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2564e+00  5.7357e-01 -1.7771e+00  ...  -2.5473e+00 -3.2143e+00 -1.0000e+02
  1.2564e+00  5.7357e-01 -1.7771e+00  ...  -2.5473e+00 -3.2143e+00 -1.0000e+02
  1.2564e+00  5.7357e-01 -1.7771e+00  ...  -2.5473e+00 -3.2143e+00 -1.0000e+02

( 1 ,.,.) = 
  4.0729e+00  3.6598e+00  1.6976e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2454e+00 -5.4733e+00 -6.0122e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1665e+00  4.9016e-01 -1.8279e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2574e+00  5.7790e-01 -1.7686e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2574e+00  5.7790e-01 -1.7686e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2574e+00  5.7790e-01 -1.7686e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.4875e+00  4.1334e+00  2.3693e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3539e+00 -5.5657e+00 -6.0617e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2459e+00  5.6860e-01 -1.7604e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2564e+00  5.7359e-01 -1.7770e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2564e+00  5.7359e-01 -1.7770e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2564e+00  5.7359e-01 -1.7770e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.6334e+00  4.3023e+00  2.6219e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3685e+00 -5.5776e+00 -6.0676e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2727e+00  5.9771e-01 -1.7319e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2568e+00  5.7540e-01 -1.7735e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2568e+00  5.7540e-01 -1.7735e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2568e+00  5.7540e-01 -1.7735e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.5858e+00  4.2490e+00  2.5459e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3789e+00 -5.5858e+00 -6.0716e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2689e+00  5.9570e-01 -1.7310e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2574e+00  5.7797e-01 -1.7685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2574e+00  5.7797e-01 -1.7685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2574e+00  5.7797e-01 -1.7685e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.3032e+00  3.9238e+00  2.0700e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3234e+00 -5.5393e+00 -6.0473e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2115e+00  5.3584e-01 -1.7866e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2572e+00  5.7724e-01 -1.7699e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2572e+00  5.7724e-01 -1.7699e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2572e+00  5.7724e-01 -1.7699e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    4.1067    3.6978    1.7489  ...  -100.0000 -100.0000 -100.0000
   -5.2741   -5.4982   -6.0260  ...  -100.0000 -100.0000 -100.0000
    1.1789    0.5008   -1.8209  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2568    0.5752   -1.7740  ...  -100.0000 -100.0000 -100.0000
    1.2568    0.5752   -1.7740  ...  -100.0000 -100.0000 -100.0000
    1.2568    0.5752   -1.7740  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    3.8105    3.3629    1.2983  ...  -100.0000 -100.0000 -100.0000
   -5.1823   -5.4200   -5.9841  ...  -100.0000 -100.0000 -100.0000
    1.1217    0.4443   -1.8697  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2574    0.5781   -1.7683  ...  -100.0000 -100.0000 -100.0000
    1.2574    0.5781   -1.7683  ...  -100.0000 -100.0000 -100.0000
    1.2574    0.5781   -1.7683  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    4.0098    3.5875    1.5973  ...  -100.0000 -100.0000 -100.0000
   -5.2405   -5.4698   -6.0109  ...  -100.0000 -100.0000 -100.0000
    1.1568    0.4784   -1.8412  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2569    0.5756   -1.7733  ...  -100.0000 -100.0000 -100.0000
    1.2569    0.5756   -1.7733  ...  -100.0000 -100.0000 -100.0000
    1.2569    0.5756   -1.7733  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    4.4623    4.1045    2.3270  ...  -100.0000 -100.0000 -100.0000
   -5.3500   -5.5624   -6.0599  ...  -100.0000 -100.0000 -100.0000
    1.2417    0.5643   -1.7641  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2564    0.5737   -1.7767  ...  -100.0000 -100.0000 -100.0000
    1.2564    0.5737   -1.7767  ...  -100.0000 -100.0000 -100.0000
    1.2564    0.5737   -1.7767  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    3.2488    2.7302    0.4891  ...     0.1356   -0.8675 -100.0000
   -4.8595   -5.1465   -5.8369  ...    -5.7716   -6.0006 -100.0000
    0.9810    0.2985   -2.0049  ...    -2.0651   -2.9141 -100.0000
              ...                ⋱                ...             
    1.2568    0.5755   -1.7734  ...    -1.8766   -2.7540 -100.0000
    1.2568    0.5755   -1.7734  ...    -1.8766   -2.7540 -100.0000
    1.2568    0.5755   -1.7734  ...    -1.8766   -2.7540 -100.0000

(14 ,.,.) = 
    4.0845    3.6708    1.7076  ...  -100.0000 -100.0000 -100.0000
   -5.2307   -5.4616   -6.0064  ...  -100.0000 -100.0000 -100.0000
    1.1707    0.4920   -1.8296  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2566    0.5746   -1.7751  ...  -100.0000 -100.0000 -100.0000
    1.2566    0.5746   -1.7751  ...  -100.0000 -100.0000 -100.0000
    1.2566    0.5746   -1.7751  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.0711e+00  3.6591e+00  1.6994e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2517e+00 -5.4783e+00 -6.0146e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1673e+00  4.9217e-01 -1.8244e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2577e+00  5.7941e-01 -1.7657e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2577e+00  5.7941e-01 -1.7657e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2577e+00  5.7941e-01 -1.7657e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.4914e+00  4.1380e+00  2.3759e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3547e+00 -5.5664e+00 -6.0620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2467e+00  5.6935e-01 -1.7598e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2564e+00  5.7348e-01 -1.7772e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2564e+00  5.7348e-01 -1.7772e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2564e+00  5.7348e-01 -1.7772e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.3352e+00  3.9588e+00  2.1165e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3210e+00 -5.5377e+00 -6.0468e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2125e+00  5.3482e-01 -1.7903e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2566e+00  5.7454e-01 -1.7751e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2566e+00  5.7454e-01 -1.7751e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2566e+00  5.7454e-01 -1.7751e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.6308e+00  3.1609e+00  1.0357e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0845e+00 -5.3370e+00 -5.9395e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.0714e+00  3.9370e-01 -1.9147e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2576e+00  5.7917e-01 -1.7661e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2576e+00  5.7917e-01 -1.7661e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2576e+00  5.7917e-01 -1.7661e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.7763e+00  3.3245e+00  1.2479e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1609e+00 -5.4018e+00 -5.9743e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1113e+00  4.3409e-01 -1.8784e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2575e+00  5.7862e-01 -1.7672e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2575e+00  5.7862e-01 -1.7672e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2575e+00  5.7862e-01 -1.7672e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.2542e+00  3.8661e+00  1.9843e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2949e+00 -5.5157e+00 -6.0350e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2080e+00  5.3075e-01 -1.7934e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2568e+00  5.7525e-01 -1.7738e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2568e+00  5.7525e-01 -1.7738e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2568e+00  5.7525e-01 -1.7738e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    4.1883    3.7901    1.8757  ...     0.8214    0.1637   -0.4575
   -5.2844   -5.5072   -6.0310  ...    -6.0987   -6.1682   -6.2522
    1.1873    0.5080   -1.8160  ...    -2.4732   -2.9364   -3.4406
              ...                ⋱                ...             
    1.2564    0.5734   -1.7773  ...    -2.4732   -2.9468   -3.4558
    1.2564    0.5734   -1.7773  ...    -2.4732   -2.9468   -3.4558
    1.2564    0.5734   -1.7773  ...    -2.4732   -2.9468   -3.4558

( 1 ,.,.) = 
    4.1851    3.7878    1.8753  ...  -100.0000 -100.0000 -100.0000
   -5.2859   -5.5079   -6.0310  ...  -100.0000 -100.0000 -100.0000
    1.1846    0.5073   -1.8140  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2570    0.5760   -1.7723  ...  -100.0000 -100.0000 -100.0000
    1.2570    0.5760   -1.7723  ...  -100.0000 -100.0000 -100.0000
    1.2570    0.5760   -1.7723  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    4.0725    3.6602    1.7002  ...  -100.0000 -100.0000 -100.0000
   -5.2570   -5.4833   -6.0178  ...  -100.0000 -100.0000 -100.0000
    1.1615    0.4845   -1.8336  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2572    0.5773   -1.7697  ...  -100.0000 -100.0000 -100.0000
    1.2572    0.5773   -1.7697  ...  -100.0000 -100.0000 -100.0000
    1.2572    0.5773   -1.7697  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    4.2769    3.8906    2.0158  ...    -0.9267   -1.3718   -0.4494
   -5.2982   -5.5190   -6.0372  ...    -6.3064   -6.3358   -6.2701
    1.2079    0.5288   -1.7976  ...    -3.8399   -4.0923   -3.5300
              ...                ⋱                ...             
    1.2562    0.5728   -1.7786  ...    -3.8726   -4.1276   -3.5610
    1.2562    0.5728   -1.7786  ...    -3.8726   -4.1276   -3.5610
    1.2562    0.5728   -1.7786  ...    -3.8726   -4.1276   -3.5610

( 4 ,.,.) = 
    3.5913    3.1132    0.9676  ...    -0.5745 -100.0000 -100.0000
   -5.0541   -5.3121   -5.9266  ...    -6.0922 -100.0000 -100.0000
    1.0650    0.3843   -1.9269  ...    -2.9691 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2568    0.5754   -1.7735  ...    -2.8798 -100.0000 -100.0000
    1.2568    0.5754   -1.7735  ...    -2.8798 -100.0000 -100.0000
    1.2568    0.5754   -1.7735  ...    -2.8798 -100.0000 -100.0000

( 5 ,.,.) = 
    3.3187    2.8089    0.5870  ...    -0.7796 -100.0000 -100.0000
   -4.9044   -5.1845   -5.8573  ...    -6.0169 -100.0000 -100.0000
    0.9998    0.3188   -1.9852  ...    -2.9007 -100.0000 -100.0000
              ...                ⋱                ...             
    1.2571    0.5768   -1.7708  ...    -2.7553 -100.0000 -100.0000
    1.2571    0.5768   -1.7708  ...    -2.7553 -100.0000 -100.0000
    1.2571    0.5768   -1.7708  ...    -2.7553 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.4302e+00  3.9641e+00  1.9135e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3728e+00 -5.6273e+00 -6.1224e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1632e+00  3.1712e-01 -2.1812e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1857e+00  3.3296e-01 -2.1890e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1857e+00  3.3296e-01 -2.1890e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1857e+00  3.3296e-01 -2.1890e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.2683e+00  3.7715e+00  1.6326e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3000e+00 -5.5681e+00 -6.0927e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1387e+00  2.9308e-01 -2.2011e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1861e+00  3.3464e-01 -2.1863e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1861e+00  3.3464e-01 -2.1863e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1861e+00  3.3464e-01 -2.1863e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.5504e+00  4.1025e+00  2.1101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3879e+00 -5.6413e+00 -6.1303e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1806e+00  3.2780e-01 -2.1794e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1831e+00  3.2293e-01 -2.2052e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1831e+00  3.2293e-01 -2.2052e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1831e+00  3.2293e-01 -2.2052e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.3300e+00  3.8453e+00  1.7405e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3468e+00 -5.6063e+00 -6.1121e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1421e+00  2.9563e-01 -2.1997e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1859e+00  3.3336e-01 -2.1884e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1859e+00  3.3336e-01 -2.1884e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1859e+00  3.3336e-01 -2.1884e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.5715e+00  4.1299e+00  2.1555e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3929e+00 -5.6444e+00 -6.1313e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1846e+00  3.3535e-01 -2.1693e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1844e+00  3.2772e-01 -2.1975e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1844e+00  3.2772e-01 -2.1975e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1844e+00  3.2772e-01 -2.1975e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.4302e+00  3.9641e+00  1.9135e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3728e+00 -5.6273e+00 -6.1224e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1632e+00  3.1712e-01 -2.1812e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1857e+00  3.3296e-01 -2.1890e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1857e+00  3.3296e-01 -2.1890e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1857e+00  3.3296e-01 -2.1890e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    4.3856    3.9135    1.8437  ...  -100.0000 -100.0000 -100.0000
   -5.3597   -5.6156   -6.1161  ...  -100.0000 -100.0000 -100.0000
    1.1514    0.3089   -2.1844  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1871    0.3384   -2.1804  ...  -100.0000 -100.0000 -100.0000
    1.1871    0.3384   -2.1804  ...  -100.0000 -100.0000 -100.0000
    1.1871    0.3384   -2.1804  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    4.3856    3.9135    1.8437  ...  -100.0000 -100.0000 -100.0000
   -5.3597   -5.6156   -6.1161  ...  -100.0000 -100.0000 -100.0000
    1.1514    0.3089   -2.1844  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1871    0.3384   -2.1804  ...  -100.0000 -100.0000 -100.0000
    1.1871    0.3384   -2.1804  ...  -100.0000 -100.0000 -100.0000
    1.1871    0.3384   -2.1804  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    4.3635    3.8816    1.7869  ...  -100.0000 -100.0000 -100.0000
   -5.3522   -5.6120   -6.1157  ...  -100.0000 -100.0000 -100.0000
    1.1416    0.2900   -2.2100  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1840    0.3263   -2.2001  ...  -100.0000 -100.0000 -100.0000
    1.1840    0.3263   -2.2001  ...  -100.0000 -100.0000 -100.0000
    1.1840    0.3263   -2.2001  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    4.1350    3.6067    1.3883  ...     0.5053    0.4132   -0.2641
   -5.2905   -5.5642   -6.0930  ...    -6.1356   -6.1290   -6.2261
    1.0987    0.2395   -2.2601  ...    -2.7350   -2.7513   -3.3058
              ...                ⋱                ...             
    1.1818    0.3175   -2.2139  ...    -2.7271   -2.7464   -3.3081
    1.1818    0.3175   -2.2139  ...    -2.7271   -2.7464   -3.3081
    1.1818    0.3175   -2.2139  ...    -2.7271   -2.7464   -3.3081

( 4 ,.,.) = 
    4.1742    3.6576    1.4677  ...     0.2415   -0.4397 -100.0000
   -5.3100   -5.5783   -6.0993  ...    -6.1623   -6.2539 -100.0000
    1.1038    0.2505   -2.2447  ...    -2.9129   -3.4632 -100.0000
              ...                ⋱                ...             
    1.1838    0.3254   -2.2012  ...    -2.9142   -3.4707 -100.0000
    1.1838    0.3254   -2.2012  ...    -2.9142   -3.4707 -100.0000
    1.1838    0.3254   -2.2012  ...    -2.9142   -3.4707 -100.0000

( 5 ,.,.) = 
    4.3212    3.8344    1.7242  ...  -100.0000 -100.0000 -100.0000
   -5.3540   -5.6125   -6.1155  ...  -100.0000 -100.0000 -100.0000
    1.1396    0.2914   -2.2052  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1853    0.3312   -2.1922  ...  -100.0000 -100.0000 -100.0000
    1.1853    0.3312   -2.1922  ...  -100.0000 -100.0000 -100.0000
    1.1853    0.3312   -2.1922  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 19 @ 2018-04-12 20:36:33.367631
training
gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 1], [7, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.0340e+00  3.6745e+00  1.9447e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3314e+00  7.5023e-01 -1.3809e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3314e+00  7.5023e-01 -1.3809e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3314e+00  7.5023e-01 -1.3809e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3314e+00  7.5023e-01 -1.3809e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3314e+00  7.5023e-01 -1.3809e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  4.2048e+00  3.8249e+00  2.3956e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3115e+00  6.5103e-01 -1.2307e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3115e+00  6.5103e-01 -1.2307e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3115e+00  6.5103e-01 -1.2307e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3115e+00  6.5103e-01 -1.2307e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3115e+00  6.5103e-01 -1.2307e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  3.8497e+00  3.4021e+00  1.6989e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2244e+00  5.3836e-01 -1.4734e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2244e+00  5.3836e-01 -1.4734e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2244e+00  5.3836e-01 -1.4734e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2244e+00  5.3836e-01 -1.4734e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2244e+00  5.3836e-01 -1.4734e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.5314e+00  3.0351e+00  9.7272e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.9343e+00 -5.2181e+00 -5.8579e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1095e+00  4.1386e-01 -1.8115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6586e+00  9.7663e-01 -1.2974e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3356e+00  6.4051e-01 -1.6218e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3356e+00  6.4051e-01 -1.6218e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  4.6196e+00  4.3973e+00  3.0544e+00  ...  -6.8493e-01  2.4196e-01 -2.5642e-01
  1.3767e+00  9.0664e-01 -1.1351e+00  ...  -4.0241e+00 -3.3871e+00 -3.7766e+00
  1.3767e+00  9.0664e-01 -1.1351e+00  ...  -4.0241e+00 -3.3871e+00 -3.7766e+00
                 ...                   ⋱                   ...                
  1.3767e+00  9.0664e-01 -1.1351e+00  ...  -4.0241e+00 -3.3871e+00 -3.7766e+00
  1.3767e+00  9.0664e-01 -1.1351e+00  ...  -4.0241e+00 -3.3871e+00 -3.7766e+00
  1.3767e+00  9.0664e-01 -1.1351e+00  ...  -4.0241e+00 -3.3871e+00 -3.7766e+00

(14,.,.) = 
  3.6289e+00  3.1791e+00  1.1526e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0337e+00 -5.2826e+00 -5.8963e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1749e+00  5.2411e-01 -1.7220e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.7082e+00  1.0703e+00 -1.2191e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6379e+00  9.9676e-01 -1.2964e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3939e+00  7.4405e-01 -1.5394e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 0, 22, 0, 53, 1], [7, 0, 24, 0, 60, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.2457e+00  3.9338e+00  2.2053e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2422e+00  6.8772e-01 -1.5432e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2422e+00  6.8772e-01 -1.5432e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2422e+00  6.8772e-01 -1.5432e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2422e+00  6.8772e-01 -1.5432e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.2422e+00  6.8772e-01 -1.5432e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.2788e+00  3.0746e+00  1.6689e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -4.8345e+00 -4.9573e+00 -5.5371e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1295e+00  8.4264e-01 -7.6742e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2376e+00  9.5108e-01 -6.6230e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5889e+00  1.3064e+00 -3.1072e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6022e+00  1.3200e+00 -3.0201e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  3.7183e+00  3.3397e+00  1.5495e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0756e+00 -5.2939e+00 -5.8656e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3428e+00  7.7595e-01 -1.2919e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2637e+00  6.9535e-01 -1.3660e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3472e+00  7.7597e-01 -1.3145e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3472e+00  7.7597e-01 -1.3145e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  4.2025e+00  3.7810e+00  1.9490e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1797e+00  4.6105e-01 -1.7891e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1797e+00  4.6105e-01 -1.7891e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1797e+00  4.6105e-01 -1.7891e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1797e+00  4.6105e-01 -1.7891e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.1797e+00  4.6105e-01 -1.7891e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  4.0668e+00  3.8045e+00  1.8352e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4399e+00  9.9518e-01 -1.4448e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4399e+00  9.9518e-01 -1.4448e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4399e+00  9.9518e-01 -1.4448e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4399e+00  9.9518e-01 -1.4448e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4399e+00  9.9518e-01 -1.4448e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  4.3727e+00  4.1863e+00  2.7292e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3613e+00  9.8762e-01 -1.0939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3613e+00  9.8762e-01 -1.0939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3613e+00  9.8762e-01 -1.0939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3613e+00  9.8762e-01 -1.0939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3613e+00  9.8762e-01 -1.0939e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    4.1865    4.0243    2.6879  ...  -100.0000 -100.0000 -100.0000
    1.3751    1.0621   -0.7992  ...  -100.0000 -100.0000 -100.0000
    1.3751    1.0621   -0.7992  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.3751    1.0621   -0.7992  ...  -100.0000 -100.0000 -100.0000
    1.3751    1.0621   -0.7992  ...  -100.0000 -100.0000 -100.0000
    1.3751    1.0621   -0.7992  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    4.3082    4.2036    2.9114  ...  -100.0000 -100.0000 -100.0000
   -5.3897   -5.4616   -5.9265  ...  -100.0000 -100.0000 -100.0000
    1.5143    1.2845   -0.5736  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1980    0.9649   -0.8905  ...  -100.0000 -100.0000 -100.0000
    1.4827    1.2516   -0.6098  ...  -100.0000 -100.0000 -100.0000
    1.7312    1.5032   -0.3595  ...  -100.0000 -100.0000 -100.0000

(2 ,.,.) = 
    4.1934    3.9304    2.4401  ...  -100.0000 -100.0000 -100.0000
   -5.2423   -5.4108   -5.9198  ...  -100.0000 -100.0000 -100.0000
    1.4098    0.9405   -1.0297  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.1627    0.6887   -1.2680  ...  -100.0000 -100.0000 -100.0000
    1.5901    1.1240   -0.8516  ...  -100.0000 -100.0000 -100.0000
    1.8093    1.3491   -0.6354  ...  -100.0000 -100.0000 -100.0000
...

(12,.,.) = 
    4.1283    3.9276    2.4339  ...    -0.4742 -100.0000 -100.0000
    1.3465    0.9781   -1.0222  ...    -3.3594 -100.0000 -100.0000
    1.3465    0.9781   -1.0222  ...    -3.3594 -100.0000 -100.0000
              ...                ⋱                ...             
    1.3465    0.9781   -1.0222  ...    -3.3594 -100.0000 -100.0000
    1.3465    0.9781   -1.0222  ...    -3.3594 -100.0000 -100.0000
    1.3465    0.9781   -1.0222  ...    -3.3594 -100.0000 -100.0000

(13,.,.) = 
    3.9919    3.7362    2.2270  ...  -100.0000 -100.0000 -100.0000
    1.5179    1.0826   -0.8658  ...  -100.0000 -100.0000 -100.0000
    1.5179    1.0826   -0.8658  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5179    1.0826   -0.8658  ...  -100.0000 -100.0000 -100.0000
    1.5179    1.0826   -0.8658  ...  -100.0000 -100.0000 -100.0000
    1.5179    1.0826   -0.8658  ...  -100.0000 -100.0000 -100.0000

(14,.,.) = 
    3.9150    3.5960    1.7591  ...  -100.0000 -100.0000 -100.0000
    1.4520    0.9349   -1.3076  ...  -100.0000 -100.0000 -100.0000
    1.4520    0.9349   -1.3076  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.4520    0.9349   -1.3076  ...  -100.0000 -100.0000 -100.0000
    1.4520    0.9349   -1.3076  ...  -100.0000 -100.0000 -100.0000
    1.4520    0.9349   -1.3076  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 0, 22, 0, 54, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 1], [7, 1], [7, 0, 8, 0, 55, 1]]
cond_score Variable containing:
(0 ,.,.) = 
    3.5167    3.3273    1.9500  ...  -100.0000 -100.0000 -100.0000
   -5.1049   -5.2172   -5.7296  ...  -100.0000 -100.0000 -100.0000
    1.4528    1.1633   -0.4760  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.4084    1.1167   -0.5476  ...  -100.0000 -100.0000 -100.0000
    1.4084    1.1167   -0.5476  ...  -100.0000 -100.0000 -100.0000
    1.4084    1.1167   -0.5476  ...  -100.0000 -100.0000 -100.0000

(1 ,.,.) = 
    2.5190    2.4189    0.8694  ...    -0.4947   -1.8244 -100.0000
   -4.7829   -4.8436   -5.4819  ...    -5.6900   -6.0186 -100.0000
    1.3252    1.1876   -0.4618  ...    -1.5656   -2.7426 -100.0000
              ...                ⋱                ...             
    1.8016    1.6667    0.0253  ...    -1.1620   -2.3860 -100.0000
    1.7330    1.5982   -0.0514  ...    -1.2371   -2.4614 -100.0000
    1.5600    1.4240   -0.2349  ...    -1.3979   -2.6108 -100.0000

(2 ,.,.) = 
    3.4059    3.3297    1.7203  ...  -100.0000 -100.0000 -100.0000
    1.4826    1.3440   -0.5811  ...  -100.0000 -100.0000 -100.0000
    1.4826    1.3440   -0.5811  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.4826    1.3440   -0.5811  ...  -100.0000 -100.0000 -100.0000
    1.4826    1.3440   -0.5811  ...  -100.0000 -100.0000 -100.0000
    1.4826    1.3440   -0.5811  ...  -100.0000 -100.0000 -100.0000

(3 ,.,.) = 
    3.5882    3.3748    1.6702  ...     0.5447   -0.3453   -0.9255
    1.4096    1.0713   -0.9549  ...    -1.8244   -2.5458   -3.0484
    1.4096    1.0713   -0.9549  ...    -1.8244   -2.5458   -3.0484
              ...                ⋱                ...             
    1.4096    1.0713   -0.9549  ...    -1.8244   -2.5458   -3.0484
    1.4096    1.0713   -0.9549  ...    -1.8244   -2.5458   -3.0484
    1.4096    1.0713   -0.9549  ...    -1.8244   -2.5458   -3.0484

(4 ,.,.) = 
    4.1832    3.9273    2.4538  ...    -1.6595   -1.9094   -0.6660
    1.4761    1.0216   -0.9571  ...    -4.1277   -4.2630   -3.4686
    1.4761    1.0216   -0.9571  ...    -4.1277   -4.2630   -3.4686
              ...                ⋱                ...             
    1.4761    1.0216   -0.9571  ...    -4.1277   -4.2630   -3.4686
    1.4761    1.0216   -0.9571  ...    -4.1277   -4.2630   -3.4686
    1.4761    1.0216   -0.9571  ...    -4.1277   -4.2630   -3.4686

(5 ,.,.) = 
    3.2227    3.0290    1.4854  ...  -100.0000 -100.0000 -100.0000
   -5.1184   -5.2295   -5.7655  ...  -100.0000 -100.0000 -100.0000
    1.4779    1.2015   -0.5541  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.4160    1.1372   -0.6414  ...  -100.0000 -100.0000 -100.0000
    1.4160    1.1372   -0.6414  ...  -100.0000 -100.0000 -100.0000
    1.4160    1.1372   -0.6414  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x9x61 (GPU 0)]

 Loss = 4.15882079742
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  3.7226e+00  3.5237e+00  1.7281e+00  ...   6.9467e-02 -8.7937e-01 -1.0000e+02
 -5.3139e+00 -5.4267e+00 -5.9740e+00  ...  -6.1220e+00 -6.2646e+00 -1.0000e+02
  1.6910e+00  1.3705e+00 -7.6936e-01  ...  -2.0130e+00 -2.8353e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5510e+00  1.2256e+00 -9.3989e-01  ...  -2.1925e+00 -3.0152e+00 -1.0000e+02
  1.5510e+00  1.2256e+00 -9.3989e-01  ...  -2.1925e+00 -3.0152e+00 -1.0000e+02
  1.5510e+00  1.2256e+00 -9.3989e-01  ...  -2.1925e+00 -3.0152e+00 -1.0000e+02

( 1 ,.,.) = 
  3.8215e+00  3.6305e+00  1.8760e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3263e+00 -5.4370e+00 -5.9784e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7038e+00  1.3866e+00 -7.4561e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5514e+00  1.2290e+00 -9.2915e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5514e+00  1.2290e+00 -9.2915e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5514e+00  1.2290e+00 -9.2915e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.3898e+00  4.2368e+00  2.7177e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4512e+00 -5.5531e+00 -6.0450e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8035e+00  1.4861e+00 -6.5001e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5510e+00  1.2256e+00 -9.3975e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5510e+00  1.2256e+00 -9.3975e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5510e+00  1.2256e+00 -9.3975e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.5659e+00  4.4260e+00  2.9957e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4618e+00 -5.5625e+00 -6.0499e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8314e+00  1.5162e+00 -6.1573e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5511e+00  1.2271e+00 -9.3526e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5511e+00  1.2271e+00 -9.3526e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5511e+00  1.2271e+00 -9.3526e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.4929e+00  4.3492e+00  2.8883e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4735e+00 -5.5727e+00 -6.0549e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8269e+00  1.5132e+00 -6.1456e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5514e+00  1.2291e+00 -9.2894e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5514e+00  1.2291e+00 -9.2894e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5514e+00  1.2291e+00 -9.2894e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.1320e+00  3.9627e+00  2.3344e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4175e+00 -5.5212e+00 -6.0263e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7618e+00  1.4457e+00 -6.8583e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5513e+00  1.2285e+00 -9.3076e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5513e+00  1.2285e+00 -9.3076e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5513e+00  1.2285e+00 -9.3076e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    3.7586    3.5629    1.7837  ...  -100.0000 -100.0000 -100.0000
   -5.3358   -5.4465   -5.9847  ...  -100.0000 -100.0000 -100.0000
    1.7051    1.3862   -0.7501  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5512    1.2270   -0.9355  ...  -100.0000 -100.0000 -100.0000
    1.5512    1.2270   -0.9355  ...  -100.0000 -100.0000 -100.0000
    1.5512    1.2270   -0.9355  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    3.4112    3.1948    1.3067  ...  -100.0000 -100.0000 -100.0000
   -5.2337   -5.3515   -5.9298  ...  -100.0000 -100.0000 -100.0000
    1.6411    1.3227   -0.8106  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5514    1.2292   -0.9286  ...  -100.0000 -100.0000 -100.0000
    1.5514    1.2292   -0.9286  ...  -100.0000 -100.0000 -100.0000
    1.5514    1.2292   -0.9286  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    3.6479    3.4451    1.6276  ...  -100.0000 -100.0000 -100.0000
   -5.3008   -5.4141   -5.9662  ...  -100.0000 -100.0000 -100.0000
    1.6813    1.3621   -0.7745  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5512    1.2273   -0.9347  ...  -100.0000 -100.0000 -100.0000
    1.5512    1.2273   -0.9347  ...  -100.0000 -100.0000 -100.0000
    1.5512    1.2273   -0.9347  ...  -100.0000 -100.0000 -100.0000
... 

(12 ,.,.) = 
    4.3586    4.2035    2.6699  ...  -100.0000 -100.0000 -100.0000
   -5.4479   -5.5499   -6.0432  ...  -100.0000 -100.0000 -100.0000
    1.7992    1.4817   -0.6542  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5510    1.2258   -0.9393  ...  -100.0000 -100.0000 -100.0000
    1.5510    1.2258   -0.9393  ...  -100.0000 -100.0000 -100.0000
    1.5510    1.2258   -0.9393  ...  -100.0000 -100.0000 -100.0000

(13 ,.,.) = 
    2.8188    2.5662    0.5232  ...    -0.1421   -1.3046 -100.0000
   -4.8898   -5.0337   -5.7464  ...    -5.7431   -6.0264 -100.0000
    1.4846    1.1611   -0.9789  ...    -1.3981   -2.4368 -100.0000
              ...                ⋱                ...             
    1.5511    1.2271   -0.9350  ...    -1.3803   -2.4385 -100.0000
    1.5511    1.2271   -0.9350  ...    -1.3803   -2.4385 -100.0000
    1.5511    1.2271   -0.9350  ...    -1.3803   -2.4385 -100.0000

(14 ,.,.) = 
    3.8707    3.6808    1.9368  ...  -100.0000 -100.0000 -100.0000
   -5.3157   -5.4280   -5.9741  ...  -100.0000 -100.0000 -100.0000
    1.7096    1.3904   -0.7470  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5511    1.2264   -0.9372  ...  -100.0000 -100.0000 -100.0000
    1.5511    1.2264   -0.9372  ...  -100.0000 -100.0000 -100.0000
    1.5511    1.2264   -0.9372  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.8254e+00  3.6359e+00  1.8875e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3381e+00 -5.4475e+00 -5.9839e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7073e+00  1.3912e+00 -7.3819e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5515e+00  1.2302e+00 -9.2533e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5515e+00  1.2302e+00 -9.2533e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5515e+00  1.2302e+00 -9.2533e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.3951e+00  4.2424e+00  2.7256e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4517e+00 -5.5536e+00 -6.0453e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8042e+00  1.4868e+00 -6.4945e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5510e+00  1.2255e+00 -9.4002e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5510e+00  1.2255e+00 -9.4002e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5510e+00  1.2255e+00 -9.4002e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.2061e+00  4.0405e+00  2.4387e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4215e+00 -5.5255e+00 -6.0293e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7676e+00  1.4497e+00 -6.8614e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5511e+00  1.2264e+00 -9.3739e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5511e+00  1.2264e+00 -9.3739e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5511e+00  1.2264e+00 -9.3739e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.2413e+00  3.0154e+00  1.0813e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1380e+00 -5.2628e+00 -5.8785e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5892e+00  1.2703e+00 -8.6241e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5515e+00  1.2301e+00 -9.2586e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5515e+00  1.2301e+00 -9.2586e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5515e+00  1.2301e+00 -9.2586e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  3.3819e+00  3.1639e+00  1.2678e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2142e+00 -5.3334e+00 -5.9192e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6309e+00  1.3126e+00 -8.2011e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5514e+00  1.2296e+00 -9.2723e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5514e+00  1.2296e+00 -9.2723e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5514e+00  1.2296e+00 -9.2723e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.0618e+00  3.8863e+00  2.2234e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3846e+00 -5.4913e+00 -6.0098e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7519e+00  1.4342e+00 -7.0090e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5511e+00  1.2270e+00 -9.3550e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5511e+00  1.2270e+00 -9.3550e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5511e+00  1.2270e+00 -9.3550e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    3.9797    3.7979    2.0991  ...     0.4556   -0.3152   -1.0096
   -5.3752   -5.4832   -6.0059  ...    -6.1662   -6.2432   -6.3296
    1.7323    1.4127   -0.7261  ...    -2.0176   -2.5961   -3.1862
              ...                ⋱                ...             
    1.5509    1.2254   -0.9402  ...    -2.2366   -2.8111   -3.3945
    1.5509    1.2254   -0.9402  ...    -2.2366   -2.8111   -3.3945
    1.5509    1.2254   -0.9402  ...    -2.2366   -2.8111   -3.3945

( 1 ,.,.) = 
    3.9790    3.7985    2.1043  ...  -100.0000 -100.0000 -100.0000
   -5.3783   -5.4854   -6.0064  ...  -100.0000 -100.0000 -100.0000
    1.7303    1.4125   -0.7219  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5512    1.2276   -0.9336  ...  -100.0000 -100.0000 -100.0000
    1.5512    1.2276   -0.9336  ...  -100.0000 -100.0000 -100.0000
    1.5512    1.2276   -0.9336  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    3.7857    3.5932    1.8290  ...  -100.0000 -100.0000 -100.0000
   -5.3383   -5.4482   -5.9851  ...  -100.0000 -100.0000 -100.0000
    1.6985    1.3808   -0.7524  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5513    1.2286   -0.9304  ...  -100.0000 -100.0000 -100.0000
    1.5513    1.2286   -0.9304  ...  -100.0000 -100.0000 -100.0000
    1.5513    1.2286   -0.9304  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    4.1160    3.9429    2.2972  ...    -1.4543   -1.9026   -0.9795
   -5.3919   -5.4987   -6.0147  ...    -6.3819   -6.4085   -6.3501
    1.7561    1.4368   -0.7024  ...    -3.6404   -3.9200   -3.3080
              ...                ⋱                ...             
    1.5509    1.2250   -0.9418  ...    -3.8532   -4.1231   -3.5322
    1.5509    1.2250   -0.9418  ...    -3.8532   -4.1231   -3.5322
    1.5509    1.2250   -0.9418  ...    -3.8532   -4.1231   -3.5322

( 4 ,.,.) = 
    3.2412    3.0123    1.0681  ...    -1.0682 -100.0000 -100.0000
   -5.1198   -5.2469   -5.8704  ...    -6.1495 -100.0000 -100.0000
    1.5883    1.2669   -0.8719  ...    -2.5676 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5511    1.2270   -0.9352  ...    -2.6616 -100.0000 -100.0000
    1.5511    1.2270   -0.9352  ...    -2.6616 -100.0000 -100.0000
    1.5511    1.2270   -0.9352  ...    -2.6616 -100.0000 -100.0000

( 5 ,.,.) = 
    2.8876    2.6393    0.6130  ...    -1.2230 -100.0000 -100.0000
   -4.9342   -5.0745   -5.7697  ...    -6.0425 -100.0000 -100.0000
    1.5042    1.1820   -0.9556  ...    -2.4181 -100.0000 -100.0000
              ...                ⋱                ...             
    1.5512    1.2282   -0.9317  ...    -2.4366 -100.0000 -100.0000
    1.5512    1.2282   -0.9317  ...    -2.4366 -100.0000 -100.0000
    1.5512    1.2282   -0.9317  ...    -2.4366 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  4.3160e+00  4.0699e+00  2.2192e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4597e+00 -5.6044e+00 -6.1159e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7473e+00  1.2869e+00 -1.1258e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5093e+00  1.0380e+00 -1.3970e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5093e+00  1.0380e+00 -1.3970e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5093e+00  1.0380e+00 -1.3970e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.1339e+00  3.8686e+00  1.9261e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3841e+00 -5.5371e+00 -6.0804e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7138e+00  1.2532e+00 -1.1576e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5094e+00  1.0392e+00 -1.3938e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5094e+00  1.0392e+00 -1.3938e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5094e+00  1.0392e+00 -1.3938e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.4746e+00  4.2406e+00  2.4587e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4726e+00 -5.6179e+00 -6.1248e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7674e+00  1.3011e+00 -1.1244e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5079e+00  1.0296e+00 -1.4178e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5079e+00  1.0296e+00 -1.4178e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5079e+00  1.0296e+00 -1.4178e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.1973e+00  3.9391e+00  2.0293e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4334e+00 -5.5812e+00 -6.1040e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7228e+00  1.2617e+00 -1.1507e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5093e+00  1.0383e+00 -1.3964e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5093e+00  1.0383e+00 -1.3964e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5093e+00  1.0383e+00 -1.3964e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.4996e+00  4.2701e+00  2.5092e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4769e+00 -5.6208e+00 -6.1254e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7716e+00  1.3086e+00 -1.1109e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5086e+00  1.0336e+00 -1.4079e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5086e+00  1.0336e+00 -1.4079e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5086e+00  1.0336e+00 -1.4079e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  4.3160e+00  4.0699e+00  2.2192e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4597e+00 -5.6044e+00 -6.1159e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7473e+00  1.2869e+00 -1.1258e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5093e+00  1.0380e+00 -1.3970e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5093e+00  1.0380e+00 -1.3970e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5093e+00  1.0380e+00 -1.3970e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  4.2452e+00  3.9941e+00  2.1154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4444e+00 -5.5898e+00 -6.1074e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7304e+00  1.2730e+00 -1.1327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5100e+00  1.0424e+00 -1.3857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5100e+00  1.0424e+00 -1.3857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5100e+00  1.0424e+00 -1.3857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  4.2452e+00  3.9941e+00  2.1154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4444e+00 -5.5898e+00 -6.1074e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7304e+00  1.2730e+00 -1.1327e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5100e+00  1.0424e+00 -1.3857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5100e+00  1.0424e+00 -1.3857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5100e+00  1.0424e+00 -1.3857e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.2131e+00  3.9535e+00  2.0412e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4348e+00 -5.5838e+00 -6.1066e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7198e+00  1.2539e+00 -1.1670e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5084e+00  1.0325e+00 -1.4106e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5084e+00  1.0325e+00 -1.4106e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5084e+00  1.0325e+00 -1.4106e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  3.8920e+00  3.5959e+00  1.5251e+00  ...   1.7163e-01  2.5169e-02 -7.6311e-01
 -5.3595e+00 -5.5191e+00 -6.0749e+00  ...  -6.1845e+00 -6.1824e+00 -6.2910e+00
  1.6662e+00  1.1923e+00 -1.2395e+00  ...  -2.2109e+00 -2.2767e+00 -2.9536e+00
                 ...                   ⋱                   ...                
  1.5072e+00  1.0251e+00 -1.4290e+00  ...  -2.4088e+00 -2.4729e+00 -3.1467e+00
  1.5072e+00  1.0251e+00 -1.4290e+00  ...  -2.4088e+00 -2.4729e+00 -3.1467e+00
  1.5072e+00  1.0251e+00 -1.4290e+00  ...  -2.4088e+00 -2.4729e+00 -3.1467e+00

( 4 ,.,.) = 
  3.9715e+00  3.6877e+00  1.6646e+00  ...  -2.3277e-01 -1.0025e+00 -1.0000e+02
 -5.3917e+00 -5.5460e+00 -6.0874e+00  ...  -6.2357e+00 -6.3311e+00 -1.0000e+02
  1.6793e+00  1.2112e+00 -1.2108e+00  ...  -2.5544e+00 -3.2049e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5083e+00  1.0317e+00 -1.4128e+00  ...  -2.7593e+00 -3.4036e+00 -1.0000e+02
  1.5083e+00  1.0317e+00 -1.4128e+00  ...  -2.7593e+00 -3.4036e+00 -1.0000e+02
  1.5083e+00  1.0317e+00 -1.4128e+00  ...  -2.7593e+00 -3.4036e+00 -1.0000e+02

( 5 ,.,.) = 
  4.1424e+00  3.8786e+00  1.9424e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4361e+00 -5.5839e+00 -6.1058e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7172e+00  1.2546e+00 -1.1599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5091e+00  1.0368e+00 -1.3999e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5091e+00  1.0368e+00 -1.3999e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5091e+00  1.0368e+00 -1.3999e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 5, 1, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 20 @ 2018-04-12 20:36:35.788165
training
gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 0, 22, 0, 53, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 0, 0, 0, 60, 1], [7, 1], [7, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  4.5929e+00  4.5452e+00  3.2272e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5759e+00  1.4196e+00 -6.8802e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5759e+00  1.4196e+00 -6.8802e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5759e+00  1.4196e+00 -6.8802e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5759e+00  1.4196e+00 -6.8802e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5759e+00  1.4196e+00 -6.8802e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  4.3108e+00  4.1214e+00  2.5814e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3042e+00  9.2404e-01 -1.2009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3042e+00  9.2404e-01 -1.2009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3042e+00  9.2404e-01 -1.2009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3042e+00  9.2404e-01 -1.2009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.3042e+00  9.2404e-01 -1.2009e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  4.2324e+00  4.1288e+00  2.8741e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4991e+00  1.2791e+00 -5.1502e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4991e+00  1.2791e+00 -5.1502e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4991e+00  1.2791e+00 -5.1502e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4991e+00  1.2791e+00 -5.1502e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4991e+00  1.2791e+00 -5.1502e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  4.1056e+00  3.8031e+00  2.2115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2775e+00 -5.4641e+00 -5.9724e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8121e+00  1.3055e+00 -7.2560e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2365e+00  7.1456e-01 -1.3000e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5738e+00  1.0585e+00 -9.7164e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8717e+00  1.3650e+00 -6.7548e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.3584e+00  3.0529e+00  1.2101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1627e+00 -5.3269e+00 -5.8975e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6414e+00  1.2146e+00 -8.3642e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1573e+00  7.2120e-01 -1.3139e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5777e+00  1.1478e+00 -9.0561e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8479e+00  1.4244e+00 -6.3697e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  4.4547e+00  4.3078e+00  2.7689e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5322e+00  1.2131e+00 -1.0060e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5322e+00  1.2131e+00 -1.0060e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5322e+00  1.2131e+00 -1.0060e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5322e+00  1.2131e+00 -1.0060e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5322e+00  1.2131e+00 -1.0060e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.6630e+00  2.4125e+00  1.0490e-01  ...  -5.6362e-01 -1.7958e+00 -1.0000e+02
 -5.0051e+00 -5.1393e+00 -5.8593e+00  ...  -5.8662e+00 -6.1233e+00 -1.0000e+02
  1.5252e+00  1.2117e+00 -1.1524e+00  ...  -1.5687e+00 -2.6548e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1805e+00  8.6297e-01 -1.4797e+00  ...  -1.8405e+00 -2.8974e+00 -1.0000e+02
  1.6454e+00  1.3334e+00 -1.0362e+00  ...  -1.4698e+00 -2.5676e+00 -1.0000e+02
  1.7907e+00  1.4813e+00 -8.9729e-01  ...  -1.3595e+00 -2.4734e+00 -1.0000e+02

(1 ,.,.) = 
  3.4864e+00  3.3406e+00  2.1180e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2266e+00 -5.3133e+00 -5.7660e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7199e+00  1.4924e+00  8.0908e-03  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2338e+00  1.0008e+00 -4.8888e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5509e+00  1.3198e+00 -1.9014e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5509e+00  1.3198e+00 -1.9014e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  3.2689e+00  3.1759e+00  1.3570e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5644e+00  1.4109e+00 -6.8730e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5644e+00  1.4109e+00 -6.8730e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5644e+00  1.4109e+00 -6.8730e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5644e+00  1.4109e+00 -6.8730e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5644e+00  1.4109e+00 -6.8730e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.8884e+00  3.7654e+00  1.9837e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5632e+00  1.3304e+00 -9.2286e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5632e+00  1.3304e+00 -9.2286e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5632e+00  1.3304e+00 -9.2286e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5632e+00  1.3304e+00 -9.2286e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5632e+00  1.3304e+00 -9.2286e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  2.6066e+00  2.1982e+00  4.0141e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.0232e+00 -5.2248e+00 -5.7973e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6070e+00  1.1240e+00 -7.3285e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3066e+00  8.1758e-01 -1.0288e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6574e+00  1.1752e+00 -6.8188e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8410e+00  1.3632e+00 -4.9912e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  4.3121e+00  4.0316e+00  2.2609e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5021e+00  9.7380e-01 -1.3786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5021e+00  9.7380e-01 -1.3786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5021e+00  9.7380e-01 -1.3786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5021e+00  9.7380e-01 -1.3786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5021e+00  9.7380e-01 -1.3786e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 0, 14, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.7791e+00  3.6007e+00  1.7189e+00  ...  -1.7768e+00 -1.0000e+02 -1.0000e+02
  1.4806e+00  1.1689e+00 -1.1073e+00  ...  -3.7963e+00 -1.0000e+02 -1.0000e+02
  1.4806e+00  1.1689e+00 -1.1073e+00  ...  -3.7963e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4806e+00  1.1689e+00 -1.1073e+00  ...  -3.7963e+00 -1.0000e+02 -1.0000e+02
  1.4806e+00  1.1689e+00 -1.1073e+00  ...  -3.7963e+00 -1.0000e+02 -1.0000e+02
  1.4806e+00  1.1689e+00 -1.1073e+00  ...  -3.7963e+00 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.8977e+00  3.8109e+00  2.1753e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6636e+00  1.4820e+00 -6.1852e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6636e+00  1.4820e+00 -6.1852e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6636e+00  1.4820e+00 -6.1852e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6636e+00  1.4820e+00 -6.1852e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6636e+00  1.4820e+00 -6.1852e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.5488e+00  2.1452e+00 -9.0617e-02  ...   3.6497e-01 -6.7423e-01 -1.6119e+00
 -4.9465e+00 -5.1526e+00 -5.8502e+00  ...  -5.5986e+00 -5.8389e+00 -6.0601e+00
  1.5707e+00  1.0960e+00 -1.1546e+00  ...  -6.0006e-01 -1.5119e+00 -2.3582e+00
                 ...                   ⋱                   ...                
  1.9288e+00  1.4629e+00 -8.0160e-01  ...  -2.6968e-01 -1.2107e+00 -2.0796e+00
  1.8441e+00  1.3750e+00 -8.9885e-01  ...  -3.6114e-01 -1.3045e+00 -2.1751e+00
  1.5379e+00  1.0585e+00 -1.2209e+00  ...  -6.7474e-01 -1.6106e+00 -2.4714e+00
...

(12,.,.) = 
  3.7109e+00  3.5639e+00  1.6374e+00  ...  -6.8953e-01 -1.3271e+00 -1.0000e+02
  1.4863e+00  1.2339e+00 -1.0869e+00  ...  -2.8709e+00 -3.4160e+00 -1.0000e+02
  1.4863e+00  1.2339e+00 -1.0869e+00  ...  -2.8709e+00 -3.4160e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.4863e+00  1.2339e+00 -1.0869e+00  ...  -2.8709e+00 -3.4160e+00 -1.0000e+02
  1.4863e+00  1.2339e+00 -1.0869e+00  ...  -2.8709e+00 -3.4160e+00 -1.0000e+02
  1.4863e+00  1.2339e+00 -1.0869e+00  ...  -2.8709e+00 -3.4160e+00 -1.0000e+02

(13,.,.) = 
  3.5413e+00  3.0836e+00  7.6309e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6523e+00  1.0051e+00 -1.5436e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6523e+00  1.0051e+00 -1.5436e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6523e+00  1.0051e+00 -1.5436e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6523e+00  1.0051e+00 -1.5436e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6523e+00  1.0051e+00 -1.5436e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  4.1148e+00  4.0110e+00  2.6867e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6307e+00  1.4177e+00 -4.1754e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6307e+00  1.4177e+00 -4.1754e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6307e+00  1.4177e+00 -4.1754e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6307e+00  1.4177e+00 -4.1754e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6307e+00  1.4177e+00 -4.1754e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 0, 18, 0, 56, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.7819e+00  2.7308e+00  1.0741e+00  ...  -5.3980e-01 -1.4431e+00 -1.0000e+02
 -5.1394e+00 -5.1718e+00 -5.7590e+00  ...  -5.9410e+00 -6.1391e+00 -1.0000e+02
  1.9359e+00  1.8429e+00  7.5686e-02  ...  -1.2655e+00 -2.0773e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.7576e+00  1.6660e+00 -1.4249e-01  ...  -1.5063e+00 -2.3344e+00 -1.0000e+02
  1.7576e+00  1.6660e+00 -1.4249e-01  ...  -1.5063e+00 -2.3344e+00 -1.0000e+02
  1.7576e+00  1.6660e+00 -1.4249e-01  ...  -1.5063e+00 -2.3344e+00 -1.0000e+02

(1 ,.,.) = 
  1.9098e+00  1.9430e+00  2.9196e-03  ...  -2.0044e-01 -1.0341e+00 -1.7788e+00
 -5.1408e+00 -5.1235e+00 -5.7691e+00  ...  -5.6840e+00 -5.8510e+00 -6.0521e+00
  1.6437e+00  1.6496e+00 -2.8670e-01  ...  -3.9795e-01 -1.1294e+00 -1.8360e+00
                 ...                   ⋱                   ...                
  1.7830e+00  1.7880e+00 -1.5308e-01  ...  -2.7811e-01 -1.0243e+00 -1.7391e+00
  1.7962e+00  1.8024e+00 -1.4688e-01  ...  -2.7733e-01 -1.0306e+00 -1.7498e+00
  1.7064e+00  1.7139e+00 -2.4526e-01  ...  -3.6957e-01 -1.1221e+00 -1.8431e+00

(2 ,.,.) = 
  3.1250e+00  3.1739e+00  1.4602e+00  ...  -3.9974e-01 -1.2802e+00 -1.0000e+02
 -5.2828e+00 -5.2654e+00 -5.8546e+00  ...  -6.0748e+00 -6.2348e+00 -1.0000e+02
  1.9152e+00  1.9228e+00 -4.6584e-04  ...  -1.5338e+00 -2.3254e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.8689e+00  1.8772e+00 -5.8052e-02  ...  -1.5944e+00 -2.3912e+00 -1.0000e+02
  1.6377e+00  1.6515e+00 -3.1914e-01  ...  -1.8644e+00 -2.6606e+00 -1.0000e+02
  1.6377e+00  1.6515e+00 -3.1914e-01  ...  -1.8644e+00 -2.6606e+00 -1.0000e+02

(3 ,.,.) = 
  2.7033e+00  2.5870e+00  5.0359e-01  ...  -1.7115e+00 -1.0000e+02 -1.0000e+02
 -5.2808e+00 -5.3386e+00 -5.9461e+00  ...  -6.2289e+00 -1.0000e+02 -1.0000e+02
  1.8730e+00  1.7054e+00 -4.6518e-01  ...  -2.3279e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6698e+00  1.5005e+00 -7.1029e-01  ...  -2.5989e+00 -1.0000e+02 -1.0000e+02
  1.6698e+00  1.5005e+00 -7.1029e-01  ...  -2.5989e+00 -1.0000e+02 -1.0000e+02
  1.6698e+00  1.5005e+00 -7.1029e-01  ...  -2.5989e+00 -1.0000e+02 -1.0000e+02

(4 ,.,.) = 
  3.8844e+00  3.9171e+00  2.3541e+00  ...  -1.6794e+00 -1.8427e+00 -1.0000e+02
  1.5061e+00  1.4933e+00 -5.8529e-01  ...  -3.7900e+00 -3.9473e+00 -1.0000e+02
  1.5061e+00  1.4933e+00 -5.8529e-01  ...  -3.7900e+00 -3.9473e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5061e+00  1.4933e+00 -5.8529e-01  ...  -3.7900e+00 -3.9473e+00 -1.0000e+02
  1.5061e+00  1.4933e+00 -5.8529e-01  ...  -3.7900e+00 -3.9473e+00 -1.0000e+02
  1.5061e+00  1.4933e+00 -5.8529e-01  ...  -3.7900e+00 -3.9473e+00 -1.0000e+02

(5 ,.,.) = 
  4.2034e+00  4.1741e+00  2.9595e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5134e+00  1.3972e+00 -3.8299e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5134e+00  1.3972e+00 -3.8299e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5134e+00  1.3972e+00 -3.8299e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5134e+00  1.3972e+00 -3.8299e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5134e+00  1.3972e+00 -3.8299e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x9x60 (GPU 0)]

 Loss = 3.89416618908
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  3.1082e+00  2.7284e+00 -5.2141e-02  ...  -6.4470e-01 -1.7003e+00 -1.0000e+02
 -5.4425e+00 -5.6088e+00 -6.2087e+00  ...  -6.1808e+00 -6.3338e+00 -1.0000e+02
  1.9725e+00  1.4780e+00 -1.3740e+00  ...  -1.6484e+00 -2.5953e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6675e+00  1.1572e+00 -1.7202e+00  ...  -1.9863e+00 -2.9282e+00 -1.0000e+02
  1.6675e+00  1.1572e+00 -1.7202e+00  ...  -1.9863e+00 -2.9282e+00 -1.0000e+02
  1.6675e+00  1.1572e+00 -1.7202e+00  ...  -1.9863e+00 -2.9282e+00 -1.0000e+02

( 1 ,.,.) = 
  3.2563e+00  2.8952e+00  1.6165e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4558e+00 -5.6178e+00 -6.2115e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9869e+00  1.5011e+00 -1.3426e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6683e+00  1.1665e+00 -1.7032e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6683e+00  1.1665e+00 -1.7032e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6683e+00  1.1665e+00 -1.7032e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.9839e+00  3.6888e+00  1.2203e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5801e+00 -5.7290e+00 -6.2631e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0814e+00  1.5927e+00 -1.2586e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6676e+00  1.1577e+00 -1.7196e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6676e+00  1.1577e+00 -1.7196e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6676e+00  1.1577e+00 -1.7196e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  4.2080e+00  3.9383e+00  1.5863e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5895e+00 -5.7364e+00 -6.2660e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0986e+00  1.6147e+00 -1.2333e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6679e+00  1.1616e+00 -1.7125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6679e+00  1.1616e+00 -1.7125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6679e+00  1.1616e+00 -1.7125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.0992e+00  3.8218e+00  1.4231e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5999e+00 -5.7443e+00 -6.2691e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0998e+00  1.6198e+00 -1.2228e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6683e+00  1.1664e+00 -1.7033e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6683e+00  1.1664e+00 -1.7033e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6683e+00  1.1664e+00 -1.7033e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  3.6525e+00  3.3291e+00  7.3029e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5485e+00 -5.6997e+00 -6.2492e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0485e+00  1.5641e+00 -1.2805e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6682e+00  1.1647e+00 -1.7062e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6682e+00  1.1647e+00 -1.7062e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6682e+00  1.1647e+00 -1.7062e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x62 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0, 0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([16, 15])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.0081e+00  2.6229e+00 -1.7597e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4334e+00 -5.5997e+00 -6.2040e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9634e+00  1.4725e+00 -1.3755e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6679e+00  1.1616e+00 -1.7125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6679e+00  1.1616e+00 -1.7125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6679e+00  1.1616e+00 -1.7125e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  2.6393e+00  2.2288e+00 -6.3227e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3337e+00 -5.5103e+00 -6.1620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9041e+00  1.4155e+00 -1.4273e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6683e+00  1.1671e+00 -1.7020e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6683e+00  1.1671e+00 -1.7020e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6683e+00  1.1671e+00 -1.7020e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  2.8905e+00  2.4959e+00 -3.2762e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4005e+00 -5.5705e+00 -6.1906e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9424e+00  1.4511e+00 -1.3965e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6679e+00  1.1622e+00 -1.7113e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6679e+00  1.1622e+00 -1.7113e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6679e+00  1.1622e+00 -1.7113e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.9469e+00  3.6483e+00  1.1630e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5773e+00 -5.7265e+00 -6.2620e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0796e+00  1.5911e+00 -1.2599e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6676e+00  1.1581e+00 -1.7190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6676e+00  1.1581e+00 -1.7190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6676e+00  1.1581e+00 -1.7190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.0769e+00  1.6216e+00 -1.2997e+00  ...  -5.5251e-01 -1.8807e+00 -1.0000e+02
 -5.0170e+00 -5.2318e+00 -6.0311e+00  ...  -5.7145e+00 -6.0580e+00 -1.0000e+02
  1.7540e+00  1.2547e+00 -1.5915e+00  ...  -7.5601e-01 -1.9869e+00 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6678e+00  1.1617e+00 -1.7121e+00  ...  -8.7641e-01 -2.1265e+00 -1.0000e+02
  1.6678e+00  1.1617e+00 -1.7121e+00  ...  -8.7641e-01 -2.1265e+00 -1.0000e+02
  1.6678e+00  1.1617e+00 -1.7121e+00  ...  -8.7641e-01 -2.1265e+00 -1.0000e+02

(14 ,.,.) = 
  3.3786e+00  3.0230e+00  3.1423e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4540e+00 -5.6179e+00 -6.2122e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9950e+00  1.5040e+00 -1.3460e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6677e+00  1.1601e+00 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6677e+00  1.1601e+00 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6677e+00  1.1601e+00 -1.7154e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[3, 0, u"``mary''"]]
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond [[4, 2, u'1850']]
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.2514e+00  2.8933e+00  1.6511e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4690e+00 -5.6286e+00 -6.2162e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9927e+00  1.5100e+00 -1.3306e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6685e+00  1.1696e+00 -1.6973e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6685e+00  1.1696e+00 -1.6973e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6685e+00  1.1696e+00 -1.6973e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.9930e+00  3.6986e+00  1.2342e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5807e+00 -5.7296e+00 -6.2634e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0816e+00  1.5928e+00 -1.2587e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6675e+00  1.1574e+00 -1.7201e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6675e+00  1.1574e+00 -1.7201e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6675e+00  1.1574e+00 -1.7201e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.7647e+00  3.4486e+00  8.8607e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5550e+00 -5.7065e+00 -6.2528e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0558e+00  1.5673e+00 -1.2825e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6677e+00  1.1597e+00 -1.7160e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6677e+00  1.1597e+00 -1.7160e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6677e+00  1.1597e+00 -1.7160e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  2.5228e+00  2.1056e+00 -7.6852e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2614e+00 -5.4458e+00 -6.1317e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8681e+00  1.3796e+00 -1.4616e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6685e+00  1.1691e+00 -1.6980e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6685e+00  1.1691e+00 -1.6980e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6685e+00  1.1691e+00 -1.6980e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  2.6220e+00  2.2108e+00 -6.5184e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3191e+00 -5.4971e+00 -6.1557e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8972e+00  1.4091e+00 -1.4328e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6684e+00  1.1680e+00 -1.7001e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6684e+00  1.1680e+00 -1.7001e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6684e+00  1.1680e+00 -1.7001e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  3.5830e+00  3.2496e+00  6.1710e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5178e+00 -5.6736e+00 -6.2376e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0375e+00  1.5495e+00 -1.2989e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6678e+00  1.1613e+00 -1.7130e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6678e+00  1.1613e+00 -1.7130e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6678e+00  1.1613e+00 -1.7130e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x63 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([6])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
  3.4599e+00  3.1124e+00  4.3356e-01  ...  -3.4272e-01 -1.2717e+00 -1.9433e+00
 -5.5082e+00 -5.6663e+00 -6.2350e+00  ...  -6.2481e+00 -6.3341e+00 -6.4111e+00
  2.0178e+00  1.5252e+00 -1.3271e+00  ...  -1.7750e+00 -2.5058e+00 -3.1056e+00
                 ...                   ⋱                   ...                
  1.6674e+00  1.1570e+00 -1.7207e+00  ...  -2.1605e+00 -2.8744e+00 -3.4599e+00
  1.6674e+00  1.1570e+00 -1.7207e+00  ...  -2.1605e+00 -2.8744e+00 -3.4599e+00
  1.6674e+00  1.1570e+00 -1.7207e+00  ...  -2.1605e+00 -2.8744e+00 -3.4599e+00

( 1 ,.,.) = 
  3.4580e+00  3.1146e+00  4.4243e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5112e+00 -5.6674e+00 -6.2348e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0183e+00  1.5308e+00 -1.3162e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6680e+00  1.1630e+00 -1.7101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6680e+00  1.1630e+00 -1.7101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6680e+00  1.1630e+00 -1.7101e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  3.1471e+00  2.7781e+00  1.9968e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4633e+00 -5.6247e+00 -6.2151e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9830e+00  1.4962e+00 -1.3484e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6682e+00  1.1657e+00 -1.7049e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6682e+00  1.1657e+00 -1.7049e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6682e+00  1.1657e+00 -1.7049e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 3 ,.,.) = 
  3.6741e+00  3.3454e+00  7.3898e-01  ...  -2.4955e+00 -2.8390e+00 -1.8896e+00
 -5.5285e+00 -5.6844e+00 -6.2431e+00  ...  -6.4692e+00 -6.4863e+00 -6.4334e+00
  2.0434e+00  1.5508e+00 -1.3026e+00  ...  -3.7256e+00 -3.9562e+00 -3.2665e+00
                 ...                   ⋱                   ...                
  1.6674e+00  1.1556e+00 -1.7233e+00  ...  -4.0631e+00 -4.2782e+00 -3.6341e+00
  1.6674e+00  1.1556e+00 -1.7233e+00  ...  -4.0631e+00 -4.2782e+00 -3.6341e+00
  1.6674e+00  1.1556e+00 -1.7233e+00  ...  -4.0631e+00 -4.2782e+00 -3.6341e+00

( 4 ,.,.) = 
  2.5688e+00  2.1472e+00 -7.3301e-01  ...  -1.8183e+00 -1.0000e+02 -1.0000e+02
 -5.2535e+00 -5.4412e+00 -6.1303e+00  ...  -6.2173e+00 -1.0000e+02 -1.0000e+02
  1.8681e+00  1.3729e+00 -1.4751e+00  ...  -2.2773e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6678e+00  1.1615e+00 -1.7124e+00  ...  -2.5224e+00 -1.0000e+02 -1.0000e+02
  1.6678e+00  1.1615e+00 -1.7124e+00  ...  -2.5224e+00 -1.0000e+02 -1.0000e+02
  1.6678e+00  1.1615e+00 -1.7124e+00  ...  -2.5224e+00 -1.0000e+02 -1.0000e+02

( 5 ,.,.) = 
  2.1371e+00  1.6880e+00 -1.2277e+00  ...  -1.8137e+00 -1.0000e+02 -1.0000e+02
 -5.0521e+00 -5.2619e+00 -6.0450e+00  ...  -6.0709e+00 -1.0000e+02 -1.0000e+02
  1.7709e+00  1.2749e+00 -1.5691e+00  ...  -1.9654e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6680e+00  1.1645e+00 -1.7068e+00  ...  -2.1204e+00 -1.0000e+02 -1.0000e+02
  1.6680e+00  1.1645e+00 -1.7068e+00  ...  -2.1204e+00 -1.0000e+02 -1.0000e+02
  1.6680e+00  1.1645e+00 -1.7068e+00  ...  -2.1204e+00 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 6x100x61 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [5, 5]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([8, 9])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [3]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Train acc_qm: 0.843137254902
   breakdown result: [ 0.84313725  0.94117647  0.84313725]
epoch_acc_new
cond_score Variable containing:
( 0 ,.,.) = 
  3.8963e+00  3.4446e+00  6.0018e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5910e+00 -5.7927e+00 -6.3187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0291e+00  1.3400e+00 -1.7503e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6212e+00  9.0425e-01 -2.1886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6212e+00  9.0425e-01 -2.1886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6212e+00  9.0425e-01 -2.1886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 1 ,.,.) = 
  3.7165e+00  3.2388e+00  3.1619e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5252e+00 -5.7374e+00 -6.2951e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9972e+00  1.3081e+00 -1.7796e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6214e+00  9.0674e-01 -2.1850e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6214e+00  9.0674e-01 -2.1850e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6214e+00  9.0674e-01 -2.1850e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

( 2 ,.,.) = 
  4.0875e+00  3.6521e+00  8.7657e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.6014e+00 -5.8052e+00 -6.3252e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0366e+00  1.3336e+00 -1.7689e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6189e+00  8.8664e-01 -2.2160e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6189e+00  8.8664e-01 -2.2160e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6189e+00  8.8664e-01 -2.2160e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
... 

(12 ,.,.) = 
  3.7537e+00  3.2821e+00  3.7787e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5673e+00 -5.7730e+00 -6.3106e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0060e+00  1.3157e+00 -1.7733e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6212e+00  9.0473e-01 -2.1880e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6212e+00  9.0473e-01 -2.1880e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6212e+00  9.0473e-01 -2.1880e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13 ,.,.) = 
  4.1164e+00  3.6906e+00  9.3883e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.6039e+00 -5.8053e+00 -6.3247e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0418e+00  1.3464e+00 -1.7513e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6200e+00  8.9533e-01 -2.2030e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6200e+00  8.9533e-01 -2.2030e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6200e+00  8.9533e-01 -2.2030e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14 ,.,.) = 
  3.8963e+00  3.4446e+00  6.0018e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5910e+00 -5.7927e+00 -6.3187e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0291e+00  1.3400e+00 -1.7503e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6212e+00  9.0425e-01 -2.1886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6212e+00  9.0425e-01 -2.1886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6212e+00  9.0425e-01 -2.1886e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

cond_score Variable containing:
( 0 ,.,.) = 
    3.7819    3.3210    0.4386  ...  -100.0000 -100.0000 -100.0000
   -5.5745   -5.7767   -6.3114  ...  -100.0000 -100.0000 -100.0000
    2.0112    1.3299   -1.7532  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.6225    0.9150   -2.1727  ...  -100.0000 -100.0000 -100.0000
    1.6225    0.9150   -2.1727  ...  -100.0000 -100.0000 -100.0000
    1.6225    0.9150   -2.1727  ...  -100.0000 -100.0000 -100.0000

( 1 ,.,.) = 
    3.7819    3.3210    0.4386  ...  -100.0000 -100.0000 -100.0000
   -5.5745   -5.7767   -6.3114  ...  -100.0000 -100.0000 -100.0000
    2.0112    1.3299   -1.7532  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.6225    0.9150   -2.1727  ...  -100.0000 -100.0000 -100.0000
    1.6225    0.9150   -2.1727  ...  -100.0000 -100.0000 -100.0000
    1.6225    0.9150   -2.1727  ...  -100.0000 -100.0000 -100.0000

( 2 ,.,.) = 
    3.7350    3.2542    0.3306  ...  -100.0000 -100.0000 -100.0000
   -5.5643   -5.7728   -6.3114  ...  -100.0000 -100.0000 -100.0000
    1.9983    1.2991   -1.7973  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.6199    0.8945   -2.2051  ...  -100.0000 -100.0000 -100.0000
    1.6199    0.8945   -2.2051  ...  -100.0000 -100.0000 -100.0000
    1.6199    0.8945   -2.2051  ...  -100.0000 -100.0000 -100.0000

( 3 ,.,.) = 
    3.3445    2.7976   -0.2702  ...    -0.5173   -0.7691   -1.6074
   -5.4928   -5.7182   -6.2896  ...    -6.2496   -6.2586   -6.3668
    1.9447    1.2261   -1.8766  ...    -1.8690   -2.0317   -2.7773
              ...                ⋱                ...             
    1.6174    0.8754   -2.2320  ...    -2.2313   -2.3866   -3.1222
    1.6174    0.8754   -2.2320  ...    -2.2313   -2.3866   -3.1222
    1.6174    0.8754   -2.2320  ...    -2.2313   -2.3866   -3.1222

( 4 ,.,.) = 
    3.4535    2.9325   -0.0879  ...    -1.1869   -1.9283 -100.0000
   -5.5291   -5.7449   -6.3000  ...    -6.3295   -6.4134 -100.0000
    1.9660    1.2609   -1.8346  ...    -2.4646   -3.1216 -100.0000
              ...                ⋱                ...             
    1.6193    0.8900   -2.2102  ...    -2.8277   -3.4696 -100.0000
    1.6193    0.8900   -2.2102  ...    -2.8277   -3.4696 -100.0000
    1.6193    0.8900   -2.2102  ...    -2.8277   -3.4696 -100.0000

( 5 ,.,.) = 
    3.6435    3.1572    0.2126  ...  -100.0000 -100.0000 -100.0000
   -5.5667   -5.7729   -6.3108  ...  -100.0000 -100.0000 -100.0000
    2.0008    1.3091   -1.7811  ...  -100.0000 -100.0000 -100.0000
              ...                ⋱                ...             
    1.6211    0.9035   -2.1908  ...  -100.0000 -100.0000 -100.0000
    1.6211    0.9035   -2.1908  ...  -100.0000 -100.0000 -100.0000
    1.6211    0.9035   -2.1908  ...  -100.0000 -100.0000 -100.0000
[torch.cuda.FloatTensor of size 6x100x49 (GPU 0)]

predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
predicted_agg [2, 4, 1, 5, 3, 0]
actual_agg [0]
predicted_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
actual_sel set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
predicted_cond [[0, 0, '<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>']]
actual_cond []
----------

 Dev acc_qm: 0.809523809524
   breakdown result: [ 0.80952381  1.          0.80952381]
 Best val acc = (0.80952380952380953, 1.0, 0.80952380952380953), on epoch (0, 0, 0) individually
Epoch 21 @ 2018-04-12 20:36:38.390193
training
gt_where_seq [[7, 0, 32, 0, 0, 56, 0, 1], [7, 0, 22, 0, 54, 1], [7, 0, 18, 0, 56, 1], [7, 1], [7, 0, 22, 0, 54, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 0, 24, 0, 60, 1], [7, 1], [7, 0, 0, 0, 60, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 1], [7, 0, 28, 0, 0, 53, 0, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.7182e+00  2.5453e+00  1.4510e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.3197e+00 -5.4063e+00 -6.0500e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7288e+00  1.4924e+00 -9.8213e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1752e+00  9.3399e-01 -1.5138e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4741e+00  1.2342e+00 -1.2321e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7776e+00  1.5410e+00 -9.3959e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  2.7796e+00  2.5327e+00  2.9189e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2205e+00 -5.3417e+00 -5.9808e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8927e+00  1.5760e+00 -7.2191e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.2915e+00  9.6496e-01 -1.3186e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6893e+00  1.3659e+00 -9.8000e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6893e+00  1.3659e+00 -9.8000e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.5144e+00  2.3707e+00 -5.1942e-02  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1199e+00 -5.1957e+00 -5.9320e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6163e+00  1.4166e+00 -1.0383e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.1151e+00  9.1414e-01 -1.5111e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5257e+00  1.3263e+00 -1.1676e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5257e+00  1.3263e+00 -1.1676e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  2.4780e+00  2.2614e+00 -5.8415e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2608e+00 -5.3622e+00 -6.0930e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8565e+00  1.5861e+00 -1.2434e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.0684e+00  7.8989e-01 -1.9861e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.4070e+00  1.1299e+00 -1.6778e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7868e+00  1.5134e+00 -1.3232e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.1708e+00  2.7781e+00  1.4400e-01  ...  -1.4510e+00 -1.0000e+02 -1.0000e+02
  1.5449e+00  1.0084e+00 -1.7468e+00  ...  -2.9178e+00 -1.0000e+02 -1.0000e+02
  1.5449e+00  1.0084e+00 -1.7468e+00  ...  -2.9178e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5449e+00  1.0084e+00 -1.7468e+00  ...  -2.9178e+00 -1.0000e+02 -1.0000e+02
  1.5449e+00  1.0084e+00 -1.7468e+00  ...  -2.9178e+00 -1.0000e+02 -1.0000e+02
  1.5449e+00  1.0084e+00 -1.7468e+00  ...  -2.9178e+00 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.8199e+00  2.9502e+00  1.5132e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.1562e+00 -5.0918e+00 -5.6572e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9341e+00  2.0490e+00  4.7253e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.3199e+00  1.4426e+00 -1.5193e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7718e+00  1.8881e+00  3.0483e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0539e+00  2.1675e+00  5.9402e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x7x63 (GPU 0)]

gt_where_seq [[7, 0, 22, 0, 53, 1], [7, 1], [7, 1], [7, 0, 12, 0, 0, 56, 0, 1], [7, 0, 32, 0, 0, 55, 0, 1], [7, 0, 0, 0, 0, 53, 0, 1], [7, 0, 28, 0, 0, 54, 0, 1], [7, 0, 32, 0, 0, 0, 55, 56, 0, 1], [7, 1], [7, 1], [7, 0, 8, 0, 55, 1], [7, 1], [7, 0, 30, 0, 0, 0, 0, 1], [7, 1], [7, 0, 14, 0, 54, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  2.6223e+00  2.1756e+00 -8.0418e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.4086e+00 -5.5890e+00 -6.2190e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9419e+00  1.4131e+00 -1.5300e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6584e+00  1.1120e+00 -1.8646e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6584e+00  1.1120e+00 -1.8646e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6584e+00  1.1120e+00 -1.8646e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.5869e+00  3.1369e+00  2.9101e-01  ...  -1.8817e+00 -1.0000e+02 -1.0000e+02
  1.7308e+00  1.0685e+00 -1.9737e+00  ...  -3.5271e+00 -1.0000e+02 -1.0000e+02
  1.7308e+00  1.0685e+00 -1.9737e+00  ...  -3.5271e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.7308e+00  1.0685e+00 -1.9737e+00  ...  -3.5271e+00 -1.0000e+02 -1.0000e+02
  1.7308e+00  1.0685e+00 -1.9737e+00  ...  -3.5271e+00 -1.0000e+02 -1.0000e+02
  1.7308e+00  1.0685e+00 -1.9737e+00  ...  -3.5271e+00 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  2.5640e+00  2.1829e+00 -5.7118e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6741e+00  1.2071e+00 -1.5666e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6741e+00  1.2071e+00 -1.5666e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6741e+00  1.2071e+00 -1.5666e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6741e+00  1.2071e+00 -1.5666e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6741e+00  1.2071e+00 -1.5666e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.4213e+00  3.2191e+00  8.7960e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.5707e+00 -5.6643e+00 -6.2070e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  2.0767e+00  1.7639e+00 -7.9845e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.7167e+00  1.3950e+00 -1.1728e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6892e+00  1.3648e+00 -1.2497e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6892e+00  1.3648e+00 -1.2497e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.0621e+00  2.7488e+00 -1.5434e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5433e+00  1.1115e+00 -1.8720e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5433e+00  1.1115e+00 -1.8720e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.5433e+00  1.1115e+00 -1.8720e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5433e+00  1.1115e+00 -1.8720e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.5433e+00  1.1115e+00 -1.8720e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  2.8303e+00  2.4311e+00 -4.9530e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
 -5.2866e+00 -5.4731e+00 -6.1667e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.9322e+00  1.4298e+00 -1.4892e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.7017e+00  1.1863e+00 -1.7726e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7017e+00  1.1863e+00 -1.7726e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7017e+00  1.1863e+00 -1.7726e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 0, 22, 0, 54, 55, 22, 0, 57, 1], [7, 1], [7, 0, 0, 0, 0, 58, 0, 1], [7, 0, 22, 0, 55, 1], [7, 1], [7, 1], [7, 1], [7, 0, 32, 0, 0, 57, 58, 0, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
cond_score Variable containing:
(0 ,.,.) = 
  3.5013e+00  3.2332e+00  8.6926e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8108e+00  1.4032e+00 -1.2394e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8108e+00  1.4032e+00 -1.2394e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.8108e+00  1.4032e+00 -1.2394e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8108e+00  1.4032e+00 -1.2394e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8108e+00  1.4032e+00 -1.2394e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(1 ,.,.) = 
  3.3594e+00  3.2386e+00  1.0471e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8453e+00  1.6399e+00 -8.7145e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8453e+00  1.6399e+00 -8.7145e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.8453e+00  1.6399e+00 -8.7145e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8453e+00  1.6399e+00 -8.7145e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8453e+00  1.6399e+00 -8.7145e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(2 ,.,.) = 
  1.6704e+00  1.5312e+00 -1.0676e+00  ...  -2.4115e+00 -1.0000e+02 -1.0000e+02
 -5.1908e+00 -5.2480e+00 -5.9917e+00  ...  -6.1594e+00 -1.0000e+02 -1.0000e+02
  2.0415e+00  1.8773e+00 -6.2813e-01  ...  -1.8365e+00 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.8395e+00  1.6732e+00 -8.4366e-01  ...  -2.0216e+00 -1.0000e+02 -1.0000e+02
  1.9382e+00  1.7730e+00 -7.5715e-01  ...  -1.9658e+00 -1.0000e+02 -1.0000e+02
  1.9938e+00  1.8296e+00 -7.1159e-01  ...  -1.9426e+00 -1.0000e+02 -1.0000e+02
...

(12,.,.) = 
  3.8521e+00  3.8209e+00  1.8921e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7571e+00  1.6379e+00 -8.0995e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7571e+00  1.6379e+00 -8.0995e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.7571e+00  1.6379e+00 -8.0995e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7571e+00  1.6379e+00 -8.0995e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.7571e+00  1.6379e+00 -8.0995e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(13,.,.) = 
  3.8131e+00  3.7461e+00  1.4503e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8080e+00  1.6375e+00 -1.1438e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8080e+00  1.6375e+00 -1.1438e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.8080e+00  1.6375e+00 -1.1438e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8080e+00  1.6375e+00 -1.1438e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.8080e+00  1.6375e+00 -1.1438e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02

(14,.,.) = 
  3.9493e+00  3.9642e+00  2.2501e+00  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6635e+00  1.6041e+00 -6.6760e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6635e+00  1.6041e+00 -6.6760e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
                 ...                   ⋱                   ...                
  1.6635e+00  1.6041e+00 -6.6760e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6635e+00  1.6041e+00 -6.6760e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
  1.6635e+00  1.6041e+00 -6.6760e-01  ...  -1.0000e+02 -1.0000e+02 -1.0000e+02
[torch.cuda.FloatTensor of size 15x9x62 (GPU 0)]

gt_where_seq [[7, 1], [7, 1], [7, 1], [7, 1], [7, 1], [7, 1]]
>>>>>>> master
